{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./pipeline/pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./pipeline/pipeline.py\n",
    "\n",
    "import kfp\n",
    "\n",
    "merge_and_split_op = kfp.components.load_component_from_file(\"./kf_utils/merge_and_split_op.yaml\")\n",
    "preprocess_dataset_op = kfp.components.load_component_from_file(\"./kf_utils/preprocess_dataset_op.yaml\")\n",
    "prepare_data_op = kfp.components.load_component_from_file(\"./kf_utils/prepare_data_op.yaml\")\n",
    "train_svm_op = kfp.components.load_component_from_file(\"./kf_utils/train_svm_op.yaml\")\n",
    "train_randomforest_op = kfp.components.load_component_from_file(\"./kf_utils/train_randomforest_op.yaml\")\n",
    "train_xgb_op = kfp.components.load_component_from_file(\"./kf_utils/train_xgb_op.yaml\")\n",
    "evaluate_models_op = kfp.components.load_component_from_file(\"./kf_utils/evaluate_models_op.yaml\")\n",
    "train_best_model_op = kfp.components.load_component_from_file(\"./kf_utils/train_best_model_op.yaml\")\n",
    "model_predict_op = kfp.components.load_component_from_file(\"./kf_utils/model_predict_op.yaml\")\n",
    "\n",
    "@kfp.dsl.pipeline(\n",
    "   name='Emission prediction pipeline',\n",
    "   description='An example pipeline.'\n",
    ")\n",
    "def emission_pipeline(\n",
    "    bucket,\n",
    "    data_2015,\n",
    "    data_2016,\n",
    "    hyperopt_iterations,\n",
    "    subfolder\n",
    "):\n",
    "    merge_and_split_task = merge_and_split_op(bucket, data_2015, data_2016)\n",
    "    preprocess_task = preprocess_dataset_op(merge_and_split_task.outputs['output_edfcsv'])\n",
    "    preparation_task = prepare_data_op(preprocess_task.outputs['output_cleandatacsv'])\n",
    "    \n",
    "    rf_train_task = train_randomforest_op(preparation_task.outputs['output_xtraincsv'],\n",
    "                                         preparation_task.outputs['output_ytraincsv'],\n",
    "                                         preparation_task.outputs['output_xtestcsv'],\n",
    "                                         preparation_task.outputs['output_ytestcsv'],\n",
    "                                         2)\n",
    "    \n",
    "    xgb_train_task = train_xgb_op(preparation_task.outputs['output_xtraincsv'],\n",
    "                                 preparation_task.outputs['output_ytraincsv'],\n",
    "                                 preparation_task.outputs['output_xtestcsv'],\n",
    "                                 preparation_task.outputs['output_ytestcsv'],\n",
    "                                 2)\n",
    "    \n",
    "    svm_train_task = train_svm_op(preparation_task.outputs['output_xtraincsv'],\n",
    "                                 preparation_task.outputs['output_ytraincsv'],\n",
    "                                 preparation_task.outputs['output_xtestcsv'],\n",
    "                                 preparation_task.outputs['output_ytestcsv'],\n",
    "                                 2)\n",
    "    evaluate_models_task = evaluate_models_op(bucket,\n",
    "                                              subfolder,\n",
    "                                              svm_train_task.outputs['MSE'],\n",
    "                                              svm_train_task.outputs['R2'],\n",
    "                                              svm_train_task.outputs['hyperparams'],\n",
    "                                              xgb_train_task.outputs['MSE'],\n",
    "                                              xgb_train_task.outputs['R2'],\n",
    "                                              xgb_train_task.outputs['hyperparams'],\n",
    "                                              rf_train_task.outputs['MSE'],\n",
    "                                              rf_train_task.outputs['R2'],\n",
    "                                              rf_train_task.outputs['hyperparams']\n",
    "                                             )\n",
    "    \n",
    "    train_best_model_task = train_best_model_op(evaluate_models_task.outputs['best_model'],\n",
    "                                               evaluate_models_task.outputs['hyperparams'],\n",
    "                                               preparation_task.outputs['output_xtraincsv'],\n",
    "                                               preparation_task.outputs['output_ytraincsv'])\n",
    "    \n",
    "    model_predict_task = model_predict_op(train_best_model_task.outputs['output_pickle_model'],\n",
    "                                          preparation_task.outputs['output_xtestcsv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "dsl-compile --py pipeline/pipeline.py --output pipeline/pipeline.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = 'http://f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/pipeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "authservice_session='authservice_session=MTY0MzYzNjI0NHxOd3dBTkZaTk16TktWVVJZV0VRMFNrUTBXRm8xTTFaRU5WaFZRa05ITlVOQlJFNUNXVkJETlZkRVNFeEROMHhIUmxSSVdqSlZRVkU9fMXwGJrw3YahHYcxrcQCmxVs2IY_ZkZJJmnKAa1VC0l1'\n",
    "client = kfp.Client(host=ENDPOINT, cookies=authservice_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(host=ENDPOINT, other_client_id=\"admin@kubeflow.org\", other_client_secret=\"12341234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiments': None, 'next_page_token': None, 'total_size': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_experiments(namespace=\"admin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=http://f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/pipeline/#/pipelines/details/d6c10b81-2d78-41fa-8343-97c0c4065553>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upload_pipe = client.upload_pipeline(pipeline_package_path=\"./pipeline.yaml\",\n",
    "                      pipeline_name=\"test_from_jupyter_TESTDELETE\",\n",
    "                      description=\"frend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(text):\n",
    "    match = re.search('{\\'id\\': \\'(.+?)\\',\\\\n', text)        \n",
    "    if match:\n",
    "        found = match.group(1)\n",
    "        return(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d6c10b81-2d78-41fa-8343-97c0c4065553'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_id(str(upload_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = 'fe0390c9-a311-4248-89e2-72522f17c26c'\n",
    "job_name = 'run_from_ipynb'\n",
    "pipeline_id = '3ac54c42-f463-49cb-9cf3-8b1eb14b7eae'\n",
    "version_id = '1'\n",
    "params = {'bucket' : 'sgf-wedr-src-data',\n",
    "        'data_2015' : 'temptest/2015-building-energy-benchmarking.csv',\n",
    "        'data_2016' : 'temptest/2016-building-energy-benchmarking.csv',\n",
    "        'hyperopt_iterations' : '1',\n",
    "        'subfolder' : 'temptest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/pipeline/#/runs/details/a3f90e7c-1376-46f4-8ccb-d95ab15d2d06\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2022, 1, 28, 14, 46, 38, tzinfo=tzutc()),\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'finished_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzutc()),\n",
       " 'id': 'a3f90e7c-1376-46f4-8ccb-d95ab15d2d06',\n",
       " 'metrics': None,\n",
       " 'name': 'run_from_ipynb',\n",
       " 'pipeline_spec': {'parameters': [{'name': 'bucket',\n",
       "                                   'value': 'sgf-wedr-src-data'},\n",
       "                                  {'name': 'data_2015',\n",
       "                                   'value': 'temptest/2015-building-energy-benchmarking.csv'},\n",
       "                                  {'name': 'data_2016',\n",
       "                                   'value': 'temptest/2016-building-energy-benchmarking.csv'},\n",
       "                                  {'name': 'hyperopt_iterations', 'value': '1'},\n",
       "                                  {'name': 'subfolder', 'value': 'temptest'}],\n",
       "                   'pipeline_id': '3ac54c42-f463-49cb-9cf3-8b1eb14b7eae',\n",
       "                   'pipeline_manifest': None,\n",
       "                   'pipeline_name': 'test_from_jupyter',\n",
       "                   'workflow_manifest': '{\"kind\":\"Workflow\",\"apiVersion\":\"argoproj.io/v1alpha1\",\"metadata\":{\"generateName\":\"emission-prediction-pipeline-\",\"creationTimestamp\":null,\"labels\":{\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\"},\"annotations\":{\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline_compilation_time\":\"2022-01-28T10:26:04.914908\",\"pipelines.kubeflow.org/pipeline_spec\":\"{\\\\\"description\\\\\": '\n",
       "                                        '\\\\\"An example pipeline.\\\\\", '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"bucket\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"data_2015\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"data_2016\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"hyperopt_iterations\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"subfolder\\\\\"}], '\n",
       "                                        '\\\\\"name\\\\\": \\\\\"Emission prediction '\n",
       "                                        'pipeline\\\\\"}\"}},\"spec\":{\"templates\":[{\"name\":\"emission-prediction-pipeline\",\"inputs\":{\"parameters\":[{\"name\":\"bucket\"},{\"name\":\"data_2015\"},{\"name\":\"data_2016\"},{\"name\":\"hyperopt_iterations\"},{\"name\":\"subfolder\"}]},\"outputs\":{},\"metadata\":{},\"dag\":{\"tasks\":[{\"name\":\"evaluate-models\",\"template\":\"evaluate-models\",\"arguments\":{\"parameters\":[{\"name\":\"bucket\",\"value\":\"{{inputs.parameters.bucket}}\"},{\"name\":\"subfolder\",\"value\":\"{{inputs.parameters.subfolder}}\"},{\"name\":\"train-randomforest-MSE\",\"value\":\"{{tasks.train-randomforest.outputs.parameters.train-randomforest-MSE}}\"},{\"name\":\"train-randomforest-R2\",\"value\":\"{{tasks.train-randomforest.outputs.parameters.train-randomforest-R2}}\"},{\"name\":\"train-randomforest-hyperparams\",\"value\":\"{{tasks.train-randomforest.outputs.parameters.train-randomforest-hyperparams}}\"},{\"name\":\"train-svm-MSE\",\"value\":\"{{tasks.train-svm.outputs.parameters.train-svm-MSE}}\"},{\"name\":\"train-svm-R2\",\"value\":\"{{tasks.train-svm.outputs.parameters.train-svm-R2}}\"},{\"name\":\"train-svm-hyperparams\",\"value\":\"{{tasks.train-svm.outputs.parameters.train-svm-hyperparams}}\"},{\"name\":\"train-xgb-MSE\",\"value\":\"{{tasks.train-xgb.outputs.parameters.train-xgb-MSE}}\"},{\"name\":\"train-xgb-R2\",\"value\":\"{{tasks.train-xgb.outputs.parameters.train-xgb-R2}}\"},{\"name\":\"train-xgb-hyperparams\",\"value\":\"{{tasks.train-xgb.outputs.parameters.train-xgb-hyperparams}}\"}]},\"dependencies\":[\"train-randomforest\",\"train-svm\",\"train-xgb\"]},{\"name\":\"merge-and-split\",\"template\":\"merge-and-split\",\"arguments\":{\"parameters\":[{\"name\":\"bucket\",\"value\":\"{{inputs.parameters.bucket}}\"},{\"name\":\"data_2015\",\"value\":\"{{inputs.parameters.data_2015}}\"},{\"name\":\"data_2016\",\"value\":\"{{inputs.parameters.data_2016}}\"}]}},{\"name\":\"model-predict\",\"template\":\"model-predict\",\"arguments\":{\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_xtestcsv}}\"},{\"name\":\"train-best-model-output_pickle_model\",\"from\":\"{{tasks.train-best-model.outputs.artifacts.train-best-model-output_pickle_model}}\"}]},\"dependencies\":[\"prepare-data\",\"train-best-model\"]},{\"name\":\"prepare-data\",\"template\":\"prepare-data\",\"arguments\":{\"artifacts\":[{\"name\":\"preprocess-dataset-output_cleandatacsv\",\"from\":\"{{tasks.preprocess-dataset.outputs.artifacts.preprocess-dataset-output_cleandatacsv}}\"}]},\"dependencies\":[\"preprocess-dataset\"]},{\"name\":\"preprocess-dataset\",\"template\":\"preprocess-dataset\",\"arguments\":{\"artifacts\":[{\"name\":\"merge-and-split-output_edfcsv\",\"from\":\"{{tasks.merge-and-split.outputs.artifacts.merge-and-split-output_edfcsv}}\"}]},\"dependencies\":[\"merge-and-split\"]},{\"name\":\"train-best-model\",\"template\":\"train-best-model\",\"arguments\":{\"parameters\":[{\"name\":\"evaluate-models-best_model\",\"value\":\"{{tasks.evaluate-models.outputs.parameters.evaluate-models-best_model}}\"},{\"name\":\"evaluate-models-hyperparams\",\"value\":\"{{tasks.evaluate-models.outputs.parameters.evaluate-models-hyperparams}}\"}],\"artifacts\":[{\"name\":\"prepare-data-output_xtraincsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_xtraincsv}}\"},{\"name\":\"prepare-data-output_ytraincsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_ytraincsv}}\"}]},\"dependencies\":[\"evaluate-models\",\"prepare-data\"]},{\"name\":\"train-randomforest\",\"template\":\"train-randomforest\",\"arguments\":{\"parameters\":[{\"name\":\"hyperopt_iterations\",\"value\":\"{{inputs.parameters.hyperopt_iterations}}\"}],\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_xtestcsv}}\"},{\"name\":\"prepare-data-output_xtraincsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_xtraincsv}}\"},{\"name\":\"prepare-data-output_ytestcsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_ytestcsv}}\"},{\"name\":\"prepare-data-output_ytraincsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_ytraincsv}}\"}]},\"dependencies\":[\"prepare-data\"]},{\"name\":\"train-svm\",\"template\":\"train-svm\",\"arguments\":{\"parameters\":[{\"name\":\"hyperopt_iterations\",\"value\":\"{{inputs.parameters.hyperopt_iterations}}\"}],\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_xtestcsv}}\"},{\"name\":\"prepare-data-output_xtraincsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_xtraincsv}}\"},{\"name\":\"prepare-data-output_ytestcsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_ytestcsv}}\"},{\"name\":\"prepare-data-output_ytraincsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_ytraincsv}}\"}]},\"dependencies\":[\"prepare-data\"]},{\"name\":\"train-xgb\",\"template\":\"train-xgb\",\"arguments\":{\"parameters\":[{\"name\":\"hyperopt_iterations\",\"value\":\"{{inputs.parameters.hyperopt_iterations}}\"}],\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_xtestcsv}}\"},{\"name\":\"prepare-data-output_xtraincsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_xtraincsv}}\"},{\"name\":\"prepare-data-output_ytestcsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_ytestcsv}}\"},{\"name\":\"prepare-data-output_ytraincsv\",\"from\":\"{{tasks.prepare-data.outputs.artifacts.prepare-data-output_ytraincsv}}\"}]},\"dependencies\":[\"prepare-data\"]}]}},{\"name\":\"evaluate-models\",\"inputs\":{\"parameters\":[{\"name\":\"bucket\"},{\"name\":\"subfolder\"},{\"name\":\"train-randomforest-MSE\"},{\"name\":\"train-randomforest-R2\"},{\"name\":\"train-randomforest-hyperparams\"},{\"name\":\"train-svm-MSE\"},{\"name\":\"train-svm-R2\"},{\"name\":\"train-svm-hyperparams\"},{\"name\":\"train-xgb-MSE\"},{\"name\":\"train-xgb-R2\"},{\"name\":\"train-xgb-hyperparams\"}]},\"outputs\":{\"parameters\":[{\"name\":\"evaluate-models-best_model\",\"valueFrom\":{\"path\":\"/tmp/outputs/best_model/data\"}},{\"name\":\"evaluate-models-hyperparams\",\"valueFrom\":{\"path\":\"/tmp/outputs/hyperparams/data\"}}],\"artifacts\":[{\"name\":\"evaluate-models-best_model\",\"path\":\"/tmp/outputs/best_model/data\"},{\"name\":\"evaluate-models-hyperparams\",\"path\":\"/tmp/outputs/hyperparams/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"bucket\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.bucket}}\\\\\", '\n",
       "                                        '\\\\\"rf_hyperparams\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-randomforest-hyperparams}}\\\\\", '\n",
       "                                        '\\\\\"rf_mse\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-randomforest-MSE}}\\\\\", '\n",
       "                                        '\\\\\"rf_r2\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-randomforest-R2}}\\\\\", '\n",
       "                                        '\\\\\"subfolder\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.subfolder}}\\\\\", '\n",
       "                                        '\\\\\"svm_hyperparams\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-svm-hyperparams}}\\\\\", '\n",
       "                                        '\\\\\"svm_mse\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-svm-MSE}}\\\\\", '\n",
       "                                        '\\\\\"svm_r2\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-svm-R2}}\\\\\", '\n",
       "                                        '\\\\\"xgb_hyperparams\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-xgb-hyperparams}}\\\\\", '\n",
       "                                        '\\\\\"xgb_mse\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-xgb-MSE}}\\\\\", '\n",
       "                                        '\\\\\"xgb_r2\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.train-xgb-R2}}\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"71480ea4e663a7a4488dd1308150bd5a38c8e976615901e4bab658e8670afc1a\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/evaluate_models_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--bucket\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"bucket\\\\\"}, \\\\\"--subfolder\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": \\\\\"subfolder\\\\\"}, '\n",
       "                                        '\\\\\"--svm-mse\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"svm_mse\\\\\"}, \\\\\"--svm-r2\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": \\\\\"svm_r2\\\\\"}, '\n",
       "                                        '\\\\\"--svm-hyperparams\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"svm_hyperparams\\\\\"}, '\n",
       "                                        '\\\\\"--xgb-mse\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"xgb_mse\\\\\"}, \\\\\"--xgb-r2\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": \\\\\"xgb_r2\\\\\"}, '\n",
       "                                        '\\\\\"--xgb-hyperparams\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"xgb_hyperparams\\\\\"}, '\n",
       "                                        '\\\\\"--rf-mse\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"rf_mse\\\\\"}, \\\\\"--rf-r2\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": \\\\\"rf_r2\\\\\"}, '\n",
       "                                        '\\\\\"--rf-hyperparams\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"rf_hyperparams\\\\\"}, '\n",
       "                                        '\\\\\"----output-paths\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": \\\\\"best_model\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"hyperparams\\\\\"}], \\\\\"command\\\\\": '\n",
       "                                        '[\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'evaluate_models(bucket, '\n",
       "                                        '\\\\\\\\n                     '\n",
       "                                        'subfolder,\\\\\\\\n                     '\n",
       "                                        'svm_mse, \\\\\\\\n                     '\n",
       "                                        'svm_r2, \\\\\\\\n                     '\n",
       "                                        'svm_hyperparams, '\n",
       "                                        '\\\\\\\\n                     xgb_mse, '\n",
       "                                        '\\\\\\\\n                     xgb_r2, '\n",
       "                                        '\\\\\\\\n                     '\n",
       "                                        'xgb_hyperparams, '\n",
       "                                        '\\\\\\\\n                     rf_mse, '\n",
       "                                        '\\\\\\\\n                     rf_r2, '\n",
       "                                        '\\\\\\\\n                     '\n",
       "                                        'rf_hyperparams\\\\\\\\n                     '\n",
       "                                        '):\\\\\\\\n\\\\\\\\n    import pandas as '\n",
       "                                        'pd\\\\\\\\n    import matplotlib.pyplot '\n",
       "                                        'as plt\\\\\\\\n    import seaborn as '\n",
       "                                        'sns\\\\\\\\n    import numpy as '\n",
       "                                        'np\\\\\\\\n    import boto3\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'def easy_bar_plot(x, y, data, '\n",
       "                                        'figname, order=None, xlab=None, '\n",
       "                                        'ylab=None, title=None, '\n",
       "                                        'grid=True,\\\\\\\\n                  '\n",
       "                                        'values_over_bars=True, vob_round=0, '\n",
       "                                        'vob_offset=None, vob_rot=None, '\n",
       "                                        'x_tick_rot=None):\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'fig, ax = plt.subplots(figsize = (18, '\n",
       "                                        '8))\\\\\\\\n        if order is '\n",
       "                                        'None:\\\\\\\\n            order = '\n",
       "                                        'np.sort(data[x].unique()) '\n",
       "                                        '\\\\\\\\n        sns.barplot(x=x, y=y, '\n",
       "                                        'data=data, ax=ax, '\n",
       "                                        'order=order)\\\\\\\\n        if xlab is '\n",
       "                                        'not None:\\\\\\\\n            '\n",
       "                                        'ax.set_xlabel(xlab, fontsize = 16, '\n",
       "                                        'fontweight = '\n",
       "                                        '\\\\\\\\\\\\\"bold\\\\\\\\\\\\\")\\\\\\\\n        if '\n",
       "                                        'ylab is not None:\\\\\\\\n            '\n",
       "                                        'ax.set_ylabel(ylab, fontsize = 16, '\n",
       "                                        'fontweight = '\n",
       "                                        '\\\\\\\\\\\\\"bold\\\\\\\\\\\\\")\\\\\\\\n        if '\n",
       "                                        'title is not None:\\\\\\\\n            '\n",
       "                                        'plt.suptitle(title, fontsize = 18, '\n",
       "                                        'fontweight = '\n",
       "                                        '\\\\\\\\\\\\\"bold\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'if grid :\\\\\\\\n            '\n",
       "                                        \"plt.grid(b=True, which='major', \"\n",
       "                                        \"axis='both', alpha = \"\n",
       "                                        '0.3)\\\\\\\\n\\\\\\\\n        if '\n",
       "                                        'values_over_bars:\\\\\\\\n            if '\n",
       "                                        'vob_offset is '\n",
       "                                        'None:\\\\\\\\n                vob_offset '\n",
       "                                        '= 0.015\\\\\\\\n            if vob_rot is '\n",
       "                                        'None:\\\\\\\\n                vob_rot = '\n",
       "                                        '0\\\\\\\\n            if vob_rot \\\\u003e '\n",
       "                                        '0:\\\\\\\\n                '\n",
       "                                        'ha=\\\\\\\\\\\\\"left\\\\\\\\\\\\\"\\\\\\\\n            '\n",
       "                                        'else:\\\\\\\\n                '\n",
       "                                        'ha=\\\\\\\\\\\\\"center\\\\\\\\\\\\\"\\\\\\\\n            '\n",
       "                                        'pos=0\\\\\\\\n            for i, (q, val) '\n",
       "                                        'in '\n",
       "                                        'data.iterrows():\\\\\\\\n                '\n",
       "                                        'if val != 0:\\\\\\\\n                    '\n",
       "                                        'ax.text(pos, val + '\n",
       "                                        'vob_offset*data[y].max(), '\n",
       "                                        '\\\\\\\\\\\\\"{}\\\\\\\\\\\\\".format(round(val,vob_round)), '\n",
       "                                        '\\\\\\\\n                            '\n",
       "                                        'ha=ha, fontsize = 12, fontweight = '\n",
       "                                        '\\\\\\\\\\\\\"bold\\\\\\\\\\\\\", rotation=vob_rot, '\n",
       "                                        '\\\\\\\\n                           '\n",
       "                                        'rotation_mode=\\\\\\\\\\\\\"anchor\\\\\\\\\\\\\")\\\\\\\\n                '\n",
       "                                        'pos += 1\\\\\\\\n        if x_tick_rot is '\n",
       "                                        'not None:\\\\\\\\n            '\n",
       "                                        'plt.xticks(rotation = x_tick_rot, '\n",
       "                                        'ha=\\\\\\\\\\\\\"right\\\\\\\\\\\\\")\\\\\\\\n        '\n",
       "                                        'plt.savefig(figname)\\\\\\\\n        '\n",
       "                                        'plt.show()\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'performance_report = {}\\\\\\\\n    '\n",
       "                                        'performance_report[\\\\\\\\\\\\\"SVM\\\\\\\\\\\\\"] '\n",
       "                                        '= {\\\\\\\\\\\\\"MSE\\\\\\\\\\\\\" : svm_mse, '\n",
       "                                        '\\\\\\\\\\\\\"R2\\\\\\\\\\\\\" : svm_r2}\\\\\\\\n    '\n",
       "                                        'performance_report[\\\\\\\\\\\\\"XGB\\\\\\\\\\\\\"] '\n",
       "                                        '= {\\\\\\\\\\\\\"MSE\\\\\\\\\\\\\" : xgb_mse, '\n",
       "                                        '\\\\\\\\\\\\\"R2\\\\\\\\\\\\\" : xgb_r2}\\\\\\\\n    '\n",
       "                                        'performance_report[\\\\\\\\\\\\\"RandomForest\\\\\\\\\\\\\"] '\n",
       "                                        '= {\\\\\\\\\\\\\"MSE\\\\\\\\\\\\\" : rf_mse, '\n",
       "                                        '\\\\\\\\\\\\\"R2\\\\\\\\\\\\\" : '\n",
       "                                        'rf_r2}\\\\\\\\n\\\\\\\\n    performance_df = '\n",
       "                                        'pd.DataFrame.from_dict(performance_report, '\n",
       "                                        'orient=\\\\\\\\\\\\\"index\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'performance_df = '\n",
       "                                        'performance_df.reset_index().rename(columns={\\\\\\\\\\\\\"index\\\\\\\\\\\\\" '\n",
       "                                        ': \\\\\\\\\\\\\"Model\\\\\\\\\\\\\"})\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'hyperparams_dict = {\\\\\\\\\\\\\"SVM\\\\\\\\\\\\\" '\n",
       "                                        ': svm_hyperparams, \\\\\\\\\\\\\"XGB\\\\\\\\\\\\\" '\n",
       "                                        ': xgb_hyperparams, '\n",
       "                                        '\\\\\\\\\\\\\"RandomForest\\\\\\\\\\\\\" : '\n",
       "                                        'rf_hyperparams}\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'easy_bar_plot(x=\\\\\\\\\\\\\"Model\\\\\\\\\\\\\", '\n",
       "                                        'y=\\\\\\\\\\\\\"R2\\\\\\\\\\\\\", '\n",
       "                                        'data=performance_df[[\\\\\\\\\\\\\"Model\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"R2\\\\\\\\\\\\\"]],\\\\\\\\n                  '\n",
       "                                        'figname = '\n",
       "                                        '\\\\\\\\\\\\\"./model_performance_R2.png\\\\\\\\\\\\\",\\\\\\\\n                  '\n",
       "                                        'order=performance_df[\\\\\\\\\\\\\"Model\\\\\\\\\\\\\"], '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'xlab=\\\\\\\\\\\\\"Model\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                  ylab=\\\\\\\\\\\\\"R2 '\n",
       "                                        'score\\\\\\\\\\\\\", \\\\\\\\n                  '\n",
       "                                        'title=\\\\\\\\\\\\\"R2 score by '\n",
       "                                        'Model\\\\\\\\\\\\\", \\\\\\\\n                  '\n",
       "                                        'grid=True, \\\\\\\\n                  '\n",
       "                                        'values_over_bars=True, '\n",
       "                                        '\\\\\\\\n                  vob_round=3, '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'vob_offset=None, '\n",
       "                                        '\\\\\\\\n                  vob_rot=None, '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'x_tick_rot=None)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'easy_bar_plot(x=\\\\\\\\\\\\\"Model\\\\\\\\\\\\\", '\n",
       "                                        'y=\\\\\\\\\\\\\"MSE\\\\\\\\\\\\\", '\n",
       "                                        'data=performance_df[[\\\\\\\\\\\\\"Model\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"MSE\\\\\\\\\\\\\"]], '\n",
       "                                        '\\\\\\\\n                  figname = '\n",
       "                                        '\\\\\\\\\\\\\"./model_performance_MSE.png\\\\\\\\\\\\\",\\\\\\\\n                  '\n",
       "                                        'order=performance_df[\\\\\\\\\\\\\"Model\\\\\\\\\\\\\"], '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'xlab=\\\\\\\\\\\\\"Model\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'ylab=\\\\\\\\\\\\\"MSE\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'title=\\\\\\\\\\\\\"MSE by Model\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                  grid=True, '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'values_over_bars=True, '\n",
       "                                        '\\\\\\\\n                  vob_round=3, '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'vob_offset=None, '\n",
       "                                        '\\\\\\\\n                  vob_rot=None, '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'x_tick_rot=None)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'best_model = '\n",
       "                                        'performance_df.loc[performance_df[\\\\\\\\\\\\\"R2\\\\\\\\\\\\\"]==performance_df[\\\\\\\\\\\\\"R2\\\\\\\\\\\\\"].max(), '\n",
       "                                        '\\\\\\\\\\\\\"Model\\\\\\\\\\\\\"].values[0]\\\\\\\\n    '\n",
       "                                        'best_models_hyperparams = '\n",
       "                                        'hyperparams_dict[best_model]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        's3_resource = '\n",
       "                                        \"boto3.client('s3')\\\\\\\\n    \"\n",
       "                                        's3_resource.upload_file(\\\\\\\\\\\\\"./model_performance_R2.png\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                            '\n",
       "                                        'bucket, '\n",
       "                                        '\\\\\\\\n                            '\n",
       "                                        'subfolder + '\n",
       "                                        '\\\\\\\\\\\\\"/model_performance_R2.png\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        's3_resource.upload_file(\\\\\\\\\\\\\"./model_performance_MSE.png\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                            '\n",
       "                                        'bucket, '\n",
       "                                        '\\\\\\\\n                            '\n",
       "                                        'subfolder + '\n",
       "                                        '\\\\\\\\\\\\\"/model_performance_MSE.png\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'return (best_model, '\n",
       "                                        'best_models_hyperparams)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_json(obj) -\\\\u003e '\n",
       "                                        'str:\\\\\\\\n    if isinstance(obj, '\n",
       "                                        'str):\\\\\\\\n        return obj\\\\\\\\n    '\n",
       "                                        'import json\\\\\\\\n\\\\\\\\n    def '\n",
       "                                        'default_serializer(obj):\\\\\\\\n        '\n",
       "                                        'if hasattr(obj, '\n",
       "                                        \"'to_struct'):\\\\\\\\n            return \"\n",
       "                                        'obj.to_struct()\\\\\\\\n        '\n",
       "                                        'else:\\\\\\\\n            raise '\n",
       "                                        'TypeError(\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"Object of type \\'%s\\' is not '\n",
       "                                        'JSON serializable and does not have '\n",
       "                                        '.to_struct() '\n",
       "                                        'method.\\\\\\\\\\\\\"\\\\\\\\n                % '\n",
       "                                        'obj.__class__.__name__)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'return json.dumps(obj, '\n",
       "                                        'default=default_serializer, '\n",
       "                                        'sort_keys=True)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_str(str_value: str) '\n",
       "                                        '-\\\\u003e str:\\\\\\\\n    if not '\n",
       "                                        'isinstance(str_value, '\n",
       "                                        'str):\\\\\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" '\n",
       "                                        'has type \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" instead of '\n",
       "                                        \"str.'.format(\\\\\\\\n            \"\n",
       "                                        'str(str_value), '\n",
       "                                        'str(type(str_value))))\\\\\\\\n    return '\n",
       "                                        'str_value\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'json\\\\\\\\nimport argparse\\\\\\\\n_parser '\n",
       "                                        '= '\n",
       "                                        \"argparse.ArgumentParser(prog='Evaluate \"\n",
       "                                        \"models', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--bucket\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"bucket\\\\\\\\\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--subfolder\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"subfolder\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--svm-mse\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"svm_mse\\\\\\\\\\\\\", '\n",
       "                                        'type=float, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--svm-r2\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"svm_r2\\\\\\\\\\\\\", '\n",
       "                                        'type=float, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--svm-hyperparams\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"svm_hyperparams\\\\\\\\\\\\\", '\n",
       "                                        'type=json.loads, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--xgb-mse\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"xgb_mse\\\\\\\\\\\\\", '\n",
       "                                        'type=float, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--xgb-r2\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"xgb_r2\\\\\\\\\\\\\", '\n",
       "                                        'type=float, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--xgb-hyperparams\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"xgb_hyperparams\\\\\\\\\\\\\", '\n",
       "                                        'type=json.loads, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--rf-mse\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"rf_mse\\\\\\\\\\\\\", '\n",
       "                                        'type=float, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--rf-r2\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"rf_r2\\\\\\\\\\\\\", type=float, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--rf-hyperparams\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"rf_hyperparams\\\\\\\\\\\\\", '\n",
       "                                        'type=json.loads, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"----output-paths\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        'type=str, nargs=2)\\\\\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        '[])\\\\\\\\n\\\\\\\\n_outputs = '\n",
       "                                        'evaluate_models(**_parsed_args)\\\\\\\\n\\\\\\\\n_output_serializers '\n",
       "                                        '= [\\\\\\\\n    _serialize_str,\\\\\\\\n    '\n",
       "                                        '_serialize_json,\\\\\\\\n\\\\\\\\n]\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'os\\\\\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\\\\\n    '\n",
       "                                        'try:\\\\\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\\\\\n    '\n",
       "                                        'except OSError:\\\\\\\\n        '\n",
       "                                        'pass\\\\\\\\n    with open(output_file, '\n",
       "                                        \"'w') as f:\\\\\\\\n        \"\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"bucket\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"subfolder\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"svm_mse\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"svm_r2\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"svm_hyperparams\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"JsonObject\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"xgb_mse\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"xgb_r2\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"xgb_hyperparams\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"JsonObject\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"rf_mse\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"rf_r2\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"rf_hyperparams\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"JsonObject\\\\\"}], \\\\\"metadata\\\\\": '\n",
       "                                        '{\\\\\"annotations\\\\\": {\\\\\"author\\\\\": '\n",
       "                                        '\\\\\"Antoine Villatte\\\\\"}}, \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Evaluate models\\\\\", \\\\\"outputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": \\\\\"best_model\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"String\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"hyperparams\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"JsonObject\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'evaluate_models(bucket, '\n",
       "                                        '\\\\n                     '\n",
       "                                        'subfolder,\\\\n                     '\n",
       "                                        'svm_mse, \\\\n                     '\n",
       "                                        'svm_r2, \\\\n                     '\n",
       "                                        'svm_hyperparams, '\n",
       "                                        '\\\\n                     xgb_mse, '\n",
       "                                        '\\\\n                     xgb_r2, '\n",
       "                                        '\\\\n                     '\n",
       "                                        'xgb_hyperparams, '\n",
       "                                        '\\\\n                     rf_mse, '\n",
       "                                        '\\\\n                     rf_r2, '\n",
       "                                        '\\\\n                     '\n",
       "                                        'rf_hyperparams\\\\n                     '\n",
       "                                        '):\\\\n\\\\n    import pandas as pd\\\\n    '\n",
       "                                        'import matplotlib.pyplot as plt\\\\n    '\n",
       "                                        'import seaborn as sns\\\\n    import '\n",
       "                                        'numpy as np\\\\n    import '\n",
       "                                        'boto3\\\\n\\\\n    def easy_bar_plot(x, '\n",
       "                                        'y, data, figname, order=None, '\n",
       "                                        'xlab=None, ylab=None, title=None, '\n",
       "                                        'grid=True,\\\\n                  '\n",
       "                                        'values_over_bars=True, vob_round=0, '\n",
       "                                        'vob_offset=None, vob_rot=None, '\n",
       "                                        'x_tick_rot=None):\\\\n\\\\n        fig, '\n",
       "                                        'ax = plt.subplots(figsize = (18, '\n",
       "                                        '8))\\\\n        if order is '\n",
       "                                        'None:\\\\n            order = '\n",
       "                                        'np.sort(data[x].unique()) \\\\n        '\n",
       "                                        'sns.barplot(x=x, y=y, data=data, '\n",
       "                                        'ax=ax, order=order)\\\\n        if xlab '\n",
       "                                        'is not None:\\\\n            '\n",
       "                                        'ax.set_xlabel(xlab, fontsize = 16, '\n",
       "                                        'fontweight = \\\\\"bold\\\\\")\\\\n        if '\n",
       "                                        'ylab is not None:\\\\n            '\n",
       "                                        'ax.set_ylabel(ylab, fontsize = 16, '\n",
       "                                        'fontweight = \\\\\"bold\\\\\")\\\\n        if '\n",
       "                                        'title is not None:\\\\n            '\n",
       "                                        'plt.suptitle(title, fontsize = 18, '\n",
       "                                        'fontweight = \\\\\"bold\\\\\")\\\\n\\\\n        '\n",
       "                                        'if grid :\\\\n            '\n",
       "                                        \"plt.grid(b=True, which='major', \"\n",
       "                                        \"axis='both', alpha = \"\n",
       "                                        '0.3)\\\\n\\\\n        if '\n",
       "                                        'values_over_bars:\\\\n            if '\n",
       "                                        'vob_offset is None:\\\\n                '\n",
       "                                        'vob_offset = 0.015\\\\n            if '\n",
       "                                        'vob_rot is None:\\\\n                '\n",
       "                                        'vob_rot = 0\\\\n            if vob_rot '\n",
       "                                        '\\\\u003e 0:\\\\n                '\n",
       "                                        'ha=\\\\\"left\\\\\"\\\\n            '\n",
       "                                        'else:\\\\n                '\n",
       "                                        'ha=\\\\\"center\\\\\"\\\\n            '\n",
       "                                        'pos=0\\\\n            for i, (q, val) '\n",
       "                                        'in data.iterrows():\\\\n                '\n",
       "                                        'if val != 0:\\\\n                    '\n",
       "                                        'ax.text(pos, val + '\n",
       "                                        'vob_offset*data[y].max(), '\n",
       "                                        '\\\\\"{}\\\\\".format(round(val,vob_round)), '\n",
       "                                        '\\\\n                            ha=ha, '\n",
       "                                        'fontsize = 12, fontweight = '\n",
       "                                        '\\\\\"bold\\\\\", rotation=vob_rot, '\n",
       "                                        '\\\\n                           '\n",
       "                                        'rotation_mode=\\\\\"anchor\\\\\")\\\\n                '\n",
       "                                        'pos += 1\\\\n        if x_tick_rot is '\n",
       "                                        'not None:\\\\n            '\n",
       "                                        'plt.xticks(rotation = x_tick_rot, '\n",
       "                                        'ha=\\\\\"right\\\\\")\\\\n        '\n",
       "                                        'plt.savefig(figname)\\\\n        '\n",
       "                                        'plt.show()\\\\n\\\\n    '\n",
       "                                        'performance_report = {}\\\\n    '\n",
       "                                        'performance_report[\\\\\"SVM\\\\\"] = '\n",
       "                                        '{\\\\\"MSE\\\\\" : svm_mse, \\\\\"R2\\\\\" : '\n",
       "                                        'svm_r2}\\\\n    '\n",
       "                                        'performance_report[\\\\\"XGB\\\\\"] = '\n",
       "                                        '{\\\\\"MSE\\\\\" : xgb_mse, \\\\\"R2\\\\\" : '\n",
       "                                        'xgb_r2}\\\\n    '\n",
       "                                        'performance_report[\\\\\"RandomForest\\\\\"] '\n",
       "                                        '= {\\\\\"MSE\\\\\" : rf_mse, \\\\\"R2\\\\\" : '\n",
       "                                        'rf_r2}\\\\n\\\\n    performance_df = '\n",
       "                                        'pd.DataFrame.from_dict(performance_report, '\n",
       "                                        'orient=\\\\\"index\\\\\")\\\\n    '\n",
       "                                        'performance_df = '\n",
       "                                        'performance_df.reset_index().rename(columns={\\\\\"index\\\\\" '\n",
       "                                        ': \\\\\"Model\\\\\"})\\\\n\\\\n    '\n",
       "                                        'hyperparams_dict = {\\\\\"SVM\\\\\" : '\n",
       "                                        'svm_hyperparams, \\\\\"XGB\\\\\" : '\n",
       "                                        'xgb_hyperparams, \\\\\"RandomForest\\\\\" : '\n",
       "                                        'rf_hyperparams}\\\\n\\\\n    '\n",
       "                                        'easy_bar_plot(x=\\\\\"Model\\\\\", '\n",
       "                                        'y=\\\\\"R2\\\\\", '\n",
       "                                        'data=performance_df[[\\\\\"Model\\\\\", '\n",
       "                                        '\\\\\"R2\\\\\"]],\\\\n                  '\n",
       "                                        'figname = '\n",
       "                                        '\\\\\"./model_performance_R2.png\\\\\",\\\\n                  '\n",
       "                                        'order=performance_df[\\\\\"Model\\\\\"], '\n",
       "                                        '\\\\n                  '\n",
       "                                        'xlab=\\\\\"Model\\\\\", '\n",
       "                                        '\\\\n                  ylab=\\\\\"R2 '\n",
       "                                        'score\\\\\", \\\\n                  '\n",
       "                                        'title=\\\\\"R2 score by Model\\\\\", '\n",
       "                                        '\\\\n                  grid=True, '\n",
       "                                        '\\\\n                  '\n",
       "                                        'values_over_bars=True, '\n",
       "                                        '\\\\n                  vob_round=3, '\n",
       "                                        '\\\\n                  vob_offset=None, '\n",
       "                                        '\\\\n                  vob_rot=None, '\n",
       "                                        '\\\\n                  '\n",
       "                                        'x_tick_rot=None)\\\\n\\\\n    '\n",
       "                                        'easy_bar_plot(x=\\\\\"Model\\\\\", '\n",
       "                                        'y=\\\\\"MSE\\\\\", '\n",
       "                                        'data=performance_df[[\\\\\"Model\\\\\", '\n",
       "                                        '\\\\\"MSE\\\\\"]], \\\\n                  '\n",
       "                                        'figname = '\n",
       "                                        '\\\\\"./model_performance_MSE.png\\\\\",\\\\n                  '\n",
       "                                        'order=performance_df[\\\\\"Model\\\\\"], '\n",
       "                                        '\\\\n                  '\n",
       "                                        'xlab=\\\\\"Model\\\\\", '\n",
       "                                        '\\\\n                  ylab=\\\\\"MSE\\\\\", '\n",
       "                                        '\\\\n                  title=\\\\\"MSE by '\n",
       "                                        'Model\\\\\", \\\\n                  '\n",
       "                                        'grid=True, \\\\n                  '\n",
       "                                        'values_over_bars=True, '\n",
       "                                        '\\\\n                  vob_round=3, '\n",
       "                                        '\\\\n                  vob_offset=None, '\n",
       "                                        '\\\\n                  vob_rot=None, '\n",
       "                                        '\\\\n                  '\n",
       "                                        'x_tick_rot=None)\\\\n\\\\n    best_model '\n",
       "                                        '= '\n",
       "                                        'performance_df.loc[performance_df[\\\\\"R2\\\\\"]==performance_df[\\\\\"R2\\\\\"].max(), '\n",
       "                                        '\\\\\"Model\\\\\"].values[0]\\\\n    '\n",
       "                                        'best_models_hyperparams = '\n",
       "                                        'hyperparams_dict[best_model]\\\\n\\\\n    '\n",
       "                                        's3_resource = '\n",
       "                                        \"boto3.client('s3')\\\\n    \"\n",
       "                                        's3_resource.upload_file(\\\\\"./model_performance_R2.png\\\\\", '\n",
       "                                        '\\\\n                            '\n",
       "                                        'bucket, '\n",
       "                                        '\\\\n                            '\n",
       "                                        'subfolder + '\n",
       "                                        '\\\\\"/model_performance_R2.png\\\\\")\\\\n    '\n",
       "                                        's3_resource.upload_file(\\\\\"./model_performance_MSE.png\\\\\", '\n",
       "                                        '\\\\n                            '\n",
       "                                        'bucket, '\n",
       "                                        '\\\\n                            '\n",
       "                                        'subfolder + '\n",
       "                                        '\\\\\"/model_performance_MSE.png\\\\\")\\\\n\\\\n    '\n",
       "                                        'return (best_model, '\n",
       "                                        'best_models_hyperparams)\\\\n\\\\ndef '\n",
       "                                        '_serialize_json(obj) -\\\\u003e '\n",
       "                                        'str:\\\\n    if isinstance(obj, '\n",
       "                                        'str):\\\\n        return obj\\\\n    '\n",
       "                                        'import json\\\\n\\\\n    def '\n",
       "                                        'default_serializer(obj):\\\\n        if '\n",
       "                                        'hasattr(obj, '\n",
       "                                        \"'to_struct'):\\\\n            return \"\n",
       "                                        'obj.to_struct()\\\\n        '\n",
       "                                        'else:\\\\n            raise '\n",
       "                                        'TypeError(\\\\n                '\n",
       "                                        '\\\\\"Object of type \\'%s\\' is not JSON '\n",
       "                                        'serializable and does not have '\n",
       "                                        '.to_struct() '\n",
       "                                        'method.\\\\\"\\\\n                % '\n",
       "                                        'obj.__class__.__name__)\\\\n\\\\n    '\n",
       "                                        'return json.dumps(obj, '\n",
       "                                        'default=default_serializer, '\n",
       "                                        'sort_keys=True)\\\\n\\\\ndef '\n",
       "                                        '_serialize_str(str_value: str) '\n",
       "                                        '-\\\\u003e str:\\\\n    if not '\n",
       "                                        'isinstance(str_value, str):\\\\n        '\n",
       "                                        'raise TypeError(\\'Value \\\\\"{}\\\\\" has '\n",
       "                                        'type \\\\\"{}\\\\\" instead of '\n",
       "                                        \"str.'.format(\\\\n            \"\n",
       "                                        'str(str_value), '\n",
       "                                        'str(type(str_value))))\\\\n    return '\n",
       "                                        'str_value\\\\n\\\\nimport json\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Evaluate \"\n",
       "                                        \"models', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--bucket\\\\\", '\n",
       "                                        'dest=\\\\\"bucket\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--subfolder\\\\\", '\n",
       "                                        'dest=\\\\\"subfolder\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--svm-mse\\\\\", '\n",
       "                                        'dest=\\\\\"svm_mse\\\\\", type=float, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--svm-r2\\\\\", '\n",
       "                                        'dest=\\\\\"svm_r2\\\\\", type=float, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--svm-hyperparams\\\\\", '\n",
       "                                        'dest=\\\\\"svm_hyperparams\\\\\", '\n",
       "                                        'type=json.loads, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--xgb-mse\\\\\", '\n",
       "                                        'dest=\\\\\"xgb_mse\\\\\", type=float, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--xgb-r2\\\\\", '\n",
       "                                        'dest=\\\\\"xgb_r2\\\\\", type=float, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--xgb-hyperparams\\\\\", '\n",
       "                                        'dest=\\\\\"xgb_hyperparams\\\\\", '\n",
       "                                        'type=json.loads, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--rf-mse\\\\\", '\n",
       "                                        'dest=\\\\\"rf_mse\\\\\", type=float, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--rf-r2\\\\\", '\n",
       "                                        'dest=\\\\\"rf_r2\\\\\", type=float, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--rf-hyperparams\\\\\", '\n",
       "                                        'dest=\\\\\"rf_hyperparams\\\\\", '\n",
       "                                        'type=json.loads, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"----output-paths\\\\\", '\n",
       "                                        'dest=\\\\\"_output_paths\\\\\", type=str, '\n",
       "                                        'nargs=2)\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\"_output_paths\\\\\", '\n",
       "                                        '[])\\\\n\\\\n_outputs = '\n",
       "                                        'evaluate_models(**_parsed_args)\\\\n\\\\n_output_serializers '\n",
       "                                        '= [\\\\n    _serialize_str,\\\\n    '\n",
       "                                        '_serialize_json,\\\\n\\\\n]\\\\n\\\\nimport '\n",
       "                                        'os\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\n    '\n",
       "                                        'try:\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\n    '\n",
       "                                        'except OSError:\\\\n        pass\\\\n    '\n",
       "                                        \"with open(output_file, 'w') as \"\n",
       "                                        'f:\\\\n        '\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\n\"],\"args\":[\"--bucket\",\"{{inputs.parameters.bucket}}\",\"--subfolder\",\"{{inputs.parameters.subfolder}}\",\"--svm-mse\",\"{{inputs.parameters.train-svm-MSE}}\",\"--svm-r2\",\"{{inputs.parameters.train-svm-R2}}\",\"--svm-hyperparams\",\"{{inputs.parameters.train-svm-hyperparams}}\",\"--xgb-mse\",\"{{inputs.parameters.train-xgb-MSE}}\",\"--xgb-r2\",\"{{inputs.parameters.train-xgb-R2}}\",\"--xgb-hyperparams\",\"{{inputs.parameters.train-xgb-hyperparams}}\",\"--rf-mse\",\"{{inputs.parameters.train-randomforest-MSE}}\",\"--rf-r2\",\"{{inputs.parameters.train-randomforest-R2}}\",\"--rf-hyperparams\",\"{{inputs.parameters.train-randomforest-hyperparams}}\",\"----output-paths\",\"/tmp/outputs/best_model/data\",\"/tmp/outputs/hyperparams/data\"],\"resources\":{}}},{\"name\":\"merge-and-split\",\"inputs\":{\"parameters\":[{\"name\":\"bucket\"},{\"name\":\"data_2015\"},{\"name\":\"data_2016\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"merge-and-split-output_edfcsv\",\"path\":\"/tmp/outputs/output_edfcsv/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"bucket\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.bucket}}\\\\\", '\n",
       "                                        '\\\\\"data_2015\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.data_2015}}\\\\\", '\n",
       "                                        '\\\\\"data_2016\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.data_2016}}\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"f3a4193e175a44e4d99167846361ada3bc260fdaf0563200bbbd47d5ba43e260\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/merge_and_split_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--bucket\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"bucket\\\\\"}, \\\\\"--data-2015\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": \\\\\"data_2015\\\\\"}, '\n",
       "                                        '\\\\\"--data-2016\\\\\", {\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"data_2016\\\\\"}, '\n",
       "                                        '\\\\\"--output-edfcsv\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_edfcsv\\\\\"}], \\\\\"command\\\\\": '\n",
       "                                        '[\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'merge_and_split(bucket, '\n",
       "                                        '\\\\\\\\n                    data_2015, '\n",
       "                                        '\\\\\\\\n                    data_2016, '\n",
       "                                        '\\\\\\\\n                    '\n",
       "                                        'output_edfcsv):\\\\\\\\n\\\\\\\\n    import '\n",
       "                                        'pandas as pd\\\\\\\\n    import '\n",
       "                                        're\\\\\\\\n    import boto3\\\\\\\\n    from '\n",
       "                                        'io import StringIO\\\\\\\\n    from '\n",
       "                                        'sklearn.model_selection import '\n",
       "                                        'GroupShuffleSplit\\\\\\\\n\\\\\\\\n    def '\n",
       "                                        'get_location(text, '\n",
       "                                        'method):\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"Retrieves data '\n",
       "                                        'from the 2015 dataset to harmonize it '\n",
       "                                        'with the 2016 '\n",
       "                                        'dataset\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n        '\n",
       "                                        'if method == '\n",
       "                                        '\\\\\\\\\\\\\"latitude\\\\\\\\\\\\\":\\\\\\\\n            '\n",
       "                                        'match = '\n",
       "                                        \"re.search('{\\\\\\\\\\\\\\\\'latitude\\\\\\\\\\\\\\\\': \"\n",
       "                                        \"\\\\\\\\\\\\\\\\'(.+?)\\\\\\\\\\\\\\\\', \"\n",
       "                                        \"\\\\\\\\\\\\\\\\'longitude', \"\n",
       "                                        'text)\\\\\\\\n        elif method == '\n",
       "                                        '\\\\\\\\\\\\\"longitude\\\\\\\\\\\\\":\\\\\\\\n            '\n",
       "                                        \"match = re.search('[0-9]\\\\\\\\\\\\\\\\', \"\n",
       "                                        \"\\\\\\\\\\\\\\\\'longitude\\\\\\\\\\\\\\\\': \"\n",
       "                                        \"\\\\\\\\\\\\\\\\'(.+?)\\\\\\\\\\\\\\\\', \"\n",
       "                                        \"\\\\\\\\\\\\\\\\'human_address\\\\\\\\\\\\\\\\'', \"\n",
       "                                        'text)\\\\\\\\n        elif method == '\n",
       "                                        '\\\\\\\\\\\\\"address\\\\\\\\\\\\\":\\\\\\\\n            '\n",
       "                                        'match = '\n",
       "                                        're.search(\\'\\\\\\\\\\\\\\\\\\'{\\\\\\\\\\\\\"address\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"(.+?)\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"city\\\\\\\\\\\\\":\\', text)      '\n",
       "                                        '\\\\\\\\n        elif method == '\n",
       "                                        '\\\\\\\\\\\\\"city\\\\\\\\\\\\\":\\\\\\\\n            '\n",
       "                                        'match = re.search(\\'\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"city\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"(.+?)\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"state\\\\\\\\\\\\\":\\', '\n",
       "                                        'text)\\\\\\\\n        elif method == '\n",
       "                                        '\\\\\\\\\\\\\"state\\\\\\\\\\\\\":\\\\\\\\n            '\n",
       "                                        'match = '\n",
       "                                        're.search(\\'\\\\\\\\\\\\\"state\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"(.+?)\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"zip\\\\\\\\\\\\\":\\', '\n",
       "                                        'text)\\\\\\\\n        elif method == '\n",
       "                                        '\\\\\\\\\\\\\"zip\\\\\\\\\\\\\":\\\\\\\\n            '\n",
       "                                        'match = '\n",
       "                                        're.search(\\'\\\\\\\\\\\\\"zip\\\\\\\\\\\\\": '\n",
       "                                        '\\\\\\\\\\\\\"(.+?)\\\\\\\\\\\\\"}\\\\\\\\\\\\\\\\\\'}\\', '\n",
       "                                        'text)\\\\\\\\n        '\n",
       "                                        'else:\\\\\\\\n            raise '\n",
       "                                        'ValueError(\\\\\\\\\\\\\"Veuillez choisir '\n",
       "                                        'une m\\\\\\\\u00e9thode (latitude, '\n",
       "                                        'longitude, adress, city, state, '\n",
       "                                        'zip)\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n        if '\n",
       "                                        'match:\\\\\\\\n            found = '\n",
       "                                        'match.group(1)\\\\\\\\n            '\n",
       "                                        'return(found)\\\\\\\\n        '\n",
       "                                        'return(\\\\\\\\\\\\\"N/A\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Load datasets\\\\\\\\n    csv_strings = '\n",
       "                                        \"{}\\\\\\\\n    encoding = 'utf-8'\\\\\\\\n    \"\n",
       "                                        'for source_data, year in '\n",
       "                                        'zip([data_2015, data_2016], '\n",
       "                                        '[\\\\\\\\\\\\\"2015\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"2016\\\\\\\\\\\\\"]):\\\\\\\\n        '\n",
       "                                        'csv_obj = '\n",
       "                                        \"boto3.client('s3').get_object(Bucket=bucket, \"\n",
       "                                        'Key=source_data)\\\\\\\\n        body = '\n",
       "                                        \"csv_obj['Body']\\\\\\\\n        \"\n",
       "                                        'csv_string = '\n",
       "                                        'body.read().decode(encoding)\\\\\\\\n        '\n",
       "                                        'csv_strings[year] = '\n",
       "                                        'csv_string\\\\\\\\n\\\\\\\\n    data15 = '\n",
       "                                        'pd.read_csv(StringIO(csv_strings[\\\\\\\\\\\\\"2015\\\\\\\\\\\\\"]))\\\\\\\\n    '\n",
       "                                        'data16 = '\n",
       "                                        'pd.read_csv(StringIO(csv_strings[\\\\\\\\\\\\\"2016\\\\\\\\\\\\\"]))\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Rename mismatched columns\\\\\\\\n    '\n",
       "                                        'rename_cols = {\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"GHGEmissions(MetricTonsCO2e)\\\\\\\\\\\\\" '\n",
       "                                        ': '\n",
       "                                        '\\\\\\\\\\\\\"TotalGHGEmissions\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"GHGEmissionsIntensity(kgCO2e/ft2)\\\\\\\\\\\\\" '\n",
       "                                        ': '\n",
       "                                        '\\\\\\\\\\\\\"GHGEmissionsIntensity\\\\\\\\\\\\\",\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"Comment\\\\\\\\\\\\\" : '\n",
       "                                        '\\\\\\\\\\\\\"Comments\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        '}\\\\\\\\n    data15.rename(columns = '\n",
       "                                        'rename_cols, inplace = '\n",
       "                                        'True)\\\\\\\\n\\\\\\\\n    # Extract location '\n",
       "                                        'info from 2015 dataset to harmonize '\n",
       "                                        'it\\\\\\\\n    '\n",
       "                                        'data15[\\\\\\\\\\\\\"Latitude\\\\\\\\\\\\\"] = '\n",
       "                                        'data15[\\\\\\\\\\\\\"Location\\\\\\\\\\\\\"].apply(get_location, '\n",
       "                                        'method = '\n",
       "                                        '\\\\\\\\\\\\\"latitude\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'data15[\\\\\\\\\\\\\"Longitude\\\\\\\\\\\\\"] = '\n",
       "                                        'data15[\\\\\\\\\\\\\"Location\\\\\\\\\\\\\"].apply(get_location, '\n",
       "                                        'method = '\n",
       "                                        '\\\\\\\\\\\\\"longitude\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'data15[\\\\\\\\\\\\\"Address\\\\\\\\\\\\\"] = '\n",
       "                                        'data15[\\\\\\\\\\\\\"Location\\\\\\\\\\\\\"].apply(get_location, '\n",
       "                                        'method = '\n",
       "                                        '\\\\\\\\\\\\\"address\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'data15[\\\\\\\\\\\\\"City\\\\\\\\\\\\\"] = '\n",
       "                                        'data15[\\\\\\\\\\\\\"Location\\\\\\\\\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\\\\\\\\\"city\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'data15[\\\\\\\\\\\\\"State\\\\\\\\\\\\\"] = '\n",
       "                                        'data15[\\\\\\\\\\\\\"Location\\\\\\\\\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\\\\\\\\\"state\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'data15[\\\\\\\\\\\\\"ZipCode\\\\\\\\\\\\\"] = '\n",
       "                                        'data15[\\\\\\\\\\\\\"Location\\\\\\\\\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\\\\\\\\\"zip\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'data15[\\\\\\\\\\\\\"ZipCode\\\\\\\\\\\\\"] = '\n",
       "                                        'data15[\\\\\\\\\\\\\"ZipCode\\\\\\\\\\\\\"].astype(int) '\n",
       "                                        '# convert to numeric\\\\\\\\n    '\n",
       "                                        'data15.drop(columns = '\n",
       "                                        '\\\\\\\\\\\\\"Location\\\\\\\\\\\\\", inplace = '\n",
       "                                        'True)\\\\\\\\n\\\\\\\\n    # Delete columns '\n",
       "                                        'from data15 that arent in '\n",
       "                                        'data16\\\\\\\\n    data15.drop(columns = '\n",
       "                                        'set(data15.columns.tolist()).difference(data16.columns.tolist()), '\n",
       "                                        'inplace = True)\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Harmonize column order\\\\\\\\n    '\n",
       "                                        'cols_order = '\n",
       "                                        'data16.columns.tolist()\\\\\\\\n    '\n",
       "                                        'data15 = data15.loc[:, '\n",
       "                                        'cols_order]\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Concatenate\\\\\\\\n    emission_df = '\n",
       "                                        'pd.concat([data15, data16], axis = 0, '\n",
       "                                        'ignore_index = True)\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Train/test split\\\\\\\\n    inTrain , '\n",
       "                                        'inTest = '\n",
       "                                        'next(GroupShuffleSplit(train_size = '\n",
       "                                        '0.7, random_state = '\n",
       "                                        '42).\\\\\\\\\\\\\\\\\\\\\\\\n                        '\n",
       "                                        'split(emission_df, groups = '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"OSEBuildingID\\\\\\\\\\\\\"]))\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\"] = '\n",
       "                                        '0\\\\\\\\n    emission_df.iloc[inTrain, '\n",
       "                                        '46] = 1\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'emission_df.to_csv(output_edfcsv, '\n",
       "                                        'index=False)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Merge \"\n",
       "                                        \"and split', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--bucket\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"bucket\\\\\\\\\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--data-2015\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"data_2015\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--data-2016\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"data_2016\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-edfcsv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_edfcsv\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'merge_and_split(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"bucket\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"data_2015\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"data_2016\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}], \\\\\"metadata\\\\\": '\n",
       "                                        '{\\\\\"annotations\\\\\": {\\\\\"author\\\\\": '\n",
       "                                        '\\\\\"Antoine Villatte\\\\\"}}, \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Merge and split\\\\\", \\\\\"outputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": \\\\\"output_edfcsv\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'merge_and_split(bucket, '\n",
       "                                        '\\\\n                    data_2015, '\n",
       "                                        '\\\\n                    data_2016, '\n",
       "                                        '\\\\n                    '\n",
       "                                        'output_edfcsv):\\\\n\\\\n    import '\n",
       "                                        'pandas as pd\\\\n    import re\\\\n    '\n",
       "                                        'import boto3\\\\n    from io import '\n",
       "                                        'StringIO\\\\n    from '\n",
       "                                        'sklearn.model_selection import '\n",
       "                                        'GroupShuffleSplit\\\\n\\\\n    def '\n",
       "                                        'get_location(text, method):\\\\n        '\n",
       "                                        '\\\\\"\\\\\"\\\\\"Retrieves data from the 2015 '\n",
       "                                        'dataset to harmonize it with the 2016 '\n",
       "                                        'dataset\\\\\"\\\\\"\\\\\"\\\\n        if method '\n",
       "                                        '== \\\\\"latitude\\\\\":\\\\n            '\n",
       "                                        'match = '\n",
       "                                        \"re.search('{\\\\\\\\'latitude\\\\\\\\': \"\n",
       "                                        \"\\\\\\\\'(.+?)\\\\\\\\', \\\\\\\\'longitude', \"\n",
       "                                        'text)\\\\n        elif method == '\n",
       "                                        '\\\\\"longitude\\\\\":\\\\n            match '\n",
       "                                        \"= re.search('[0-9]\\\\\\\\', \"\n",
       "                                        \"\\\\\\\\'longitude\\\\\\\\': \\\\\\\\'(.+?)\\\\\\\\', \"\n",
       "                                        \"\\\\\\\\'human_address\\\\\\\\'', \"\n",
       "                                        'text)\\\\n        elif method == '\n",
       "                                        '\\\\\"address\\\\\":\\\\n            match = '\n",
       "                                        're.search(\\'\\\\\\\\\\'{\\\\\"address\\\\\": '\n",
       "                                        '\\\\\"(.+?)\\\\\", \\\\\"city\\\\\":\\', '\n",
       "                                        'text)      \\\\n        elif method == '\n",
       "                                        '\\\\\"city\\\\\":\\\\n            match = '\n",
       "                                        're.search(\\'\\\\\", \\\\\"city\\\\\": '\n",
       "                                        '\\\\\"(.+?)\\\\\", \\\\\"state\\\\\":\\', '\n",
       "                                        'text)\\\\n        elif method == '\n",
       "                                        '\\\\\"state\\\\\":\\\\n            match = '\n",
       "                                        're.search(\\'\\\\\"state\\\\\": \\\\\"(.+?)\\\\\", '\n",
       "                                        '\\\\\"zip\\\\\":\\', text)\\\\n        elif '\n",
       "                                        'method == \\\\\"zip\\\\\":\\\\n            '\n",
       "                                        'match = re.search(\\'\\\\\"zip\\\\\": '\n",
       "                                        '\\\\\"(.+?)\\\\\"}\\\\\\\\\\'}\\', '\n",
       "                                        'text)\\\\n        else:\\\\n            '\n",
       "                                        'raise ValueError(\\\\\"Veuillez choisir '\n",
       "                                        'une méthode (latitude, longitude, '\n",
       "                                        'adress, city, state, '\n",
       "                                        'zip)\\\\\")\\\\n\\\\n        if '\n",
       "                                        'match:\\\\n            found = '\n",
       "                                        'match.group(1)\\\\n            '\n",
       "                                        'return(found)\\\\n        '\n",
       "                                        'return(\\\\\"N/A\\\\\")\\\\n\\\\n    # Load '\n",
       "                                        'datasets\\\\n    csv_strings = {}\\\\n    '\n",
       "                                        \"encoding = 'utf-8'\\\\n    for \"\n",
       "                                        'source_data, year in zip([data_2015, '\n",
       "                                        'data_2016], [\\\\\"2015\\\\\", '\n",
       "                                        '\\\\\"2016\\\\\"]):\\\\n        csv_obj = '\n",
       "                                        \"boto3.client('s3').get_object(Bucket=bucket, \"\n",
       "                                        'Key=source_data)\\\\n        body = '\n",
       "                                        \"csv_obj['Body']\\\\n        csv_string \"\n",
       "                                        '= '\n",
       "                                        'body.read().decode(encoding)\\\\n        '\n",
       "                                        'csv_strings[year] = '\n",
       "                                        'csv_string\\\\n\\\\n    data15 = '\n",
       "                                        'pd.read_csv(StringIO(csv_strings[\\\\\"2015\\\\\"]))\\\\n    '\n",
       "                                        'data16 = '\n",
       "                                        'pd.read_csv(StringIO(csv_strings[\\\\\"2016\\\\\"]))\\\\n\\\\n    '\n",
       "                                        '# Rename mismatched columns\\\\n    '\n",
       "                                        'rename_cols = {\\\\n        '\n",
       "                                        '\\\\\"GHGEmissions(MetricTonsCO2e)\\\\\" : '\n",
       "                                        '\\\\\"TotalGHGEmissions\\\\\",\\\\n        '\n",
       "                                        '\\\\\"GHGEmissionsIntensity(kgCO2e/ft2)\\\\\" '\n",
       "                                        ': '\n",
       "                                        '\\\\\"GHGEmissionsIntensity\\\\\",\\\\n        '\n",
       "                                        '\\\\\"Comment\\\\\" : \\\\\"Comments\\\\\"\\\\n    '\n",
       "                                        '}\\\\n    data15.rename(columns = '\n",
       "                                        'rename_cols, inplace = True)\\\\n\\\\n    '\n",
       "                                        '# Extract location info from 2015 '\n",
       "                                        'dataset to harmonize it\\\\n    '\n",
       "                                        'data15[\\\\\"Latitude\\\\\"] = '\n",
       "                                        'data15[\\\\\"Location\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\"latitude\\\\\")\\\\n    '\n",
       "                                        'data15[\\\\\"Longitude\\\\\"] = '\n",
       "                                        'data15[\\\\\"Location\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\"longitude\\\\\")\\\\n    '\n",
       "                                        'data15[\\\\\"Address\\\\\"] = '\n",
       "                                        'data15[\\\\\"Location\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\"address\\\\\")\\\\n    '\n",
       "                                        'data15[\\\\\"City\\\\\"] = '\n",
       "                                        'data15[\\\\\"Location\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\"city\\\\\")\\\\n    '\n",
       "                                        'data15[\\\\\"State\\\\\"] = '\n",
       "                                        'data15[\\\\\"Location\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\"state\\\\\")\\\\n    '\n",
       "                                        'data15[\\\\\"ZipCode\\\\\"] = '\n",
       "                                        'data15[\\\\\"Location\\\\\"].apply(get_location, '\n",
       "                                        'method = \\\\\"zip\\\\\")\\\\n    '\n",
       "                                        'data15[\\\\\"ZipCode\\\\\"] = '\n",
       "                                        'data15[\\\\\"ZipCode\\\\\"].astype(int) # '\n",
       "                                        'convert to numeric\\\\n    '\n",
       "                                        'data15.drop(columns = \\\\\"Location\\\\\", '\n",
       "                                        'inplace = True)\\\\n\\\\n    # Delete '\n",
       "                                        'columns from data15 that arent in '\n",
       "                                        'data16\\\\n    data15.drop(columns = '\n",
       "                                        'set(data15.columns.tolist()).difference(data16.columns.tolist()), '\n",
       "                                        'inplace = True)\\\\n\\\\n    # Harmonize '\n",
       "                                        'column order\\\\n    cols_order = '\n",
       "                                        'data16.columns.tolist()\\\\n    data15 '\n",
       "                                        '= data15.loc[:, cols_order]\\\\n\\\\n    '\n",
       "                                        '# Concatenate\\\\n    emission_df = '\n",
       "                                        'pd.concat([data15, data16], axis = 0, '\n",
       "                                        'ignore_index = True)\\\\n\\\\n    # '\n",
       "                                        'Train/test split\\\\n    inTrain , '\n",
       "                                        'inTest = '\n",
       "                                        'next(GroupShuffleSplit(train_size = '\n",
       "                                        '0.7, random_state = '\n",
       "                                        '42).\\\\\\\\\\\\n                        '\n",
       "                                        'split(emission_df, groups = '\n",
       "                                        'emission_df[\\\\\"OSEBuildingID\\\\\"]))\\\\n\\\\n    '\n",
       "                                        'emission_df[\\\\\"in_train\\\\\"] = 0\\\\n    '\n",
       "                                        'emission_df.iloc[inTrain, 46] = '\n",
       "                                        '1\\\\n\\\\n    '\n",
       "                                        'emission_df.to_csv(output_edfcsv, '\n",
       "                                        'index=False)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Merge \"\n",
       "                                        \"and split', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--bucket\\\\\", '\n",
       "                                        'dest=\\\\\"bucket\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--data-2015\\\\\", '\n",
       "                                        'dest=\\\\\"data_2015\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--data-2016\\\\\", '\n",
       "                                        'dest=\\\\\"data_2016\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-edfcsv\\\\\", '\n",
       "                                        'dest=\\\\\"output_edfcsv\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'merge_and_split(**_parsed_args)\\\\n\"],\"args\":[\"--bucket\",\"{{inputs.parameters.bucket}}\",\"--data-2015\",\"{{inputs.parameters.data_2015}}\",\"--data-2016\",\"{{inputs.parameters.data_2016}}\",\"--output-edfcsv\",\"/tmp/outputs/output_edfcsv/data\"],\"resources\":{}}},{\"name\":\"model-predict\",\"inputs\":{\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"path\":\"/tmp/inputs/input_X_predict_csv/data\"},{\"name\":\"train-best-model-output_pickle_model\",\"path\":\"/tmp/inputs/input_model_pickle/data\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"model-predict-output_prediction_csv\",\"path\":\"/tmp/outputs/output_prediction_csv/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"f4721521d1bbab4a9793e687253d927d5360eb52b40b3cc66b4940bd464dffbe\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/model_predict_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--input-model-pickle\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_model_pickle\\\\\"}, '\n",
       "                                        '\\\\\"--input-X-predict-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_X_predict_csv\\\\\"}, '\n",
       "                                        '\\\\\"--output-prediction-csv\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_prediction_csv\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'model_predict(input_model_pickle, '\n",
       "                                        '\\\\\\\\n                  '\n",
       "                                        'input_X_predict_csv,\\\\\\\\n                  '\n",
       "                                        'output_prediction_csv):\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'import pandas as pd\\\\\\\\n    import '\n",
       "                                        'pickle\\\\\\\\n    import numpy as '\n",
       "                                        'np\\\\\\\\n\\\\\\\\n    with '\n",
       "                                        \"open(input_model_pickle, 'rb') as \"\n",
       "                                        'file:\\\\\\\\n        modfit = '\n",
       "                                        'pickle.load(file)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'X_predict = '\n",
       "                                        'pd.read_csv(input_X_predict_csv)\\\\\\\\n    '\n",
       "                                        'predictions = '\n",
       "                                        'modfit.predict(X_predict)\\\\\\\\n    '\n",
       "                                        'predictions = np.exp(predictions) - '\n",
       "                                        '1\\\\\\\\n\\\\\\\\n    predictions_df = '\n",
       "                                        'pd.DataFrame()\\\\\\\\n    '\n",
       "                                        'predictions_df[\\\\\\\\\\\\\"y_pred\\\\\\\\\\\\\"] '\n",
       "                                        '= predictions\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'predictions_df.to_csv(output_prediction_csv)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Model \"\n",
       "                                        \"predict', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-model-pickle\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_model_pickle\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-X-predict-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_X_predict_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-prediction-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_prediction_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'model_predict(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_model_pickle\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Pickle\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_X_predict_csv\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"CSV\\\\\"}], '\n",
       "                                        '\\\\\"metadata\\\\\": {\\\\\"annotations\\\\\": '\n",
       "                                        '{\\\\\"author\\\\\": \\\\\"Antoine '\n",
       "                                        'Villatte\\\\\"}}, \\\\\"name\\\\\": \\\\\"Model '\n",
       "                                        'predict\\\\\", \\\\\"outputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"output_prediction_csv\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'model_predict(input_model_pickle, '\n",
       "                                        '\\\\n                  '\n",
       "                                        'input_X_predict_csv,\\\\n                  '\n",
       "                                        'output_prediction_csv):\\\\n\\\\n    '\n",
       "                                        'import pandas as pd\\\\n    import '\n",
       "                                        'pickle\\\\n    import numpy as '\n",
       "                                        'np\\\\n\\\\n    with '\n",
       "                                        \"open(input_model_pickle, 'rb') as \"\n",
       "                                        'file:\\\\n        modfit = '\n",
       "                                        'pickle.load(file)\\\\n\\\\n    X_predict '\n",
       "                                        '= '\n",
       "                                        'pd.read_csv(input_X_predict_csv)\\\\n    '\n",
       "                                        'predictions = '\n",
       "                                        'modfit.predict(X_predict)\\\\n    '\n",
       "                                        'predictions = np.exp(predictions) - '\n",
       "                                        '1\\\\n\\\\n    predictions_df = '\n",
       "                                        'pd.DataFrame()\\\\n    '\n",
       "                                        'predictions_df[\\\\\"y_pred\\\\\"] = '\n",
       "                                        'predictions\\\\n\\\\n    '\n",
       "                                        'predictions_df.to_csv(output_prediction_csv)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Model \"\n",
       "                                        \"predict', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--input-model-pickle\\\\\", '\n",
       "                                        'dest=\\\\\"input_model_pickle\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-X-predict-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_X_predict_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-prediction-csv\\\\\", '\n",
       "                                        'dest=\\\\\"output_prediction_csv\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'model_predict(**_parsed_args)\\\\n\"],\"args\":[\"--input-model-pickle\",\"/tmp/inputs/input_model_pickle/data\",\"--input-X-predict-csv\",\"/tmp/inputs/input_X_predict_csv/data\",\"--output-prediction-csv\",\"/tmp/outputs/output_prediction_csv/data\"],\"resources\":{}}},{\"name\":\"prepare-data\",\"inputs\":{\"artifacts\":[{\"name\":\"preprocess-dataset-output_cleandatacsv\",\"path\":\"/tmp/inputs/input_cleandatacsv/data\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"path\":\"/tmp/outputs/output_xtestcsv/data\"},{\"name\":\"prepare-data-output_xtraincsv\",\"path\":\"/tmp/outputs/output_xtraincsv/data\"},{\"name\":\"prepare-data-output_ytestcsv\",\"path\":\"/tmp/outputs/output_ytestcsv/data\"},{\"name\":\"prepare-data-output_ytraincsv\",\"path\":\"/tmp/outputs/output_ytraincsv/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"9e63df7ee17b6e48d63b5ff6f40c06f9af81e0c2f4add240f355524c53c1219a\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/prepare_data_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--input-cleandatacsv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_cleandatacsv\\\\\"}, '\n",
       "                                        '\\\\\"--output-xtraincsv\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_xtraincsv\\\\\"}, '\n",
       "                                        '\\\\\"--output-ytraincsv\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_ytraincsv\\\\\"}, '\n",
       "                                        '\\\\\"--output-xtestcsv\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_xtestcsv\\\\\"}, '\n",
       "                                        '\\\\\"--output-ytestcsv\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_ytestcsv\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'prepare_data(input_cleandatacsv,\\\\\\\\n                '\n",
       "                                        'output_xtraincsv,\\\\\\\\n                '\n",
       "                                        'output_ytraincsv,\\\\\\\\n                '\n",
       "                                        'output_xtestcsv,\\\\\\\\n                '\n",
       "                                        'output_ytestcsv):\\\\\\\\n\\\\\\\\n    import '\n",
       "                                        'numpy as np\\\\\\\\n    import pandas as '\n",
       "                                        'pd\\\\\\\\n    from sklearn.preprocessing '\n",
       "                                        'import StandardScaler, '\n",
       "                                        'OneHotEncoder\\\\\\\\n\\\\\\\\n    clean_data '\n",
       "                                        '= '\n",
       "                                        'pd.read_csv(input_cleandatacsv)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Numeric / categorical '\n",
       "                                        'separation\\\\\\\\n    numcols = '\n",
       "                                        'clean_data.select_dtypes(include = '\n",
       "                                        'np.number).columns\\\\\\\\n    catcols = '\n",
       "                                        'list(set(clean_data.columns) - '\n",
       "                                        'set(numcols))\\\\\\\\n    othercols = '\n",
       "                                        '[\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"SiteEnergyUse(kBtu)\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"TotalGHGEmissions\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"BCResponse\\\\\\\\\\\\\"]\\\\\\\\n    '\n",
       "                                        'numcols = [feature for feature in '\n",
       "                                        'numcols.tolist() if feature not in '\n",
       "                                        'othercols]\\\\\\\\n\\\\\\\\n    num_data = '\n",
       "                                        'clean_data.loc[:, numcols]\\\\\\\\n    '\n",
       "                                        'cat_data = clean_data.loc[:, '\n",
       "                                        'catcols]\\\\\\\\n    rest_data = '\n",
       "                                        'clean_data.loc[:, '\n",
       "                                        'othercols]\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Normalize\\\\\\\\n    standardscaler = '\n",
       "                                        'StandardScaler()\\\\\\\\n    num_data = '\n",
       "                                        'standardscaler.fit_transform(num_data)\\\\\\\\n    '\n",
       "                                        'num_data = pd.DataFrame(num_data, '\n",
       "                                        'columns = numcols)\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Delete outliers\\\\\\\\n    not_extreme = '\n",
       "                                        '(num_data.lt(3).all(axis = 1)) '\n",
       "                                        '\\\\u0026 (num_data.gt(-3).all(axis = '\n",
       "                                        '1))\\\\\\\\n    for index in '\n",
       "                                        'range(len(not_extreme)):\\\\\\\\n        '\n",
       "                                        'if rest_data.loc[:, '\n",
       "                                        '\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\"].iloc[index] '\n",
       "                                        '== 0:\\\\\\\\n            '\n",
       "                                        'not_extreme[index] = '\n",
       "                                        'True\\\\\\\\n\\\\\\\\n    # Encode '\n",
       "                                        'categorical variables\\\\\\\\n    '\n",
       "                                        'ohencoder = OneHotEncoder()\\\\\\\\n    '\n",
       "                                        'ohecat_data = '\n",
       "                                        'ohencoder.fit_transform(cat_data).toarray()\\\\\\\\n    '\n",
       "                                        'ohecat_colnames = []\\\\\\\\n    for '\n",
       "                                        'feature in catcols:\\\\\\\\n        for '\n",
       "                                        'value in '\n",
       "                                        'clean_data[feature].unique().tolist():\\\\\\\\n            '\n",
       "                                        'ohecat_colnames.append(feature + '\n",
       "                                        '\\\\\\\\\\\\\"_\\\\\\\\\\\\\" + value)\\\\\\\\n    '\n",
       "                                        'ohecat_data = '\n",
       "                                        'pd.DataFrame(ohecat_data, columns = '\n",
       "                                        'ohecat_colnames)\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Remove sparse dummies \\\\\\\\n    '\n",
       "                                        'ohecat_data = ohecat_data.loc[:, '\n",
       "                                        'ohecat_data.sum().ge(30)]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Concatenate\\\\\\\\n    preproc_data = '\n",
       "                                        'pd.concat([rest_data, num_data, '\n",
       "                                        'ohecat_data], axis = 1)\\\\\\\\n    '\n",
       "                                        'preproc_data = '\n",
       "                                        'preproc_data.loc[not_extreme, '\n",
       "                                        ':]\\\\\\\\n    rest_data = '\n",
       "                                        'rest_data.loc[not_extreme, '\n",
       "                                        ':]\\\\\\\\n\\\\\\\\n    # train-test '\n",
       "                                        'split\\\\\\\\n    train = '\n",
       "                                        'preproc_data.loc[preproc_data[\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\"] '\n",
       "                                        '== 1, :].drop(columns = '\n",
       "                                        '\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\")\\\\\\\\n    test '\n",
       "                                        '= '\n",
       "                                        'preproc_data.loc[preproc_data[\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\"] '\n",
       "                                        '== 0, :].drop(columns = '\n",
       "                                        '\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\")\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'train = train.drop(columns = '\n",
       "                                        '[\\\\\\\\\\\\\"TotalGHGEmissions\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"SiteEnergyUse(kBtu)\\\\\\\\\\\\\"])\\\\\\\\n    '\n",
       "                                        'test = test.drop(columns = '\n",
       "                                        '[\\\\\\\\\\\\\"TotalGHGEmissions\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"SiteEnergyUse(kBtu)\\\\\\\\\\\\\"])\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Separate features from '\n",
       "                                        'preds\\\\\\\\n    X_train = '\n",
       "                                        'train.drop(columns = '\n",
       "                                        '\\\\\\\\\\\\\"BCResponse\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'Y_train = '\n",
       "                                        'train[\\\\\\\\\\\\\"BCResponse\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'X_test = test.drop(columns = '\n",
       "                                        '\\\\\\\\\\\\\"BCResponse\\\\\\\\\\\\\")\\\\\\\\n    '\n",
       "                                        'Y_test = '\n",
       "                                        'test[\\\\\\\\\\\\\"BCResponse\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Save files \\\\\\\\n    '\n",
       "                                        'output_artifact_list = '\n",
       "                                        '[output_xtraincsv, output_ytraincsv, '\n",
       "                                        'output_xtestcsv, '\n",
       "                                        'output_ytestcsv]\\\\\\\\n\\\\\\\\n    for '\n",
       "                                        'index, dataset in enumerate([X_train, '\n",
       "                                        'Y_train, X_test, '\n",
       "                                        'Y_test]):\\\\\\\\n        artif = '\n",
       "                                        'output_artifact_list[index]\\\\\\\\n        '\n",
       "                                        'dataset.to_csv(artif, index = False, '\n",
       "                                        'header = True)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Prepare \"\n",
       "                                        \"data', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-cleandatacsv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_cleandatacsv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-xtraincsv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_xtraincsv\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-ytraincsv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_ytraincsv\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-xtestcsv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_xtestcsv\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-ytestcsv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_ytestcsv\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'prepare_data(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_cleandatacsv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}], \\\\\"metadata\\\\\": '\n",
       "                                        '{\\\\\"annotations\\\\\": {\\\\\"author\\\\\": '\n",
       "                                        '\\\\\"Antoine Villatte\\\\\"}}, \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Prepare data\\\\\", \\\\\"outputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": \\\\\"output_xtraincsv\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"output_ytraincsv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"output_xtestcsv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"output_ytestcsv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'prepare_data(input_cleandatacsv,\\\\n                '\n",
       "                                        'output_xtraincsv,\\\\n                '\n",
       "                                        'output_ytraincsv,\\\\n                '\n",
       "                                        'output_xtestcsv,\\\\n                '\n",
       "                                        'output_ytestcsv):\\\\n\\\\n    import '\n",
       "                                        'numpy as np\\\\n    import pandas as '\n",
       "                                        'pd\\\\n    from sklearn.preprocessing '\n",
       "                                        'import StandardScaler, '\n",
       "                                        'OneHotEncoder\\\\n\\\\n    clean_data = '\n",
       "                                        'pd.read_csv(input_cleandatacsv)\\\\n\\\\n    '\n",
       "                                        '# Numeric / categorical '\n",
       "                                        'separation\\\\n    numcols = '\n",
       "                                        'clean_data.select_dtypes(include = '\n",
       "                                        'np.number).columns\\\\n    catcols = '\n",
       "                                        'list(set(clean_data.columns) - '\n",
       "                                        'set(numcols))\\\\n    othercols = '\n",
       "                                        '[\\\\\"in_train\\\\\", '\n",
       "                                        '\\\\\"SiteEnergyUse(kBtu)\\\\\", '\n",
       "                                        '\\\\\"TotalGHGEmissions\\\\\", '\n",
       "                                        '\\\\\"BCResponse\\\\\"]\\\\n    numcols = '\n",
       "                                        '[feature for feature in '\n",
       "                                        'numcols.tolist() if feature not in '\n",
       "                                        'othercols]\\\\n\\\\n    num_data = '\n",
       "                                        'clean_data.loc[:, numcols]\\\\n    '\n",
       "                                        'cat_data = clean_data.loc[:, '\n",
       "                                        'catcols]\\\\n    rest_data = '\n",
       "                                        'clean_data.loc[:, othercols]\\\\n\\\\n    '\n",
       "                                        '# Normalize\\\\n    standardscaler = '\n",
       "                                        'StandardScaler()\\\\n    num_data = '\n",
       "                                        'standardscaler.fit_transform(num_data)\\\\n    '\n",
       "                                        'num_data = pd.DataFrame(num_data, '\n",
       "                                        'columns = numcols)\\\\n\\\\n    # Delete '\n",
       "                                        'outliers\\\\n    not_extreme = '\n",
       "                                        '(num_data.lt(3).all(axis = 1)) '\n",
       "                                        '\\\\u0026 (num_data.gt(-3).all(axis = '\n",
       "                                        '1))\\\\n    for index in '\n",
       "                                        'range(len(not_extreme)):\\\\n        if '\n",
       "                                        'rest_data.loc[:, '\n",
       "                                        '\\\\\"in_train\\\\\"].iloc[index] == '\n",
       "                                        '0:\\\\n            not_extreme[index] = '\n",
       "                                        'True\\\\n\\\\n    # Encode categorical '\n",
       "                                        'variables\\\\n    ohencoder = '\n",
       "                                        'OneHotEncoder()\\\\n    ohecat_data = '\n",
       "                                        'ohencoder.fit_transform(cat_data).toarray()\\\\n    '\n",
       "                                        'ohecat_colnames = []\\\\n    for '\n",
       "                                        'feature in catcols:\\\\n        for '\n",
       "                                        'value in '\n",
       "                                        'clean_data[feature].unique().tolist():\\\\n            '\n",
       "                                        'ohecat_colnames.append(feature + '\n",
       "                                        '\\\\\"_\\\\\" + value)\\\\n    ohecat_data = '\n",
       "                                        'pd.DataFrame(ohecat_data, columns = '\n",
       "                                        'ohecat_colnames)\\\\n\\\\n    # Remove '\n",
       "                                        'sparse dummies \\\\n    ohecat_data = '\n",
       "                                        'ohecat_data.loc[:, '\n",
       "                                        'ohecat_data.sum().ge(30)]\\\\n\\\\n    # '\n",
       "                                        'Concatenate\\\\n    preproc_data = '\n",
       "                                        'pd.concat([rest_data, num_data, '\n",
       "                                        'ohecat_data], axis = 1)\\\\n    '\n",
       "                                        'preproc_data = '\n",
       "                                        'preproc_data.loc[not_extreme, '\n",
       "                                        ':]\\\\n    rest_data = '\n",
       "                                        'rest_data.loc[not_extreme, '\n",
       "                                        ':]\\\\n\\\\n    # train-test split\\\\n    '\n",
       "                                        'train = '\n",
       "                                        'preproc_data.loc[preproc_data[\\\\\"in_train\\\\\"] '\n",
       "                                        '== 1, :].drop(columns = '\n",
       "                                        '\\\\\"in_train\\\\\")\\\\n    test = '\n",
       "                                        'preproc_data.loc[preproc_data[\\\\\"in_train\\\\\"] '\n",
       "                                        '== 0, :].drop(columns = '\n",
       "                                        '\\\\\"in_train\\\\\")\\\\n\\\\n    train = '\n",
       "                                        'train.drop(columns = '\n",
       "                                        '[\\\\\"TotalGHGEmissions\\\\\", '\n",
       "                                        '\\\\\"SiteEnergyUse(kBtu)\\\\\"])\\\\n    '\n",
       "                                        'test = test.drop(columns = '\n",
       "                                        '[\\\\\"TotalGHGEmissions\\\\\", '\n",
       "                                        '\\\\\"SiteEnergyUse(kBtu)\\\\\"])\\\\n\\\\n    '\n",
       "                                        '# Separate features from preds\\\\n    '\n",
       "                                        'X_train = train.drop(columns = '\n",
       "                                        '\\\\\"BCResponse\\\\\")\\\\n    Y_train = '\n",
       "                                        'train[\\\\\"BCResponse\\\\\"]\\\\n\\\\n    '\n",
       "                                        'X_test = test.drop(columns = '\n",
       "                                        '\\\\\"BCResponse\\\\\")\\\\n    Y_test = '\n",
       "                                        'test[\\\\\"BCResponse\\\\\"]\\\\n\\\\n    # '\n",
       "                                        'Save files \\\\n    '\n",
       "                                        'output_artifact_list = '\n",
       "                                        '[output_xtraincsv, output_ytraincsv, '\n",
       "                                        'output_xtestcsv, '\n",
       "                                        'output_ytestcsv]\\\\n\\\\n    for index, '\n",
       "                                        'dataset in enumerate([X_train, '\n",
       "                                        'Y_train, X_test, Y_test]):\\\\n        '\n",
       "                                        'artif = '\n",
       "                                        'output_artifact_list[index]\\\\n        '\n",
       "                                        'dataset.to_csv(artif, index = False, '\n",
       "                                        'header = True)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Prepare \"\n",
       "                                        \"data', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--input-cleandatacsv\\\\\", '\n",
       "                                        'dest=\\\\\"input_cleandatacsv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-xtraincsv\\\\\", '\n",
       "                                        'dest=\\\\\"output_xtraincsv\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-ytraincsv\\\\\", '\n",
       "                                        'dest=\\\\\"output_ytraincsv\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-xtestcsv\\\\\", '\n",
       "                                        'dest=\\\\\"output_xtestcsv\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-ytestcsv\\\\\", '\n",
       "                                        'dest=\\\\\"output_ytestcsv\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'prepare_data(**_parsed_args)\\\\n\"],\"args\":[\"--input-cleandatacsv\",\"/tmp/inputs/input_cleandatacsv/data\",\"--output-xtraincsv\",\"/tmp/outputs/output_xtraincsv/data\",\"--output-ytraincsv\",\"/tmp/outputs/output_ytraincsv/data\",\"--output-xtestcsv\",\"/tmp/outputs/output_xtestcsv/data\",\"--output-ytestcsv\",\"/tmp/outputs/output_ytestcsv/data\"],\"resources\":{}}},{\"name\":\"preprocess-dataset\",\"inputs\":{\"artifacts\":[{\"name\":\"merge-and-split-output_edfcsv\",\"path\":\"/tmp/inputs/input_edfcsv/data\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"preprocess-dataset-output_cleandatacsv\",\"path\":\"/tmp/outputs/output_cleandatacsv/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"6be827e49ca000f6859aab5a8eb8a9b3dc9fbadb99b7c003887361dc625f2a39\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/preprocess_dataset_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--input-edfcsv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_edfcsv\\\\\"}, '\n",
       "                                        '\\\\\"--output-cleandatacsv\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_cleandatacsv\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'preprocess_dataset(input_edfcsv,\\\\\\\\n                        '\n",
       "                                        'output_cleandatacsv):\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'import pandas as pd\\\\\\\\n    import '\n",
       "                                        'numpy as np\\\\\\\\n    from scipy.stats '\n",
       "                                        'import boxcox\\\\\\\\n    import '\n",
       "                                        're\\\\\\\\n    import math\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'def count_commas(text):\\\\\\\\n        '\n",
       "                                        '\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"Fonction '\n",
       "                                        'text.count(\\\\\\\\\\\\\",\\\\\\\\\\\\\") sachant '\n",
       "                                        'g\\\\\\\\u00e9rer les '\n",
       "                                        'nan\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\\\\\\"\\\\\\\\n        '\n",
       "                                        'if type(text) is str '\n",
       "                                        ':\\\\\\\\n            '\n",
       "                                        'return(text.count(\\\\\\\\\\\\\",\\\\\\\\\\\\\") + '\n",
       "                                        '1)\\\\\\\\n        else :\\\\\\\\n            '\n",
       "                                        'if '\n",
       "                                        'np.isnan(text):\\\\\\\\n                '\n",
       "                                        'return(np.nan)\\\\\\\\n            else '\n",
       "                                        ':\\\\\\\\n                '\n",
       "                                        'raise(TypeError(\\\\\\\\\\\\\"Valeur non '\n",
       "                                        'textuelle et non NA '\n",
       "                                        'observ\\\\\\\\u00e9e\\\\\\\\\\\\\"))\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'def fetch_noFloors(emission_df, '\n",
       "                                        'neighborhood, '\n",
       "                                        'property_type):\\\\\\\\n        '\n",
       "                                        'neighb_prop_pivot_table = '\n",
       "                                        'emission_df.dropna().loc[emission_df[\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\"] '\n",
       "                                        '== 1, '\n",
       "                                        ':].pivot_table(\\\\\\\\\\\\\"NumberofFloors\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                                                                   '\n",
       "                                        'index = \\\\\\\\\\\\\"Neighborhood\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                                                                   '\n",
       "                                        'columns = '\n",
       "                                        '\\\\\\\\\\\\\"PrimaryPropertyType\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                                                                   '\n",
       "                                        'aggfunc = lambda X: '\n",
       "                                        'X.quantile(0.5))\\\\\\\\n        output = '\n",
       "                                        'neighb_prop_pivot_table.loc[neighborhood, '\n",
       "                                        'property_type]\\\\\\\\n        if '\n",
       "                                        'math.isnan(output):\\\\\\\\n            '\n",
       "                                        'print(\\\\\\\\\\\\\"Pas de donn\\\\\\\\u00e9es '\n",
       "                                        'pour ce type de b\\\\\\\\u00e2timent dans '\n",
       "                                        'ce voisinage, extraction de la '\n",
       "                                        'm\\\\\\\\u00e9diane '\n",
       "                                        'globale\\\\\\\\\\\\\")\\\\\\\\n            '\n",
       "                                        'output = '\n",
       "                                        'round(neighb_prop_pivot_table.loc[:, '\n",
       "                                        'property_type].quantile(0.5),0)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'return(output)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'emission_df = '\n",
       "                                        'pd.read_csv(input_edfcsv)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Log of response variable\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"BCResponse\\\\\\\\\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'boxcox(emission_df[\\\\\\\\\\\\\"TotalGHGEmissions\\\\\\\\\\\\\"] '\n",
       "                                        '+ 1, -0.1)\\\\\\\\n\\\\\\\\n    # Fill '\n",
       "                                        'NAs\\\\\\\\n        ## Impute '\n",
       "                                        'SecondLargestPropertyUseType\\\\\\\\n    '\n",
       "                                        'emission_df.loc[(emission_df[\\\\\\\\\\\\\"SecondLargestPropertyUseType\\\\\\\\\\\\\"].isna()) '\n",
       "                                        '\\\\u0026 '\n",
       "                                        '(~emission_df[\\\\\\\\\\\\\"ListOfAllPropertyUseTypes\\\\\\\\\\\\\"].isna()), '\n",
       "                                        '\\\\\\\\n                    '\n",
       "                                        '\\\\\\\\\\\\\"SecondLargestPropertyUseType\\\\\\\\\\\\\"] '\n",
       "                                        '= \\\\\\\\\\\\\"None\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        '\n",
       "                                        '## Impute '\n",
       "                                        'SecondLargestPropertyUseTypeGFA\\\\\\\\n    '\n",
       "                                        'emission_df.loc[(emission_df[\\\\\\\\\\\\\"SecondLargestPropertyUseTypeGFA\\\\\\\\\\\\\"].isna()) '\n",
       "                                        '\\\\u0026 '\n",
       "                                        '(~emission_df[\\\\\\\\\\\\\"ListOfAllPropertyUseTypes\\\\\\\\\\\\\"].isna()), '\n",
       "                                        '\\\\\\\\n                    '\n",
       "                                        '\\\\\\\\\\\\\"SecondLargestPropertyUseTypeGFA\\\\\\\\\\\\\"] '\n",
       "                                        '= 0\\\\\\\\n\\\\\\\\n        ## Impute '\n",
       "                                        'ThirdLargestPropertyUseType\\\\\\\\n    '\n",
       "                                        'emission_df.loc[(emission_df[\\\\\\\\\\\\\"ThirdLargestPropertyUseType\\\\\\\\\\\\\"].isna()) '\n",
       "                                        '\\\\u0026 '\n",
       "                                        '(~emission_df[\\\\\\\\\\\\\"ListOfAllPropertyUseTypes\\\\\\\\\\\\\"].isna()), '\n",
       "                                        '\\\\\\\\n                    '\n",
       "                                        '\\\\\\\\\\\\\"ThirdLargestPropertyUseType\\\\\\\\\\\\\"] '\n",
       "                                        '= \\\\\\\\\\\\\"None\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n        '\n",
       "                                        '## Impute '\n",
       "                                        'ThirdLargestPropertyUseTypeGFA\\\\\\\\n    '\n",
       "                                        'emission_df.loc[(emission_df[\\\\\\\\\\\\\"ThirdLargestPropertyUseTypeGFA\\\\\\\\\\\\\"].isna()) '\n",
       "                                        '\\\\u0026 '\n",
       "                                        '(~emission_df[\\\\\\\\\\\\\"ListOfAllPropertyUseTypes\\\\\\\\\\\\\"].isna()), '\n",
       "                                        '\\\\\\\\n                    '\n",
       "                                        '\\\\\\\\\\\\\"ThirdLargestPropertyUseTypeGFA\\\\\\\\\\\\\"] '\n",
       "                                        '= 0\\\\\\\\n\\\\\\\\n    # Drop columns with '\n",
       "                                        'too many NaNs\\\\\\\\n    '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        '[\\\\\\\\\\\\\"YearsENERGYSTARCertified\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"Comments\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"Outlier\\\\\\\\\\\\\"], inplace = '\n",
       "                                        'True)\\\\\\\\n\\\\\\\\n    # Only keep non '\n",
       "                                        'residential buildings\\\\\\\\n    '\n",
       "                                        'emission_df = '\n",
       "                                        'emission_df.loc[emission_df[\\\\\\\\\\\\\"BuildingType\\\\\\\\\\\\\"].apply(lambda '\n",
       "                                        'X: '\n",
       "                                        'bool(re.search(\\\\\\\\\\\\\"^[Nn]on[Rr]esidential\\\\\\\\\\\\\", '\n",
       "                                        'X))), :]\\\\\\\\n    # Drop Building '\n",
       "                                        'Type\\\\\\\\n    emission_df.drop(columns '\n",
       "                                        '= \\\\\\\\\\\\\"BuildingType\\\\\\\\\\\\\", inplace '\n",
       "                                        '= True)\\\\\\\\n\\\\\\\\n    # Drop '\n",
       "                                        'low-impact location variables\\\\\\\\n    '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        '[\\\\\\\\\\\\\"Address\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"City\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"State\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"ZipCode\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"TaxParcelIdentificationNumber\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"CouncilDistrictCode\\\\\\\\\\\\\"], '\n",
       "                                        '\\\\\\\\n                    inplace = '\n",
       "                                        'True)\\\\\\\\n\\\\\\\\n    # Drop ID '\n",
       "                                        'variables\\\\\\\\n    '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        '[\\\\\\\\\\\\\"OSEBuildingID\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"PropertyName\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"DefaultData\\\\\\\\\\\\\"], inplace = '\n",
       "                                        'True)\\\\\\\\n\\\\\\\\n    # Reset '\n",
       "                                        'index\\\\\\\\n    '\n",
       "                                        'emission_df.reset_index(inplace = '\n",
       "                                        'True, drop = True)\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Drop variables too highly correlated '\n",
       "                                        'to the reponse variable\\\\\\\\n    '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        \"['SiteEUIWN(kBtu/sf)', \"\n",
       "                                        \"'SourceEUI(kBtu/sf)', \"\n",
       "                                        \"'SourceEUIWN(kBtu/sf)',\\\\\\\\n                                \"\n",
       "                                        \"'SiteEnergyUseWN(kBtu)', \"\n",
       "                                        \"'Electricity(kWh)', \"\n",
       "                                        \"'NaturalGas(therms)', \"\n",
       "                                        '\\\\\\\\n                                '\n",
       "                                        '\\\\\\\\\\\\\"SiteEUI(kBtu/sf)\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"GHGEmissionsIntensity\\\\\\\\\\\\\"], '\n",
       "                                        'inplace = True)\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Feature engineering : neighborhood '\n",
       "                                        'type\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"Neighborhood_type_GHGE\\\\\\\\\\\\\"] '\n",
       "                                        '= \\\\\\\\\\\\\"med-low\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'emission_df.loc[emission_df[\\\\\\\\\\\\\"Neighborhood\\\\\\\\\\\\\"].isin([\\\\\\\\\\\\\"GREATER '\n",
       "                                        'DUWAMISH\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"SOUTHEAST\\\\\\\\\\\\\"]), '\n",
       "                                        '\\\\\\\\\\\\\"Neighborhood_type_GHGE\\\\\\\\\\\\\"] '\n",
       "                                        '= \\\\\\\\\\\\\"low\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'emission_df.loc[emission_df[\\\\\\\\\\\\\"Neighborhood\\\\\\\\\\\\\"].isin([\\\\\\\\\\\\\"NORTHEAST\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"MAGNOLIA / QUEEN ANNE\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"SOUTHWEST\\\\\\\\\\\\\", \\\\\\\\\\\\\"LAKE '\n",
       "                                        'UNION\\\\\\\\\\\\\"]), '\n",
       "                                        '\\\\\\\\n                    '\n",
       "                                        '\\\\\\\\\\\\\"Neighborhood_type_GHGE\\\\\\\\\\\\\"] '\n",
       "                                        '= \\\\\\\\\\\\\"med-high\\\\\\\\\\\\\"\\\\\\\\n    '\n",
       "                                        'emission_df.loc[emission_df[\\\\\\\\\\\\\"Neighborhood\\\\\\\\\\\\\"].isin([\\\\\\\\\\\\\"DOWNTOWN\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"EAST\\\\\\\\\\\\\"]), '\n",
       "                                        '\\\\\\\\\\\\\"Neighborhood_type_GHGE\\\\\\\\\\\\\"] '\n",
       "                                        '= \\\\\\\\\\\\\"high\\\\\\\\\\\\\"\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'Feature engineering : age\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"Age\\\\\\\\\\\\\"] = '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"DataYear\\\\\\\\\\\\\"] - '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"YearBuilt\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# FE : Number of use types\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"NumberOfUseTypes\\\\\\\\\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"ListOfAllPropertyUseTypes\\\\\\\\\\\\\"].apply(count_commas)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# FE : Proportion occupied by each '\n",
       "                                        'use\\\\\\\\n    three_uses_sum = '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"LargestPropertyUseTypeGFA\\\\\\\\\\\\\"] '\n",
       "                                        '+ '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"SecondLargestPropertyUseTypeGFA\\\\\\\\\\\\\"] '\n",
       "                                        '+ \\\\\\\\\\\\\\\\\\\\\\\\n                    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"ThirdLargestPropertyUseTypeGFA\\\\\\\\\\\\\"]\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"PrimaryUseGFARatio\\\\\\\\\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'round(emission_df[\\\\\\\\\\\\\"LargestPropertyUseTypeGFA\\\\\\\\\\\\\"] '\n",
       "                                        '/ three_uses_sum, 3)\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"SecondaryUseGFARatio\\\\\\\\\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'round(emission_df[\\\\\\\\\\\\\"SecondLargestPropertyUseTypeGFA\\\\\\\\\\\\\"] '\n",
       "                                        '/ three_uses_sum, 3)\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"TerciaryUseGFARatio\\\\\\\\\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'round(emission_df[\\\\\\\\\\\\\"ThirdLargestPropertyUseTypeGFA\\\\\\\\\\\\\"] '\n",
       "                                        '/ three_uses_sum, 3)\\\\\\\\n\\\\\\\\n    # '\n",
       "                                        'FE : proportion of each energy '\n",
       "                                        'use\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"NG_ratio\\\\\\\\\\\\\"] = '\n",
       "                                        'round(emission_df[\\\\\\\\\\\\\"NaturalGas(kBtu)\\\\\\\\\\\\\"] '\n",
       "                                        '/ '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"SiteEnergyUse(kBtu)\\\\\\\\\\\\\"], '\n",
       "                                        '3)\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"Elec_ratio\\\\\\\\\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'round(emission_df[\\\\\\\\\\\\\"Electricity(kBtu)\\\\\\\\\\\\\"] '\n",
       "                                        '/ '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"SiteEnergyUse(kBtu)\\\\\\\\\\\\\"], '\n",
       "                                        '3)\\\\\\\\n    '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"Steam_ratio\\\\\\\\\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'round(emission_df[\\\\\\\\\\\\\"SteamUse(kBtu)\\\\\\\\\\\\\"] '\n",
       "                                        '/ '\n",
       "                                        'emission_df[\\\\\\\\\\\\\"SiteEnergyUse(kBtu)\\\\\\\\\\\\\"], '\n",
       "                                        '3)\\\\\\\\n    emission_df.drop(index = '\n",
       "                                        '[780, 2781, 2027, 498, 1677], inplace '\n",
       "                                        '= True) # Impossible values\\\\\\\\n    '\n",
       "                                        'emission_df.reset_index(drop = True, '\n",
       "                                        'inplace = True)\\\\\\\\n\\\\\\\\n    # Drop '\n",
       "                                        'useless columns\\\\\\\\n    clean_data = '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        '[\\\\\\\\\\\\\"DataYear\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"Neighborhood\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"Longitude\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"Latitude\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"YearBuilt\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"PropertyGFATotal\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                                            '\n",
       "                                        '\\\\\\\\\\\\\"SteamUse(kBtu)\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"Electricity(kBtu)\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"NaturalGas(kBtu)\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"PrimaryPropertyType\\\\\\\\\\\\\"])\\\\\\\\n\\\\\\\\n    '\n",
       "                                        '# Drop NAs\\\\\\\\n    '\n",
       "                                        'clean_data.dropna(subset = '\n",
       "                                        '[\\\\\\\\\\\\\"LargestPropertyUseType\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"TotalGHGEmissions\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"NG_ratio\\\\\\\\\\\\\"], inplace = '\n",
       "                                        'True)\\\\\\\\n    '\n",
       "                                        'emission_df.dropna().loc[emission_df[\\\\\\\\\\\\\"in_train\\\\\\\\\\\\\"] '\n",
       "                                        '== 1, '\n",
       "                                        ':].pivot_table(\\\\\\\\\\\\\"NumberofFloors\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                                                                        '\n",
       "                                        'index = \\\\\\\\\\\\\"Neighborhood\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                                                                        '\n",
       "                                        'columns = '\n",
       "                                        '\\\\\\\\\\\\\"PrimaryPropertyType\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\n                                                                        '\n",
       "                                        'aggfunc = lambda X: '\n",
       "                                        'X.quantile(0.5))\\\\\\\\n\\\\\\\\n    # Fill '\n",
       "                                        'NAs\\\\\\\\n    for index in '\n",
       "                                        '(clean_data.loc[clean_data[\\\\\\\\\\\\\"NumberofFloors\\\\\\\\\\\\\"].isna(), '\n",
       "                                        '\\\\\\\\\\\\\"NumberofFloors\\\\\\\\\\\\\"]).index.tolist():\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'row_neighborhood = '\n",
       "                                        'emission_df.loc[emission_df.index == '\n",
       "                                        'index, '\n",
       "                                        '\\\\\\\\\\\\\"Neighborhood\\\\\\\\\\\\\"].at[index]\\\\\\\\n        '\n",
       "                                        'row_property_type = '\n",
       "                                        'emission_df.loc[emission_df.index == '\n",
       "                                        'index, '\n",
       "                                        '\\\\\\\\\\\\\"PrimaryPropertyType\\\\\\\\\\\\\"].at[index]\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'clean_data.loc[clean_data.index ==  '\n",
       "                                        'index, \\\\\\\\\\\\\"NumberofFloors\\\\\\\\\\\\\"] '\n",
       "                                        '= \\\\\\\\\\\\\\\\\\\\\\\\n            '\n",
       "                                        'fetch_noFloors(emission_df, '\n",
       "                                        'row_neighborhood, '\n",
       "                                        'row_property_type)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'clean_data.loc[clean_data[\\\\\\\\\\\\\"ENERGYSTARScore\\\\\\\\\\\\\"].isna(), '\n",
       "                                        '\\\\\\\\\\\\\"ENERGYSTARScore\\\\\\\\\\\\\"] = '\n",
       "                                        '0\\\\\\\\n    '\n",
       "                                        'clean_data.reset_index(inplace = '\n",
       "                                        'True, drop = True)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'clean_data.to_csv(output_cleandatacsv, '\n",
       "                                        'index=False)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Preprocess \"\n",
       "                                        \"dataset', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-edfcsv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_edfcsv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-cleandatacsv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_cleandatacsv\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'preprocess_dataset(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_edfcsv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}], \\\\\"metadata\\\\\": '\n",
       "                                        '{\\\\\"annotations\\\\\": {\\\\\"author\\\\\": '\n",
       "                                        '\\\\\"Antoine Villatte\\\\\"}}, \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Preprocess dataset\\\\\", '\n",
       "                                        '\\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"output_cleandatacsv\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'preprocess_dataset(input_edfcsv,\\\\n                        '\n",
       "                                        'output_cleandatacsv):\\\\n\\\\n    import '\n",
       "                                        'pandas as pd\\\\n    import numpy as '\n",
       "                                        'np\\\\n    from scipy.stats import '\n",
       "                                        'boxcox\\\\n    import re\\\\n    import '\n",
       "                                        'math\\\\n\\\\n    def '\n",
       "                                        'count_commas(text):\\\\n        '\n",
       "                                        '\\\\\"\\\\\"\\\\\"Fonction text.count(\\\\\",\\\\\") '\n",
       "                                        'sachant gérer les '\n",
       "                                        'nan\\\\\"\\\\\"\\\\\"\\\\n        if type(text) '\n",
       "                                        'is str :\\\\n            '\n",
       "                                        'return(text.count(\\\\\",\\\\\") + '\n",
       "                                        '1)\\\\n        else :\\\\n            if '\n",
       "                                        'np.isnan(text):\\\\n                '\n",
       "                                        'return(np.nan)\\\\n            else '\n",
       "                                        ':\\\\n                '\n",
       "                                        'raise(TypeError(\\\\\"Valeur non '\n",
       "                                        'textuelle et non NA '\n",
       "                                        'observée\\\\\"))\\\\n\\\\n    def '\n",
       "                                        'fetch_noFloors(emission_df, '\n",
       "                                        'neighborhood, '\n",
       "                                        'property_type):\\\\n        '\n",
       "                                        'neighb_prop_pivot_table = '\n",
       "                                        'emission_df.dropna().loc[emission_df[\\\\\"in_train\\\\\"] '\n",
       "                                        '== 1, '\n",
       "                                        ':].pivot_table(\\\\\"NumberofFloors\\\\\", '\n",
       "                                        '\\\\n                                                                   '\n",
       "                                        'index = \\\\\"Neighborhood\\\\\", '\n",
       "                                        '\\\\n                                                                   '\n",
       "                                        'columns = \\\\\"PrimaryPropertyType\\\\\", '\n",
       "                                        '\\\\n                                                                   '\n",
       "                                        'aggfunc = lambda X: '\n",
       "                                        'X.quantile(0.5))\\\\n        output = '\n",
       "                                        'neighb_prop_pivot_table.loc[neighborhood, '\n",
       "                                        'property_type]\\\\n        if '\n",
       "                                        'math.isnan(output):\\\\n            '\n",
       "                                        'print(\\\\\"Pas de données pour ce type '\n",
       "                                        'de bâtiment dans ce voisinage, '\n",
       "                                        'extraction de la médiane '\n",
       "                                        'globale\\\\\")\\\\n            output = '\n",
       "                                        'round(neighb_prop_pivot_table.loc[:, '\n",
       "                                        'property_type].quantile(0.5),0)\\\\n\\\\n        '\n",
       "                                        'return(output)\\\\n\\\\n    emission_df = '\n",
       "                                        'pd.read_csv(input_edfcsv)\\\\n\\\\n    # '\n",
       "                                        'Log of response variable\\\\n    '\n",
       "                                        'emission_df[\\\\\"BCResponse\\\\\"] = '\n",
       "                                        'boxcox(emission_df[\\\\\"TotalGHGEmissions\\\\\"] '\n",
       "                                        '+ 1, -0.1)\\\\n\\\\n    # Fill '\n",
       "                                        'NAs\\\\n        ## Impute '\n",
       "                                        'SecondLargestPropertyUseType\\\\n    '\n",
       "                                        'emission_df.loc[(emission_df[\\\\\"SecondLargestPropertyUseType\\\\\"].isna()) '\n",
       "                                        '\\\\u0026 '\n",
       "                                        '(~emission_df[\\\\\"ListOfAllPropertyUseTypes\\\\\"].isna()), '\n",
       "                                        '\\\\n                    '\n",
       "                                        '\\\\\"SecondLargestPropertyUseType\\\\\"] = '\n",
       "                                        '\\\\\"None\\\\\"\\\\n\\\\n        ## Impute '\n",
       "                                        'SecondLargestPropertyUseTypeGFA\\\\n    '\n",
       "                                        'emission_df.loc[(emission_df[\\\\\"SecondLargestPropertyUseTypeGFA\\\\\"].isna()) '\n",
       "                                        '\\\\u0026 '\n",
       "                                        '(~emission_df[\\\\\"ListOfAllPropertyUseTypes\\\\\"].isna()), '\n",
       "                                        '\\\\n                    '\n",
       "                                        '\\\\\"SecondLargestPropertyUseTypeGFA\\\\\"] '\n",
       "                                        '= 0\\\\n\\\\n        ## Impute '\n",
       "                                        'ThirdLargestPropertyUseType\\\\n    '\n",
       "                                        'emission_df.loc[(emission_df[\\\\\"ThirdLargestPropertyUseType\\\\\"].isna()) '\n",
       "                                        '\\\\u0026 '\n",
       "                                        '(~emission_df[\\\\\"ListOfAllPropertyUseTypes\\\\\"].isna()), '\n",
       "                                        '\\\\n                    '\n",
       "                                        '\\\\\"ThirdLargestPropertyUseType\\\\\"] = '\n",
       "                                        '\\\\\"None\\\\\"\\\\n\\\\n        ## Impute '\n",
       "                                        'ThirdLargestPropertyUseTypeGFA\\\\n    '\n",
       "                                        'emission_df.loc[(emission_df[\\\\\"ThirdLargestPropertyUseTypeGFA\\\\\"].isna()) '\n",
       "                                        '\\\\u0026 '\n",
       "                                        '(~emission_df[\\\\\"ListOfAllPropertyUseTypes\\\\\"].isna()), '\n",
       "                                        '\\\\n                    '\n",
       "                                        '\\\\\"ThirdLargestPropertyUseTypeGFA\\\\\"] '\n",
       "                                        '= 0\\\\n\\\\n    # Drop columns with too '\n",
       "                                        'many NaNs\\\\n    '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        '[\\\\\"YearsENERGYSTARCertified\\\\\", '\n",
       "                                        '\\\\\"Comments\\\\\", \\\\\"Outlier\\\\\"], '\n",
       "                                        'inplace = True)\\\\n\\\\n    # Only keep '\n",
       "                                        'non residential buildings\\\\n    '\n",
       "                                        'emission_df = '\n",
       "                                        'emission_df.loc[emission_df[\\\\\"BuildingType\\\\\"].apply(lambda '\n",
       "                                        'X: '\n",
       "                                        'bool(re.search(\\\\\"^[Nn]on[Rr]esidential\\\\\", '\n",
       "                                        'X))), :]\\\\n    # Drop Building '\n",
       "                                        'Type\\\\n    emission_df.drop(columns = '\n",
       "                                        '\\\\\"BuildingType\\\\\", inplace = '\n",
       "                                        'True)\\\\n\\\\n    # Drop low-impact '\n",
       "                                        'location variables\\\\n    '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        '[\\\\\"Address\\\\\", \\\\\"City\\\\\", '\n",
       "                                        '\\\\\"State\\\\\", \\\\\"ZipCode\\\\\", '\n",
       "                                        '\\\\\"TaxParcelIdentificationNumber\\\\\", '\n",
       "                                        '\\\\\"CouncilDistrictCode\\\\\"], '\n",
       "                                        '\\\\n                    inplace = '\n",
       "                                        'True)\\\\n\\\\n    # Drop ID '\n",
       "                                        'variables\\\\n    '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        '[\\\\\"OSEBuildingID\\\\\", '\n",
       "                                        '\\\\\"PropertyName\\\\\", '\n",
       "                                        '\\\\\"DefaultData\\\\\"], inplace = '\n",
       "                                        'True)\\\\n\\\\n    # Reset index\\\\n    '\n",
       "                                        'emission_df.reset_index(inplace = '\n",
       "                                        'True, drop = True)\\\\n\\\\n    # Drop '\n",
       "                                        'variables too highly correlated to '\n",
       "                                        'the reponse variable\\\\n    '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        \"['SiteEUIWN(kBtu/sf)', \"\n",
       "                                        \"'SourceEUI(kBtu/sf)', \"\n",
       "                                        \"'SourceEUIWN(kBtu/sf)',\\\\n                                \"\n",
       "                                        \"'SiteEnergyUseWN(kBtu)', \"\n",
       "                                        \"'Electricity(kWh)', \"\n",
       "                                        \"'NaturalGas(therms)', \"\n",
       "                                        '\\\\n                                '\n",
       "                                        '\\\\\"SiteEUI(kBtu/sf)\\\\\", '\n",
       "                                        '\\\\\"GHGEmissionsIntensity\\\\\"], inplace '\n",
       "                                        '= True)\\\\n\\\\n    # Feature '\n",
       "                                        'engineering : neighborhood type\\\\n    '\n",
       "                                        'emission_df[\\\\\"Neighborhood_type_GHGE\\\\\"] '\n",
       "                                        '= \\\\\"med-low\\\\\"\\\\n    '\n",
       "                                        'emission_df.loc[emission_df[\\\\\"Neighborhood\\\\\"].isin([\\\\\"GREATER '\n",
       "                                        'DUWAMISH\\\\\", \\\\\"SOUTHEAST\\\\\"]), '\n",
       "                                        '\\\\\"Neighborhood_type_GHGE\\\\\"] = '\n",
       "                                        '\\\\\"low\\\\\"\\\\n    '\n",
       "                                        'emission_df.loc[emission_df[\\\\\"Neighborhood\\\\\"].isin([\\\\\"NORTHEAST\\\\\", '\n",
       "                                        '\\\\\"MAGNOLIA / QUEEN ANNE\\\\\", '\n",
       "                                        '\\\\\"SOUTHWEST\\\\\", \\\\\"LAKE UNION\\\\\"]), '\n",
       "                                        '\\\\n                    '\n",
       "                                        '\\\\\"Neighborhood_type_GHGE\\\\\"] = '\n",
       "                                        '\\\\\"med-high\\\\\"\\\\n    '\n",
       "                                        'emission_df.loc[emission_df[\\\\\"Neighborhood\\\\\"].isin([\\\\\"DOWNTOWN\\\\\", '\n",
       "                                        '\\\\\"EAST\\\\\"]), '\n",
       "                                        '\\\\\"Neighborhood_type_GHGE\\\\\"] = '\n",
       "                                        '\\\\\"high\\\\\"\\\\n\\\\n    # Feature '\n",
       "                                        'engineering : age\\\\n    '\n",
       "                                        'emission_df[\\\\\"Age\\\\\"] = '\n",
       "                                        'emission_df[\\\\\"DataYear\\\\\"] - '\n",
       "                                        'emission_df[\\\\\"YearBuilt\\\\\"]\\\\n\\\\n    '\n",
       "                                        '# FE : Number of use types\\\\n    '\n",
       "                                        'emission_df[\\\\\"NumberOfUseTypes\\\\\"] = '\n",
       "                                        'emission_df[\\\\\"ListOfAllPropertyUseTypes\\\\\"].apply(count_commas)\\\\n\\\\n    '\n",
       "                                        '# FE : Proportion occupied by each '\n",
       "                                        'use\\\\n    three_uses_sum = '\n",
       "                                        'emission_df[\\\\\"LargestPropertyUseTypeGFA\\\\\"] '\n",
       "                                        '+ '\n",
       "                                        'emission_df[\\\\\"SecondLargestPropertyUseTypeGFA\\\\\"] '\n",
       "                                        '+ \\\\\\\\\\\\n                    '\n",
       "                                        'emission_df[\\\\\"ThirdLargestPropertyUseTypeGFA\\\\\"]\\\\n\\\\n    '\n",
       "                                        'emission_df[\\\\\"PrimaryUseGFARatio\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'round(emission_df[\\\\\"LargestPropertyUseTypeGFA\\\\\"] '\n",
       "                                        '/ three_uses_sum, 3)\\\\n    '\n",
       "                                        'emission_df[\\\\\"SecondaryUseGFARatio\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'round(emission_df[\\\\\"SecondLargestPropertyUseTypeGFA\\\\\"] '\n",
       "                                        '/ three_uses_sum, 3)\\\\n    '\n",
       "                                        'emission_df[\\\\\"TerciaryUseGFARatio\\\\\"] '\n",
       "                                        '= '\n",
       "                                        'round(emission_df[\\\\\"ThirdLargestPropertyUseTypeGFA\\\\\"] '\n",
       "                                        '/ three_uses_sum, 3)\\\\n\\\\n    # FE : '\n",
       "                                        'proportion of each energy use\\\\n    '\n",
       "                                        'emission_df[\\\\\"NG_ratio\\\\\"] = '\n",
       "                                        'round(emission_df[\\\\\"NaturalGas(kBtu)\\\\\"] '\n",
       "                                        '/ '\n",
       "                                        'emission_df[\\\\\"SiteEnergyUse(kBtu)\\\\\"], '\n",
       "                                        '3)\\\\n    '\n",
       "                                        'emission_df[\\\\\"Elec_ratio\\\\\"] = '\n",
       "                                        'round(emission_df[\\\\\"Electricity(kBtu)\\\\\"] '\n",
       "                                        '/ '\n",
       "                                        'emission_df[\\\\\"SiteEnergyUse(kBtu)\\\\\"], '\n",
       "                                        '3)\\\\n    '\n",
       "                                        'emission_df[\\\\\"Steam_ratio\\\\\"] = '\n",
       "                                        'round(emission_df[\\\\\"SteamUse(kBtu)\\\\\"] '\n",
       "                                        '/ '\n",
       "                                        'emission_df[\\\\\"SiteEnergyUse(kBtu)\\\\\"], '\n",
       "                                        '3)\\\\n    emission_df.drop(index = '\n",
       "                                        '[780, 2781, 2027, 498, 1677], inplace '\n",
       "                                        '= True) # Impossible values\\\\n    '\n",
       "                                        'emission_df.reset_index(drop = True, '\n",
       "                                        'inplace = True)\\\\n\\\\n    # Drop '\n",
       "                                        'useless columns\\\\n    clean_data = '\n",
       "                                        'emission_df.drop(columns = '\n",
       "                                        '[\\\\\"DataYear\\\\\", \\\\\"Neighborhood\\\\\", '\n",
       "                                        '\\\\\"Longitude\\\\\", \\\\\"Latitude\\\\\", '\n",
       "                                        '\\\\\"YearBuilt\\\\\", '\n",
       "                                        '\\\\\"PropertyGFATotal\\\\\", '\n",
       "                                        '\\\\n                                            '\n",
       "                                        '\\\\\"SteamUse(kBtu)\\\\\", '\n",
       "                                        '\\\\\"Electricity(kBtu)\\\\\", '\n",
       "                                        '\\\\\"NaturalGas(kBtu)\\\\\", '\n",
       "                                        '\\\\\"PrimaryPropertyType\\\\\"])\\\\n\\\\n    '\n",
       "                                        '# Drop NAs\\\\n    '\n",
       "                                        'clean_data.dropna(subset = '\n",
       "                                        '[\\\\\"LargestPropertyUseType\\\\\", '\n",
       "                                        '\\\\\"TotalGHGEmissions\\\\\", '\n",
       "                                        '\\\\\"NG_ratio\\\\\"], inplace = '\n",
       "                                        'True)\\\\n    '\n",
       "                                        'emission_df.dropna().loc[emission_df[\\\\\"in_train\\\\\"] '\n",
       "                                        '== 1, '\n",
       "                                        ':].pivot_table(\\\\\"NumberofFloors\\\\\", '\n",
       "                                        '\\\\n                                                                        '\n",
       "                                        'index = \\\\\"Neighborhood\\\\\", '\n",
       "                                        '\\\\n                                                                        '\n",
       "                                        'columns = \\\\\"PrimaryPropertyType\\\\\", '\n",
       "                                        '\\\\n                                                                        '\n",
       "                                        'aggfunc = lambda X: '\n",
       "                                        'X.quantile(0.5))\\\\n\\\\n    # Fill '\n",
       "                                        'NAs\\\\n    for index in '\n",
       "                                        '(clean_data.loc[clean_data[\\\\\"NumberofFloors\\\\\"].isna(), '\n",
       "                                        '\\\\\"NumberofFloors\\\\\"]).index.tolist():\\\\n\\\\n        '\n",
       "                                        'row_neighborhood = '\n",
       "                                        'emission_df.loc[emission_df.index == '\n",
       "                                        'index, '\n",
       "                                        '\\\\\"Neighborhood\\\\\"].at[index]\\\\n        '\n",
       "                                        'row_property_type = '\n",
       "                                        'emission_df.loc[emission_df.index == '\n",
       "                                        'index, '\n",
       "                                        '\\\\\"PrimaryPropertyType\\\\\"].at[index]\\\\n\\\\n        '\n",
       "                                        'clean_data.loc[clean_data.index ==  '\n",
       "                                        'index, \\\\\"NumberofFloors\\\\\"] = '\n",
       "                                        '\\\\\\\\\\\\n            '\n",
       "                                        'fetch_noFloors(emission_df, '\n",
       "                                        'row_neighborhood, '\n",
       "                                        'row_property_type)\\\\n\\\\n    '\n",
       "                                        'clean_data.loc[clean_data[\\\\\"ENERGYSTARScore\\\\\"].isna(), '\n",
       "                                        '\\\\\"ENERGYSTARScore\\\\\"] = 0\\\\n    '\n",
       "                                        'clean_data.reset_index(inplace = '\n",
       "                                        'True, drop = True)\\\\n\\\\n    '\n",
       "                                        'clean_data.to_csv(output_cleandatacsv, '\n",
       "                                        'index=False)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Preprocess \"\n",
       "                                        \"dataset', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--input-edfcsv\\\\\", '\n",
       "                                        'dest=\\\\\"input_edfcsv\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-cleandatacsv\\\\\", '\n",
       "                                        'dest=\\\\\"output_cleandatacsv\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'preprocess_dataset(**_parsed_args)\\\\n\"],\"args\":[\"--input-edfcsv\",\"/tmp/inputs/input_edfcsv/data\",\"--output-cleandatacsv\",\"/tmp/outputs/output_cleandatacsv/data\"],\"resources\":{}}},{\"name\":\"train-best-model\",\"inputs\":{\"parameters\":[{\"name\":\"evaluate-models-best_model\"},{\"name\":\"evaluate-models-hyperparams\"}],\"artifacts\":[{\"name\":\"prepare-data-output_xtraincsv\",\"path\":\"/tmp/inputs/input_X_train_csv/data\"},{\"name\":\"prepare-data-output_ytraincsv\",\"path\":\"/tmp/inputs/input_y_train_csv/data\"}]},\"outputs\":{\"artifacts\":[{\"name\":\"train-best-model-output_pickle_model\",\"path\":\"/tmp/outputs/output_pickle_model/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"best_hyperparams\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.evaluate-models-hyperparams}}\\\\\", '\n",
       "                                        '\\\\\"best_model\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.evaluate-models-best_model}}\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"1a8a3c3b40092fc87b74ec45aa59026cfbaeb71bfc20721f1cdd2dc353e32745\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/train_best_model_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--best-model\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": \\\\\"best_model\\\\\"}, '\n",
       "                                        '\\\\\"--best-hyperparams\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"best_hyperparams\\\\\"}, '\n",
       "                                        '\\\\\"--input-X-train-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_X_train_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-y-train-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_y_train_csv\\\\\"}, '\n",
       "                                        '\\\\\"--output-pickle-model\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"output_pickle_model\\\\\"}], '\n",
       "                                        '\\\\\"command\\\\\": [\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\\\\\n    import os\\\\\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\\\\\n    return '\n",
       "                                        'file_path\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        'train_best_model(best_model, '\n",
       "                                        '\\\\\\\\n                     '\n",
       "                                        'best_hyperparams, '\n",
       "                                        '\\\\\\\\n                     '\n",
       "                                        'input_X_train_csv, '\n",
       "                                        '\\\\\\\\n                     '\n",
       "                                        'input_y_train_csv,\\\\\\\\n                     '\n",
       "                                        'output_pickle_model):\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'import pandas as pd\\\\\\\\n    import '\n",
       "                                        'xgboost as xgb\\\\\\\\n    from '\n",
       "                                        'sklearn.metrics import '\n",
       "                                        'mean_squared_error, '\n",
       "                                        'explained_variance_score, '\n",
       "                                        'r2_score\\\\\\\\n    from '\n",
       "                                        'sklearn.model_selection import '\n",
       "                                        'cross_val_score, KFold\\\\\\\\n    from '\n",
       "                                        'sklearn.svm import SVR\\\\\\\\n    from '\n",
       "                                        'sklearn.ensemble import '\n",
       "                                        'RandomForestRegressor\\\\\\\\n    import '\n",
       "                                        'os\\\\\\\\n    import pickle\\\\\\\\n\\\\\\\\n    '\n",
       "                                        \"if best_model == 'XGB':\\\\\\\\n        \"\n",
       "                                        'modfit = xgb.XGBRegressor(objective = '\n",
       "                                        '\\\\\\\\\\\\\"reg:squarederror\\\\\\\\\\\\\",\\\\\\\\n                                   '\n",
       "                                        'tree_method = '\n",
       "                                        \"'hist',\\\\\\\\n                                   \"\n",
       "                                        'eval_metric = '\n",
       "                                        '[\\\\\\\\\\\\\"rmse\\\\\\\\\\\\\"],\\\\\\\\n                                   '\n",
       "                                        '**best_hyperparams)\\\\\\\\n    elif '\n",
       "                                        \"best_model == 'SVM':\\\\\\\\n        \"\n",
       "                                        'modfit = '\n",
       "                                        'SVR(**best_hyperparams)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'elif best_model == '\n",
       "                                        '\\\\\\\\\\\\\"RandomForest\\\\\\\\\\\\\":\\\\\\\\n        '\n",
       "                                        'modfit = '\n",
       "                                        'RandomForestRegressor(**best_hyperparams)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'else:\\\\\\\\n        raise '\n",
       "                                        'ValueError(\\\\\\\\\\\\\"Model name not '\n",
       "                                        'recognized : '\n",
       "                                        '\\\\\\\\\\\\\".format(best_model))\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'X_train = '\n",
       "                                        'pd.read_csv(input_X_train_csv)\\\\\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'pd.read_csv(input_y_train_csv)\\\\\\\\n    '\n",
       "                                        'modfit.fit(X_train, '\n",
       "                                        'y_train)\\\\\\\\n\\\\\\\\n    with '\n",
       "                                        \"open(output_pickle_model, 'wb') as \"\n",
       "                                        'f:\\\\\\\\n        pickle.dump(modfit, '\n",
       "                                        'f)\\\\\\\\n\\\\\\\\nimport json\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train \"\n",
       "                                        \"best model', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--best-model\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"best_model\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--best-hyperparams\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"best_hyperparams\\\\\\\\\\\\\", '\n",
       "                                        'type=json.loads, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-X-train-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_X_train_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-y-train-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_y_train_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--output-pickle-model\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"output_pickle_model\\\\\\\\\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n\\\\\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'train_best_model(**_parsed_args)\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"best_model\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"String\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"best_hyperparams\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"JsonObject\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_X_train_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_y_train_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}], \\\\\"metadata\\\\\": '\n",
       "                                        '{\\\\\"annotations\\\\\": {\\\\\"author\\\\\": '\n",
       "                                        '\\\\\"Antoine Villatte\\\\\"}}, \\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Train best model\\\\\", '\n",
       "                                        '\\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"output_pickle_model\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Pickle\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        '_make_parent_dirs_and_return_path(file_path: '\n",
       "                                        'str):\\\\n    import os\\\\n    '\n",
       "                                        'os.makedirs(os.path.dirname(file_path), '\n",
       "                                        'exist_ok=True)\\\\n    return '\n",
       "                                        'file_path\\\\n\\\\ndef '\n",
       "                                        'train_best_model(best_model, '\n",
       "                                        '\\\\n                     '\n",
       "                                        'best_hyperparams, '\n",
       "                                        '\\\\n                     '\n",
       "                                        'input_X_train_csv, '\n",
       "                                        '\\\\n                     '\n",
       "                                        'input_y_train_csv,\\\\n                     '\n",
       "                                        'output_pickle_model):\\\\n\\\\n    import '\n",
       "                                        'pandas as pd\\\\n    import xgboost as '\n",
       "                                        'xgb\\\\n    from sklearn.metrics import '\n",
       "                                        'mean_squared_error, '\n",
       "                                        'explained_variance_score, '\n",
       "                                        'r2_score\\\\n    from '\n",
       "                                        'sklearn.model_selection import '\n",
       "                                        'cross_val_score, KFold\\\\n    from '\n",
       "                                        'sklearn.svm import SVR\\\\n    from '\n",
       "                                        'sklearn.ensemble import '\n",
       "                                        'RandomForestRegressor\\\\n    import '\n",
       "                                        'os\\\\n    import pickle\\\\n\\\\n    if '\n",
       "                                        \"best_model == 'XGB':\\\\n        modfit \"\n",
       "                                        '= xgb.XGBRegressor(objective = '\n",
       "                                        '\\\\\"reg:squarederror\\\\\",\\\\n                                   '\n",
       "                                        'tree_method = '\n",
       "                                        \"'hist',\\\\n                                   \"\n",
       "                                        'eval_metric = '\n",
       "                                        '[\\\\\"rmse\\\\\"],\\\\n                                   '\n",
       "                                        '**best_hyperparams)\\\\n    elif '\n",
       "                                        \"best_model == 'SVM':\\\\n        modfit \"\n",
       "                                        '= SVR(**best_hyperparams)\\\\n\\\\n    '\n",
       "                                        'elif best_model == '\n",
       "                                        '\\\\\"RandomForest\\\\\":\\\\n        modfit '\n",
       "                                        '= '\n",
       "                                        'RandomForestRegressor(**best_hyperparams)\\\\n\\\\n    '\n",
       "                                        'else:\\\\n        raise '\n",
       "                                        'ValueError(\\\\\"Model name not '\n",
       "                                        'recognized : '\n",
       "                                        '\\\\\".format(best_model))\\\\n\\\\n    '\n",
       "                                        'X_train = '\n",
       "                                        'pd.read_csv(input_X_train_csv)\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'pd.read_csv(input_y_train_csv)\\\\n    '\n",
       "                                        'modfit.fit(X_train, y_train)\\\\n\\\\n    '\n",
       "                                        \"with open(output_pickle_model, 'wb') \"\n",
       "                                        'as f:\\\\n        pickle.dump(modfit, '\n",
       "                                        'f)\\\\n\\\\nimport json\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train \"\n",
       "                                        \"best model', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--best-model\\\\\", '\n",
       "                                        'dest=\\\\\"best_model\\\\\", type=str, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--best-hyperparams\\\\\", '\n",
       "                                        'dest=\\\\\"best_hyperparams\\\\\", '\n",
       "                                        'type=json.loads, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-X-train-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_X_train_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-y-train-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_y_train_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--output-pickle-model\\\\\", '\n",
       "                                        'dest=\\\\\"output_pickle_model\\\\\", '\n",
       "                                        'type=_make_parent_dirs_and_return_path, '\n",
       "                                        'required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parsed_args '\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'train_best_model(**_parsed_args)\\\\n\"],\"args\":[\"--best-model\",\"{{inputs.parameters.evaluate-models-best_model}}\",\"--best-hyperparams\",\"{{inputs.parameters.evaluate-models-hyperparams}}\",\"--input-X-train-csv\",\"/tmp/inputs/input_X_train_csv/data\",\"--input-y-train-csv\",\"/tmp/inputs/input_y_train_csv/data\",\"--output-pickle-model\",\"/tmp/outputs/output_pickle_model/data\"],\"resources\":{}}},{\"name\":\"train-randomforest\",\"inputs\":{\"parameters\":[{\"name\":\"hyperopt_iterations\"}],\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"path\":\"/tmp/inputs/input_x_test_csv/data\"},{\"name\":\"prepare-data-output_xtraincsv\",\"path\":\"/tmp/inputs/input_x_train_csv/data\"},{\"name\":\"prepare-data-output_ytestcsv\",\"path\":\"/tmp/inputs/input_y_test_csv/data\"},{\"name\":\"prepare-data-output_ytraincsv\",\"path\":\"/tmp/inputs/input_y_train_csv/data\"}]},\"outputs\":{\"parameters\":[{\"name\":\"train-randomforest-MSE\",\"valueFrom\":{\"path\":\"/tmp/outputs/MSE/data\"}},{\"name\":\"train-randomforest-R2\",\"valueFrom\":{\"path\":\"/tmp/outputs/R2/data\"}},{\"name\":\"train-randomforest-hyperparams\",\"valueFrom\":{\"path\":\"/tmp/outputs/hyperparams/data\"}}],\"artifacts\":[{\"name\":\"train-randomforest-MSE\",\"path\":\"/tmp/outputs/MSE/data\"},{\"name\":\"train-randomforest-R2\",\"path\":\"/tmp/outputs/R2/data\"},{\"name\":\"train-randomforest-hyperparams\",\"path\":\"/tmp/outputs/hyperparams/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"hyperopt_iterations\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.hyperopt_iterations}}\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"d409f2ef67c47aca2ba39faaa5862da7432f0fb64be28b81fd400062f79067c4\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/train_randomforest_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--input-x-train-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_x_train_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-y-train-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_y_train_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-x-test-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_x_test_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-y-test-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_y_test_csv\\\\\"}, '\n",
       "                                        '\\\\\"--hyperopt-iterations\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"hyperopt_iterations\\\\\"}, '\n",
       "                                        '\\\\\"----output-paths\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": \\\\\"MSE\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": \\\\\"R2\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"hyperparams\\\\\"}], \\\\\"command\\\\\": '\n",
       "                                        '[\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'train_randomforest(input_x_train_csv, '\n",
       "                                        '\\\\\\\\n                       '\n",
       "                                        'input_y_train_csv, '\n",
       "                                        '\\\\\\\\n                       '\n",
       "                                        'input_x_test_csv, '\n",
       "                                        '\\\\\\\\n                       '\n",
       "                                        'input_y_test_csv,\\\\\\\\n                      '\n",
       "                                        'hyperopt_iterations\\\\\\\\n  '\n",
       "                                        '):\\\\\\\\n\\\\\\\\n    global '\n",
       "                                        'best\\\\\\\\n\\\\\\\\n    import pandas as '\n",
       "                                        'pd\\\\\\\\n    from sklearn.ensemble '\n",
       "                                        'import RandomForestRegressor\\\\\\\\n    '\n",
       "                                        'from sklearn.metrics import '\n",
       "                                        'mean_squared_error, r2_score\\\\\\\\n    '\n",
       "                                        'from sklearn.model_selection import '\n",
       "                                        'cross_val_score\\\\\\\\n    import '\n",
       "                                        'hyperopt\\\\\\\\n    from hyperopt import '\n",
       "                                        'fmin, tpe, hp, STATUS_OK, Trials, '\n",
       "                                        'space_eval\\\\\\\\n    from random import '\n",
       "                                        'seed\\\\\\\\n\\\\\\\\n    X_train = '\n",
       "                                        'pd.read_csv(input_x_train_csv)\\\\\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'pd.read_csv(input_y_train_csv)\\\\\\\\n    '\n",
       "                                        'X_test = '\n",
       "                                        'pd.read_csv(input_x_test_csv)\\\\\\\\n    '\n",
       "                                        'y_test = '\n",
       "                                        'pd.read_csv(input_y_test_csv)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'seed(42)\\\\\\\\n    def '\n",
       "                                        'model_accuracy(params):\\\\\\\\n        '\n",
       "                                        'rf_reg = '\n",
       "                                        'RandomForestRegressor(**params)\\\\\\\\n        '\n",
       "                                        'return cross_val_score(rf_reg, '\n",
       "                                        'X_train, y_train).mean()\\\\\\\\n\\\\\\\\n    '\n",
       "                                        \"space = {\\\\\\\\n        'max_depth': \"\n",
       "                                        \"hp.choice('max_depth', range(1, \"\n",
       "                                        \"20)),\\\\\\\\n        'max_features': \"\n",
       "                                        \"hp.choice('max_features', range(1, \"\n",
       "                                        \"70)),\\\\\\\\n        'n_estimators': \"\n",
       "                                        \"hp.choice('n_estimators', range(100, \"\n",
       "                                        '500)),\\\\\\\\n        '\n",
       "                                        \"'min_samples_split' : \"\n",
       "                                        \"hp.choice('min_samples_split', \"\n",
       "                                        'range(2, 10)),\\\\\\\\n        '\n",
       "                                        \"'min_samples_leaf' : \"\n",
       "                                        \"hp.choice('min_samples_leaf', \"\n",
       "                                        'range(1, 10)),\\\\\\\\n        '\n",
       "                                        \"'max_leaf_nodes' : \"\n",
       "                                        \"hp.choice('max_leaf_nodes', range(2, \"\n",
       "                                        \"10, 2)),\\\\\\\\n        'criterion': \"\n",
       "                                        \"hp.choice('criterion', \"\n",
       "                                        '[\\\\\\\\\\\\\"mse\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"mae\\\\\\\\\\\\\"])}\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'best=0\\\\\\\\n    def '\n",
       "                                        'hyperparameter_tuning(space):\\\\\\\\n        '\n",
       "                                        'global best\\\\\\\\n        acc = '\n",
       "                                        'model_accuracy(space)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'if acc \\\\u003e best:\\\\\\\\n            '\n",
       "                                        'best = acc\\\\\\\\n            print '\n",
       "                                        \"('new best:', best, \"\n",
       "                                        'space)\\\\\\\\n\\\\\\\\n        return '\n",
       "                                        \"{'loss': 1-acc, 'status': \"\n",
       "                                        'STATUS_OK}\\\\\\\\n\\\\\\\\n    trials = '\n",
       "                                        'Trials()\\\\\\\\n    best = '\n",
       "                                        'fmin(hyperparameter_tuning, space, '\n",
       "                                        'algo=tpe.suggest, '\n",
       "                                        'max_evals=hyperopt_iterations, '\n",
       "                                        'trials=trials)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'rf_hyperparams = space_eval(space, '\n",
       "                                        'best)\\\\\\\\n\\\\\\\\n    modfit_rf = '\n",
       "                                        'RandomForestRegressor(**rf_hyperparams)\\\\\\\\n    '\n",
       "                                        'modfit_rf.fit(X_train, '\n",
       "                                        'y_train)\\\\\\\\n\\\\\\\\n    rf_mse = '\n",
       "                                        'mean_squared_error(y_test.to_numpy(), '\n",
       "                                        'modfit_rf.predict(X_test))\\\\\\\\n    '\n",
       "                                        'rf_accuracies = '\n",
       "                                        'cross_val_score(estimator = '\n",
       "                                        'modfit_rf, X = X_test, y = y_test, '\n",
       "                                        '\\\\\\\\n                                    '\n",
       "                                        'cv = 10)\\\\\\\\n    rf_r2 = '\n",
       "                                        'rf_accuracies.mean()\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'return(rf_mse, rf_r2, '\n",
       "                                        'rf_hyperparams)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_float(float_value: float) '\n",
       "                                        '-\\\\u003e str:\\\\\\\\n    if '\n",
       "                                        'isinstance(float_value, '\n",
       "                                        'str):\\\\\\\\n        return '\n",
       "                                        'float_value\\\\\\\\n    if not '\n",
       "                                        'isinstance(float_value, (float, '\n",
       "                                        'int)):\\\\\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" '\n",
       "                                        'has type \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" instead of '\n",
       "                                        \"float.'.format(\\\\\\\\n            \"\n",
       "                                        'str(float_value), '\n",
       "                                        'str(type(float_value))))\\\\\\\\n    '\n",
       "                                        'return str(float_value)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_json(obj) -\\\\u003e '\n",
       "                                        'str:\\\\\\\\n    if isinstance(obj, '\n",
       "                                        'str):\\\\\\\\n        return obj\\\\\\\\n    '\n",
       "                                        'import json\\\\\\\\n\\\\\\\\n    def '\n",
       "                                        'default_serializer(obj):\\\\\\\\n        '\n",
       "                                        'if hasattr(obj, '\n",
       "                                        \"'to_struct'):\\\\\\\\n            return \"\n",
       "                                        'obj.to_struct()\\\\\\\\n        '\n",
       "                                        'else:\\\\\\\\n            raise '\n",
       "                                        'TypeError(\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"Object of type \\'%s\\' is not '\n",
       "                                        'JSON serializable and does not have '\n",
       "                                        '.to_struct() '\n",
       "                                        'method.\\\\\\\\\\\\\"\\\\\\\\n                % '\n",
       "                                        'obj.__class__.__name__)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'return json.dumps(obj, '\n",
       "                                        'default=default_serializer, '\n",
       "                                        'sort_keys=True)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train \"\n",
       "                                        \"randomforest', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-x-train-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_x_train_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-y-train-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_y_train_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-x-test-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_x_test_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-y-test-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_y_test_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--hyperopt-iterations\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"hyperopt_iterations\\\\\\\\\\\\\", '\n",
       "                                        'type=int, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"----output-paths\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        'type=str, nargs=3)\\\\\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        '[])\\\\\\\\n\\\\\\\\n_outputs = '\n",
       "                                        'train_randomforest(**_parsed_args)\\\\\\\\n\\\\\\\\n_output_serializers '\n",
       "                                        '= [\\\\\\\\n    _serialize_float,\\\\\\\\n    '\n",
       "                                        '_serialize_float,\\\\\\\\n    '\n",
       "                                        '_serialize_json,\\\\\\\\n\\\\\\\\n]\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'os\\\\\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\\\\\n    '\n",
       "                                        'try:\\\\\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\\\\\n    '\n",
       "                                        'except OSError:\\\\\\\\n        '\n",
       "                                        'pass\\\\\\\\n    with open(output_file, '\n",
       "                                        \"'w') as f:\\\\\\\\n        \"\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_x_train_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_y_train_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_x_test_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_y_test_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"hyperopt_iterations\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"Integer\\\\\"}], '\n",
       "                                        '\\\\\"metadata\\\\\": {\\\\\"annotations\\\\\": '\n",
       "                                        '{\\\\\"author\\\\\": \\\\\"Antoine '\n",
       "                                        'Villatte\\\\\"}}, \\\\\"name\\\\\": \\\\\"Train '\n",
       "                                        'randomforest\\\\\", \\\\\"outputs\\\\\": '\n",
       "                                        '[{\\\\\"name\\\\\": \\\\\"MSE\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": \\\\\"R2\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"Float\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"hyperparams\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": '\n",
       "                                        '\\\\\"JsonObject\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'train_randomforest(input_x_train_csv, '\n",
       "                                        '\\\\n                       '\n",
       "                                        'input_y_train_csv, '\n",
       "                                        '\\\\n                       '\n",
       "                                        'input_x_test_csv, '\n",
       "                                        '\\\\n                       '\n",
       "                                        'input_y_test_csv,\\\\n                      '\n",
       "                                        'hyperopt_iterations\\\\n  ):\\\\n\\\\n    '\n",
       "                                        'global best\\\\n\\\\n    import pandas as '\n",
       "                                        'pd\\\\n    from sklearn.ensemble import '\n",
       "                                        'RandomForestRegressor\\\\n    from '\n",
       "                                        'sklearn.metrics import '\n",
       "                                        'mean_squared_error, r2_score\\\\n    '\n",
       "                                        'from sklearn.model_selection import '\n",
       "                                        'cross_val_score\\\\n    import '\n",
       "                                        'hyperopt\\\\n    from hyperopt import '\n",
       "                                        'fmin, tpe, hp, STATUS_OK, Trials, '\n",
       "                                        'space_eval\\\\n    from random import '\n",
       "                                        'seed\\\\n\\\\n    X_train = '\n",
       "                                        'pd.read_csv(input_x_train_csv)\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'pd.read_csv(input_y_train_csv)\\\\n    '\n",
       "                                        'X_test = '\n",
       "                                        'pd.read_csv(input_x_test_csv)\\\\n    '\n",
       "                                        'y_test = '\n",
       "                                        'pd.read_csv(input_y_test_csv)\\\\n\\\\n    '\n",
       "                                        'seed(42)\\\\n    def '\n",
       "                                        'model_accuracy(params):\\\\n        '\n",
       "                                        'rf_reg = '\n",
       "                                        'RandomForestRegressor(**params)\\\\n        '\n",
       "                                        'return cross_val_score(rf_reg, '\n",
       "                                        'X_train, y_train).mean()\\\\n\\\\n    '\n",
       "                                        \"space = {\\\\n        'max_depth': \"\n",
       "                                        \"hp.choice('max_depth', range(1, \"\n",
       "                                        \"20)),\\\\n        'max_features': \"\n",
       "                                        \"hp.choice('max_features', range(1, \"\n",
       "                                        \"70)),\\\\n        'n_estimators': \"\n",
       "                                        \"hp.choice('n_estimators', range(100, \"\n",
       "                                        \"500)),\\\\n        'min_samples_split' \"\n",
       "                                        \": hp.choice('min_samples_split', \"\n",
       "                                        'range(2, 10)),\\\\n        '\n",
       "                                        \"'min_samples_leaf' : \"\n",
       "                                        \"hp.choice('min_samples_leaf', \"\n",
       "                                        'range(1, 10)),\\\\n        '\n",
       "                                        \"'max_leaf_nodes' : \"\n",
       "                                        \"hp.choice('max_leaf_nodes', range(2, \"\n",
       "                                        \"10, 2)),\\\\n        'criterion': \"\n",
       "                                        'hp.choice(\\'criterion\\', [\\\\\"mse\\\\\", '\n",
       "                                        '\\\\\"mae\\\\\"])}\\\\n\\\\n    best=0\\\\n    '\n",
       "                                        'def '\n",
       "                                        'hyperparameter_tuning(space):\\\\n        '\n",
       "                                        'global best\\\\n        acc = '\n",
       "                                        'model_accuracy(space)\\\\n\\\\n        if '\n",
       "                                        'acc \\\\u003e best:\\\\n            best '\n",
       "                                        \"= acc\\\\n            print ('new \"\n",
       "                                        \"best:', best, space)\\\\n\\\\n        \"\n",
       "                                        \"return {'loss': 1-acc, 'status': \"\n",
       "                                        'STATUS_OK}\\\\n\\\\n    trials = '\n",
       "                                        'Trials()\\\\n    best = '\n",
       "                                        'fmin(hyperparameter_tuning, space, '\n",
       "                                        'algo=tpe.suggest, '\n",
       "                                        'max_evals=hyperopt_iterations, '\n",
       "                                        'trials=trials)\\\\n\\\\n    '\n",
       "                                        'rf_hyperparams = space_eval(space, '\n",
       "                                        'best)\\\\n\\\\n    modfit_rf = '\n",
       "                                        'RandomForestRegressor(**rf_hyperparams)\\\\n    '\n",
       "                                        'modfit_rf.fit(X_train, '\n",
       "                                        'y_train)\\\\n\\\\n    rf_mse = '\n",
       "                                        'mean_squared_error(y_test.to_numpy(), '\n",
       "                                        'modfit_rf.predict(X_test))\\\\n    '\n",
       "                                        'rf_accuracies = '\n",
       "                                        'cross_val_score(estimator = '\n",
       "                                        'modfit_rf, X = X_test, y = y_test, '\n",
       "                                        '\\\\n                                    '\n",
       "                                        'cv = 10)\\\\n    rf_r2 = '\n",
       "                                        'rf_accuracies.mean()\\\\n\\\\n    '\n",
       "                                        'return(rf_mse, rf_r2, '\n",
       "                                        'rf_hyperparams)\\\\n\\\\ndef '\n",
       "                                        '_serialize_float(float_value: float) '\n",
       "                                        '-\\\\u003e str:\\\\n    if '\n",
       "                                        'isinstance(float_value, '\n",
       "                                        'str):\\\\n        return '\n",
       "                                        'float_value\\\\n    if not '\n",
       "                                        'isinstance(float_value, (float, '\n",
       "                                        'int)):\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\"{}\\\\\" has type '\n",
       "                                        '\\\\\"{}\\\\\" instead of '\n",
       "                                        \"float.'.format(\\\\n            \"\n",
       "                                        'str(float_value), '\n",
       "                                        'str(type(float_value))))\\\\n    return '\n",
       "                                        'str(float_value)\\\\n\\\\ndef '\n",
       "                                        '_serialize_json(obj) -\\\\u003e '\n",
       "                                        'str:\\\\n    if isinstance(obj, '\n",
       "                                        'str):\\\\n        return obj\\\\n    '\n",
       "                                        'import json\\\\n\\\\n    def '\n",
       "                                        'default_serializer(obj):\\\\n        if '\n",
       "                                        'hasattr(obj, '\n",
       "                                        \"'to_struct'):\\\\n            return \"\n",
       "                                        'obj.to_struct()\\\\n        '\n",
       "                                        'else:\\\\n            raise '\n",
       "                                        'TypeError(\\\\n                '\n",
       "                                        '\\\\\"Object of type \\'%s\\' is not JSON '\n",
       "                                        'serializable and does not have '\n",
       "                                        '.to_struct() '\n",
       "                                        'method.\\\\\"\\\\n                % '\n",
       "                                        'obj.__class__.__name__)\\\\n\\\\n    '\n",
       "                                        'return json.dumps(obj, '\n",
       "                                        'default=default_serializer, '\n",
       "                                        'sort_keys=True)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train \"\n",
       "                                        \"randomforest', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--input-x-train-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_x_train_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-y-train-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_y_train_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-x-test-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_x_test_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-y-test-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_y_test_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--hyperopt-iterations\\\\\", '\n",
       "                                        'dest=\\\\\"hyperopt_iterations\\\\\", '\n",
       "                                        'type=int, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"----output-paths\\\\\", '\n",
       "                                        'dest=\\\\\"_output_paths\\\\\", type=str, '\n",
       "                                        'nargs=3)\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\"_output_paths\\\\\", '\n",
       "                                        '[])\\\\n\\\\n_outputs = '\n",
       "                                        'train_randomforest(**_parsed_args)\\\\n\\\\n_output_serializers '\n",
       "                                        '= [\\\\n    _serialize_float,\\\\n    '\n",
       "                                        '_serialize_float,\\\\n    '\n",
       "                                        '_serialize_json,\\\\n\\\\n]\\\\n\\\\nimport '\n",
       "                                        'os\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\n    '\n",
       "                                        'try:\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\n    '\n",
       "                                        'except OSError:\\\\n        pass\\\\n    '\n",
       "                                        \"with open(output_file, 'w') as \"\n",
       "                                        'f:\\\\n        '\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\n\"],\"args\":[\"--input-x-train-csv\",\"/tmp/inputs/input_x_train_csv/data\",\"--input-y-train-csv\",\"/tmp/inputs/input_y_train_csv/data\",\"--input-x-test-csv\",\"/tmp/inputs/input_x_test_csv/data\",\"--input-y-test-csv\",\"/tmp/inputs/input_y_test_csv/data\",\"--hyperopt-iterations\",\"{{inputs.parameters.hyperopt_iterations}}\",\"----output-paths\",\"/tmp/outputs/MSE/data\",\"/tmp/outputs/R2/data\",\"/tmp/outputs/hyperparams/data\"],\"resources\":{}}},{\"name\":\"train-svm\",\"inputs\":{\"parameters\":[{\"name\":\"hyperopt_iterations\"}],\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"path\":\"/tmp/inputs/input_x_test_csv/data\"},{\"name\":\"prepare-data-output_xtraincsv\",\"path\":\"/tmp/inputs/input_x_train_csv/data\"},{\"name\":\"prepare-data-output_ytestcsv\",\"path\":\"/tmp/inputs/input_y_test_csv/data\"},{\"name\":\"prepare-data-output_ytraincsv\",\"path\":\"/tmp/inputs/input_y_train_csv/data\"}]},\"outputs\":{\"parameters\":[{\"name\":\"train-svm-MSE\",\"valueFrom\":{\"path\":\"/tmp/outputs/MSE/data\"}},{\"name\":\"train-svm-R2\",\"valueFrom\":{\"path\":\"/tmp/outputs/R2/data\"}},{\"name\":\"train-svm-hyperparams\",\"valueFrom\":{\"path\":\"/tmp/outputs/hyperparams/data\"}}],\"artifacts\":[{\"name\":\"train-svm-MSE\",\"path\":\"/tmp/outputs/MSE/data\"},{\"name\":\"train-svm-R2\",\"path\":\"/tmp/outputs/R2/data\"},{\"name\":\"train-svm-hyperparams\",\"path\":\"/tmp/outputs/hyperparams/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"hyperopt_iterations\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.hyperopt_iterations}}\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"e26a807469ad3a858e3d839e62cda2f21a9b2695bdd7b0f18ff010d6d4c98715\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/train_svm_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--input-x-train-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_x_train_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-y-train-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_y_train_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-x-test-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_x_test_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-y-test-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_y_test_csv\\\\\"}, '\n",
       "                                        '\\\\\"--hyperopt-iterations\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"hyperopt_iterations\\\\\"}, '\n",
       "                                        '\\\\\"----output-paths\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": \\\\\"MSE\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": \\\\\"R2\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"hyperparams\\\\\"}], \\\\\"command\\\\\": '\n",
       "                                        '[\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'train_svm(input_x_train_csv, '\n",
       "                                        '\\\\\\\\n              input_y_train_csv, '\n",
       "                                        '\\\\\\\\n              input_x_test_csv, '\n",
       "                                        '\\\\\\\\n              '\n",
       "                                        'input_y_test_csv,\\\\\\\\n              '\n",
       "                                        'hyperopt_iterations\\\\\\\\n  '\n",
       "                                        '):\\\\\\\\n\\\\\\\\n    global '\n",
       "                                        'best\\\\\\\\n\\\\\\\\n    import pandas as '\n",
       "                                        'pd\\\\\\\\n    import xgboost as '\n",
       "                                        'xgb\\\\\\\\n    from sklearn.metrics '\n",
       "                                        'import mean_squared_error, '\n",
       "                                        'explained_variance_score, '\n",
       "                                        'r2_score\\\\\\\\n    from '\n",
       "                                        'sklearn.model_selection import '\n",
       "                                        'cross_val_score, KFold\\\\\\\\n    from '\n",
       "                                        'sklearn.svm import SVR\\\\\\\\n    import '\n",
       "                                        'hyperopt\\\\\\\\n    from hyperopt import '\n",
       "                                        'fmin, tpe, hp, STATUS_OK, Trials, '\n",
       "                                        'space_eval\\\\\\\\n    from random import '\n",
       "                                        'seed\\\\\\\\n\\\\\\\\n    X_train = '\n",
       "                                        'pd.read_csv(input_x_train_csv)\\\\\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'pd.read_csv(input_y_train_csv)\\\\\\\\n    '\n",
       "                                        'X_test = '\n",
       "                                        'pd.read_csv(input_x_test_csv)\\\\\\\\n    '\n",
       "                                        'y_test = '\n",
       "                                        'pd.read_csv(input_y_test_csv)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'seed(42)\\\\\\\\n    def '\n",
       "                                        'model_accuracy(params):\\\\\\\\n        '\n",
       "                                        'svm_reg = SVR(**params)\\\\\\\\n        '\n",
       "                                        'return cross_val_score(svm_reg, '\n",
       "                                        'X_train, y_train).mean()\\\\\\\\n\\\\\\\\n    '\n",
       "                                        \"space = {\\\\\\\\n        'C': \"\n",
       "                                        \"hp.quniform('C', 0.005, 1.0, \"\n",
       "                                        \"0.01),\\\\\\\\n        'degree': \"\n",
       "                                        \"hp.choice('degree', range(2, \"\n",
       "                                        \"6)),\\\\\\\\n        'coef0' : \"\n",
       "                                        \"hp.quniform('coef0', 0.5, 2, \"\n",
       "                                        \"0.2),\\\\\\\\n        'gamma' : \"\n",
       "                                        \"hp.quniform('gamma', 0.005, 0.1, \"\n",
       "                                        \"0.01),\\\\\\\\n        'kernel': \"\n",
       "                                        \"hp.choice('kernel', \"\n",
       "                                        '[\\\\\\\\\\\\\"linear\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"rbf\\\\\\\\\\\\\", '\n",
       "                                        '\\\\\\\\\\\\\"sigmoid\\\\\\\\\\\\\"])\\\\\\\\n    '\n",
       "                                        '}\\\\\\\\n\\\\\\\\n    best=0\\\\\\\\n    def '\n",
       "                                        'hyperparameter_tuning(space):\\\\\\\\n        '\n",
       "                                        'global best\\\\\\\\n        acc = '\n",
       "                                        'model_accuracy(space)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'if acc \\\\u003e best:\\\\\\\\n            '\n",
       "                                        'best = acc\\\\\\\\n            print '\n",
       "                                        \"('new best:', best, \"\n",
       "                                        'space)\\\\\\\\n\\\\\\\\n        return '\n",
       "                                        \"{'loss': 1-acc, 'status': \"\n",
       "                                        'STATUS_OK}\\\\\\\\n\\\\\\\\n    trials = '\n",
       "                                        'Trials()\\\\\\\\n    best = '\n",
       "                                        'fmin(hyperparameter_tuning, space, '\n",
       "                                        'algo=tpe.suggest, '\n",
       "                                        'max_evals=hyperopt_iterations, '\n",
       "                                        'trials=trials)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'svm_hyperparams = space_eval(space, '\n",
       "                                        'best)\\\\\\\\n\\\\\\\\n    modfit_svm = '\n",
       "                                        'SVR(**svm_hyperparams)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'modfit_svm.fit(X_train, '\n",
       "                                        'y_train)\\\\\\\\n\\\\\\\\n    svm_mse = '\n",
       "                                        'mean_squared_error(y_test.to_numpy(), '\n",
       "                                        'modfit_svm.predict(X_test))\\\\\\\\n    '\n",
       "                                        'svm_accuracies = '\n",
       "                                        'cross_val_score(estimator = '\n",
       "                                        'modfit_svm, X = X_test, y = y_test, '\n",
       "                                        '\\\\\\\\n                                    '\n",
       "                                        'cv = 10)\\\\\\\\n    svm_r2 = '\n",
       "                                        'svm_accuracies.mean()\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'return(svm_mse, svm_r2, '\n",
       "                                        'svm_hyperparams)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_float(float_value: float) '\n",
       "                                        '-\\\\u003e str:\\\\\\\\n    if '\n",
       "                                        'isinstance(float_value, '\n",
       "                                        'str):\\\\\\\\n        return '\n",
       "                                        'float_value\\\\\\\\n    if not '\n",
       "                                        'isinstance(float_value, (float, '\n",
       "                                        'int)):\\\\\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" '\n",
       "                                        'has type \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" instead of '\n",
       "                                        \"float.'.format(\\\\\\\\n            \"\n",
       "                                        'str(float_value), '\n",
       "                                        'str(type(float_value))))\\\\\\\\n    '\n",
       "                                        'return str(float_value)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_json(obj) -\\\\u003e '\n",
       "                                        'str:\\\\\\\\n    if isinstance(obj, '\n",
       "                                        'str):\\\\\\\\n        return obj\\\\\\\\n    '\n",
       "                                        'import json\\\\\\\\n\\\\\\\\n    def '\n",
       "                                        'default_serializer(obj):\\\\\\\\n        '\n",
       "                                        'if hasattr(obj, '\n",
       "                                        \"'to_struct'):\\\\\\\\n            return \"\n",
       "                                        'obj.to_struct()\\\\\\\\n        '\n",
       "                                        'else:\\\\\\\\n            raise '\n",
       "                                        'TypeError(\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"Object of type \\'%s\\' is not '\n",
       "                                        'JSON serializable and does not have '\n",
       "                                        '.to_struct() '\n",
       "                                        'method.\\\\\\\\\\\\\"\\\\\\\\n                % '\n",
       "                                        'obj.__class__.__name__)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'return json.dumps(obj, '\n",
       "                                        'default=default_serializer, '\n",
       "                                        'sort_keys=True)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train \"\n",
       "                                        \"svm', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-x-train-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_x_train_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-y-train-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_y_train_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-x-test-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_x_test_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-y-test-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_y_test_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--hyperopt-iterations\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"hyperopt_iterations\\\\\\\\\\\\\", '\n",
       "                                        'type=int, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"----output-paths\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        'type=str, nargs=3)\\\\\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        '[])\\\\\\\\n\\\\\\\\n_outputs = '\n",
       "                                        'train_svm(**_parsed_args)\\\\\\\\n\\\\\\\\n_output_serializers '\n",
       "                                        '= [\\\\\\\\n    _serialize_float,\\\\\\\\n    '\n",
       "                                        '_serialize_float,\\\\\\\\n    '\n",
       "                                        '_serialize_json,\\\\\\\\n\\\\\\\\n]\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'os\\\\\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\\\\\n    '\n",
       "                                        'try:\\\\\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\\\\\n    '\n",
       "                                        'except OSError:\\\\\\\\n        '\n",
       "                                        'pass\\\\\\\\n    with open(output_file, '\n",
       "                                        \"'w') as f:\\\\\\\\n        \"\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_x_train_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_y_train_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_x_test_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_y_test_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"hyperopt_iterations\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"Integer\\\\\"}], '\n",
       "                                        '\\\\\"metadata\\\\\": {\\\\\"annotations\\\\\": '\n",
       "                                        '{\\\\\"author\\\\\": \\\\\"Antoine '\n",
       "                                        'Villatte\\\\\"}}, \\\\\"name\\\\\": \\\\\"Train '\n",
       "                                        'svm\\\\\", \\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"MSE\\\\\", \\\\\"type\\\\\": \\\\\"Float\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"R2\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"hyperparams\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"JsonObject\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'train_svm(input_x_train_csv, '\n",
       "                                        '\\\\n              input_y_train_csv, '\n",
       "                                        '\\\\n              input_x_test_csv, '\n",
       "                                        '\\\\n              '\n",
       "                                        'input_y_test_csv,\\\\n              '\n",
       "                                        'hyperopt_iterations\\\\n  ):\\\\n\\\\n    '\n",
       "                                        'global best\\\\n\\\\n    import pandas as '\n",
       "                                        'pd\\\\n    import xgboost as xgb\\\\n    '\n",
       "                                        'from sklearn.metrics import '\n",
       "                                        'mean_squared_error, '\n",
       "                                        'explained_variance_score, '\n",
       "                                        'r2_score\\\\n    from '\n",
       "                                        'sklearn.model_selection import '\n",
       "                                        'cross_val_score, KFold\\\\n    from '\n",
       "                                        'sklearn.svm import SVR\\\\n    import '\n",
       "                                        'hyperopt\\\\n    from hyperopt import '\n",
       "                                        'fmin, tpe, hp, STATUS_OK, Trials, '\n",
       "                                        'space_eval\\\\n    from random import '\n",
       "                                        'seed\\\\n\\\\n    X_train = '\n",
       "                                        'pd.read_csv(input_x_train_csv)\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'pd.read_csv(input_y_train_csv)\\\\n    '\n",
       "                                        'X_test = '\n",
       "                                        'pd.read_csv(input_x_test_csv)\\\\n    '\n",
       "                                        'y_test = '\n",
       "                                        'pd.read_csv(input_y_test_csv)\\\\n\\\\n    '\n",
       "                                        'seed(42)\\\\n    def '\n",
       "                                        'model_accuracy(params):\\\\n        '\n",
       "                                        'svm_reg = SVR(**params)\\\\n        '\n",
       "                                        'return cross_val_score(svm_reg, '\n",
       "                                        'X_train, y_train).mean()\\\\n\\\\n    '\n",
       "                                        \"space = {\\\\n        'C': \"\n",
       "                                        \"hp.quniform('C', 0.005, 1.0, \"\n",
       "                                        \"0.01),\\\\n        'degree': \"\n",
       "                                        \"hp.choice('degree', range(2, \"\n",
       "                                        \"6)),\\\\n        'coef0' : \"\n",
       "                                        \"hp.quniform('coef0', 0.5, 2, \"\n",
       "                                        \"0.2),\\\\n        'gamma' : \"\n",
       "                                        \"hp.quniform('gamma', 0.005, 0.1, \"\n",
       "                                        \"0.01),\\\\n        'kernel': \"\n",
       "                                        'hp.choice(\\'kernel\\', [\\\\\"linear\\\\\", '\n",
       "                                        '\\\\\"rbf\\\\\", \\\\\"sigmoid\\\\\"])\\\\n    '\n",
       "                                        '}\\\\n\\\\n    best=0\\\\n    def '\n",
       "                                        'hyperparameter_tuning(space):\\\\n        '\n",
       "                                        'global best\\\\n        acc = '\n",
       "                                        'model_accuracy(space)\\\\n\\\\n        if '\n",
       "                                        'acc \\\\u003e best:\\\\n            best '\n",
       "                                        \"= acc\\\\n            print ('new \"\n",
       "                                        \"best:', best, space)\\\\n\\\\n        \"\n",
       "                                        \"return {'loss': 1-acc, 'status': \"\n",
       "                                        'STATUS_OK}\\\\n\\\\n    trials = '\n",
       "                                        'Trials()\\\\n    best = '\n",
       "                                        'fmin(hyperparameter_tuning, space, '\n",
       "                                        'algo=tpe.suggest, '\n",
       "                                        'max_evals=hyperopt_iterations, '\n",
       "                                        'trials=trials)\\\\n\\\\n    '\n",
       "                                        'svm_hyperparams = space_eval(space, '\n",
       "                                        'best)\\\\n\\\\n    modfit_svm = '\n",
       "                                        'SVR(**svm_hyperparams)\\\\n\\\\n    '\n",
       "                                        'modfit_svm.fit(X_train, '\n",
       "                                        'y_train)\\\\n\\\\n    svm_mse = '\n",
       "                                        'mean_squared_error(y_test.to_numpy(), '\n",
       "                                        'modfit_svm.predict(X_test))\\\\n    '\n",
       "                                        'svm_accuracies = '\n",
       "                                        'cross_val_score(estimator = '\n",
       "                                        'modfit_svm, X = X_test, y = y_test, '\n",
       "                                        '\\\\n                                    '\n",
       "                                        'cv = 10)\\\\n    svm_r2 = '\n",
       "                                        'svm_accuracies.mean()\\\\n\\\\n    '\n",
       "                                        'return(svm_mse, svm_r2, '\n",
       "                                        'svm_hyperparams)\\\\n\\\\ndef '\n",
       "                                        '_serialize_float(float_value: float) '\n",
       "                                        '-\\\\u003e str:\\\\n    if '\n",
       "                                        'isinstance(float_value, '\n",
       "                                        'str):\\\\n        return '\n",
       "                                        'float_value\\\\n    if not '\n",
       "                                        'isinstance(float_value, (float, '\n",
       "                                        'int)):\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\"{}\\\\\" has type '\n",
       "                                        '\\\\\"{}\\\\\" instead of '\n",
       "                                        \"float.'.format(\\\\n            \"\n",
       "                                        'str(float_value), '\n",
       "                                        'str(type(float_value))))\\\\n    return '\n",
       "                                        'str(float_value)\\\\n\\\\ndef '\n",
       "                                        '_serialize_json(obj) -\\\\u003e '\n",
       "                                        'str:\\\\n    if isinstance(obj, '\n",
       "                                        'str):\\\\n        return obj\\\\n    '\n",
       "                                        'import json\\\\n\\\\n    def '\n",
       "                                        'default_serializer(obj):\\\\n        if '\n",
       "                                        'hasattr(obj, '\n",
       "                                        \"'to_struct'):\\\\n            return \"\n",
       "                                        'obj.to_struct()\\\\n        '\n",
       "                                        'else:\\\\n            raise '\n",
       "                                        'TypeError(\\\\n                '\n",
       "                                        '\\\\\"Object of type \\'%s\\' is not JSON '\n",
       "                                        'serializable and does not have '\n",
       "                                        '.to_struct() '\n",
       "                                        'method.\\\\\"\\\\n                % '\n",
       "                                        'obj.__class__.__name__)\\\\n\\\\n    '\n",
       "                                        'return json.dumps(obj, '\n",
       "                                        'default=default_serializer, '\n",
       "                                        'sort_keys=True)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train \"\n",
       "                                        \"svm', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--input-x-train-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_x_train_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-y-train-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_y_train_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-x-test-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_x_test_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-y-test-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_y_test_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--hyperopt-iterations\\\\\", '\n",
       "                                        'dest=\\\\\"hyperopt_iterations\\\\\", '\n",
       "                                        'type=int, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"----output-paths\\\\\", '\n",
       "                                        'dest=\\\\\"_output_paths\\\\\", type=str, '\n",
       "                                        'nargs=3)\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\"_output_paths\\\\\", '\n",
       "                                        '[])\\\\n\\\\n_outputs = '\n",
       "                                        'train_svm(**_parsed_args)\\\\n\\\\n_output_serializers '\n",
       "                                        '= [\\\\n    _serialize_float,\\\\n    '\n",
       "                                        '_serialize_float,\\\\n    '\n",
       "                                        '_serialize_json,\\\\n\\\\n]\\\\n\\\\nimport '\n",
       "                                        'os\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\n    '\n",
       "                                        'try:\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\n    '\n",
       "                                        'except OSError:\\\\n        pass\\\\n    '\n",
       "                                        \"with open(output_file, 'w') as \"\n",
       "                                        'f:\\\\n        '\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\n\"],\"args\":[\"--input-x-train-csv\",\"/tmp/inputs/input_x_train_csv/data\",\"--input-y-train-csv\",\"/tmp/inputs/input_y_train_csv/data\",\"--input-x-test-csv\",\"/tmp/inputs/input_x_test_csv/data\",\"--input-y-test-csv\",\"/tmp/inputs/input_y_test_csv/data\",\"--hyperopt-iterations\",\"{{inputs.parameters.hyperopt_iterations}}\",\"----output-paths\",\"/tmp/outputs/MSE/data\",\"/tmp/outputs/R2/data\",\"/tmp/outputs/hyperparams/data\"],\"resources\":{}}},{\"name\":\"train-xgb\",\"inputs\":{\"parameters\":[{\"name\":\"hyperopt_iterations\"}],\"artifacts\":[{\"name\":\"prepare-data-output_xtestcsv\",\"path\":\"/tmp/inputs/input_x_test_csv/data\"},{\"name\":\"prepare-data-output_xtraincsv\",\"path\":\"/tmp/inputs/input_x_train_csv/data\"},{\"name\":\"prepare-data-output_ytestcsv\",\"path\":\"/tmp/inputs/input_y_test_csv/data\"},{\"name\":\"prepare-data-output_ytraincsv\",\"path\":\"/tmp/inputs/input_y_train_csv/data\"}]},\"outputs\":{\"parameters\":[{\"name\":\"train-xgb-MSE\",\"valueFrom\":{\"path\":\"/tmp/outputs/MSE/data\"}},{\"name\":\"train-xgb-R2\",\"valueFrom\":{\"path\":\"/tmp/outputs/R2/data\"}},{\"name\":\"train-xgb-hyperparams\",\"valueFrom\":{\"path\":\"/tmp/outputs/hyperparams/data\"}}],\"artifacts\":[{\"name\":\"train-xgb-MSE\",\"path\":\"/tmp/outputs/MSE/data\"},{\"name\":\"train-xgb-R2\",\"path\":\"/tmp/outputs/R2/data\"},{\"name\":\"train-xgb-hyperparams\",\"path\":\"/tmp/outputs/hyperparams/data\"}]},\"metadata\":{\"annotations\":{\"author\":\"Antoine '\n",
       "                                        'Villatte\",\"pipelines.kubeflow.org/arguments.parameters\":\"{\\\\\"hyperopt_iterations\\\\\": '\n",
       "                                        '\\\\\"{{inputs.parameters.hyperopt_iterations}}\\\\\"}\",\"pipelines.kubeflow.org/component_ref\":\"{\\\\\"digest\\\\\": '\n",
       "                                        '\\\\\"54726d39870ed5af8bab1e59e028e9ca5571546fc01ba3174af4337f85a24981\\\\\", '\n",
       "                                        '\\\\\"url\\\\\": '\n",
       "                                        '\\\\\"./kf_utils/train_xgb_op.yaml\\\\\"}\",\"pipelines.kubeflow.org/component_spec\":\"{\\\\\"implementation\\\\\": '\n",
       "                                        '{\\\\\"container\\\\\": {\\\\\"args\\\\\": '\n",
       "                                        '[\\\\\"--input-x-train-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_x_train_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-y-train-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_y_train_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-x-test-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_x_test_csv\\\\\"}, '\n",
       "                                        '\\\\\"--input-y-test-csv\\\\\", '\n",
       "                                        '{\\\\\"inputPath\\\\\": '\n",
       "                                        '\\\\\"input_y_test_csv\\\\\"}, '\n",
       "                                        '\\\\\"--hyperopt-iterations\\\\\", '\n",
       "                                        '{\\\\\"inputValue\\\\\": '\n",
       "                                        '\\\\\"hyperopt_iterations\\\\\"}, '\n",
       "                                        '\\\\\"----output-paths\\\\\", '\n",
       "                                        '{\\\\\"outputPath\\\\\": \\\\\"MSE\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": \\\\\"R2\\\\\"}, '\n",
       "                                        '{\\\\\"outputPath\\\\\": '\n",
       "                                        '\\\\\"hyperparams\\\\\"}], \\\\\"command\\\\\": '\n",
       "                                        '[\\\\\"sh\\\\\", \\\\\"-ec\\\\\", '\n",
       "                                        '\\\\\"program_path=$(mktemp)\\\\\\\\nprintf '\n",
       "                                        '\\\\\\\\\\\\\"%s\\\\\\\\\\\\\" \\\\\\\\\\\\\"$0\\\\\\\\\\\\\" '\n",
       "                                        '\\\\u003e '\n",
       "                                        '\\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\"\\\\\\\\npython3 '\n",
       "                                        '-u \\\\\\\\\\\\\"$program_path\\\\\\\\\\\\\" '\n",
       "                                        '\\\\\\\\\\\\\"$@\\\\\\\\\\\\\"\\\\\\\\n\\\\\", \\\\\"def '\n",
       "                                        'train_xgb(input_x_train_csv, '\n",
       "                                        '\\\\\\\\n              input_y_train_csv, '\n",
       "                                        '\\\\\\\\n              input_x_test_csv, '\n",
       "                                        '\\\\\\\\n              '\n",
       "                                        'input_y_test_csv,\\\\\\\\n              '\n",
       "                                        'hyperopt_iterations\\\\\\\\n  '\n",
       "                                        '):\\\\\\\\n\\\\\\\\n    global '\n",
       "                                        'best\\\\\\\\n\\\\\\\\n    import pandas as '\n",
       "                                        'pd\\\\\\\\n    import xgboost as '\n",
       "                                        'xgb\\\\\\\\n    from sklearn.metrics '\n",
       "                                        'import mean_squared_error, '\n",
       "                                        'explained_variance_score, '\n",
       "                                        'r2_score\\\\\\\\n    from '\n",
       "                                        'sklearn.model_selection import '\n",
       "                                        'cross_val_score, KFold\\\\\\\\n    from '\n",
       "                                        'sklearn.svm import SVR\\\\\\\\n    import '\n",
       "                                        'hyperopt\\\\\\\\n    from hyperopt import '\n",
       "                                        'fmin, tpe, hp, STATUS_OK, Trials, '\n",
       "                                        'space_eval\\\\\\\\n    from random import '\n",
       "                                        'seed\\\\\\\\n\\\\\\\\n    X_train = '\n",
       "                                        'pd.read_csv(input_x_train_csv)\\\\\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'pd.read_csv(input_y_train_csv)\\\\\\\\n    '\n",
       "                                        'X_test = '\n",
       "                                        'pd.read_csv(input_x_test_csv)\\\\\\\\n    '\n",
       "                                        'y_test = '\n",
       "                                        'pd.read_csv(input_y_test_csv)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'seed(42)\\\\\\\\n    def '\n",
       "                                        'model_accuracy(params):\\\\\\\\n        '\n",
       "                                        'xgb_reg = xgb.XGBRegressor(objective '\n",
       "                                        '= '\n",
       "                                        '\\\\\\\\\\\\\"reg:squarederror\\\\\\\\\\\\\",\\\\\\\\n                                   '\n",
       "                                        'tree_method = '\n",
       "                                        \"'hist',\\\\\\\\n                                   \"\n",
       "                                        'eval_metric = '\n",
       "                                        '[\\\\\\\\\\\\\"rmse\\\\\\\\\\\\\"],\\\\\\\\n                                   '\n",
       "                                        '**params)\\\\\\\\n        return '\n",
       "                                        'cross_val_score(xgb_reg, X_train, '\n",
       "                                        'y_train).mean()\\\\\\\\n\\\\\\\\n    space = '\n",
       "                                        \"{\\\\\\\\n        'max_depth' : \"\n",
       "                                        \"hp.choice('max_depth', range(1, 30, \"\n",
       "                                        \"1)),\\\\\\\\n        'learning_rate' : \"\n",
       "                                        \"hp.quniform('learning_rate', 0.01, \"\n",
       "                                        '0.5, 0.01),\\\\\\\\n        '\n",
       "                                        \"'n_estimators' : \"\n",
       "                                        \"hp.choice('n_estimators', range(20, \"\n",
       "                                        \"205, 5)),\\\\\\\\n        'gamma' : \"\n",
       "                                        \"hp.quniform('gamma', 0, 0.50, \"\n",
       "                                        \"0.01),\\\\\\\\n        'min_child_weight' \"\n",
       "                                        \": hp.quniform('min_child_weight', 1, \"\n",
       "                                        \"10, 1),\\\\\\\\n        'subsample' : \"\n",
       "                                        \"hp.quniform('subsample', 0.1, 1, \"\n",
       "                                        \"0.01),\\\\\\\\n        'colsample_bytree' \"\n",
       "                                        \": hp.quniform('colsample_bytree', \"\n",
       "                                        '0.1, 1.0, 0.01),\\\\\\\\n        '\n",
       "                                        \"'colsample_bylevel' : \"\n",
       "                                        \"hp.quniform('colsample_bylevel', 0.1, \"\n",
       "                                        '1.0, 0.01),\\\\\\\\n        '\n",
       "                                        \"'colsample_bynode' : \"\n",
       "                                        \"hp.quniform('colsample_bynode', 0.1, \"\n",
       "                                        '1.0, 0.01),\\\\\\\\n        '\n",
       "                                        \"'max_delta_step' : \"\n",
       "                                        \"hp.choice('max_delta_step', range(0, \"\n",
       "                                        '11, 1))\\\\\\\\n    }\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'best=0\\\\\\\\n    def '\n",
       "                                        'hyperparameter_tuning(space):\\\\\\\\n        '\n",
       "                                        'global best\\\\\\\\n        acc = '\n",
       "                                        'model_accuracy(space)\\\\\\\\n\\\\\\\\n        '\n",
       "                                        'if acc \\\\u003e best:\\\\\\\\n            '\n",
       "                                        'best = acc\\\\\\\\n            print '\n",
       "                                        \"('new best:', best, \"\n",
       "                                        'space)\\\\\\\\n\\\\\\\\n        return '\n",
       "                                        \"{'loss': 1-acc, 'status': \"\n",
       "                                        'STATUS_OK}\\\\\\\\n\\\\\\\\n    trials = '\n",
       "                                        'Trials()\\\\\\\\n    best = '\n",
       "                                        'fmin(hyperparameter_tuning, space, '\n",
       "                                        'algo=tpe.suggest, '\n",
       "                                        'max_evals=hyperopt_iterations, '\n",
       "                                        'trials=trials)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'xgb_hyperparams = space_eval(space, '\n",
       "                                        'best)\\\\\\\\n\\\\\\\\n    modfit_xgb = '\n",
       "                                        'xgb.XGBRegressor(objective = '\n",
       "                                        '\\\\\\\\\\\\\"reg:squarederror\\\\\\\\\\\\\",\\\\\\\\n                                      '\n",
       "                                        'tree_method = '\n",
       "                                        \"'hist',\\\\\\\\n                                      \"\n",
       "                                        'eval_metric = '\n",
       "                                        '[\\\\\\\\\\\\\"rmse\\\\\\\\\\\\\"],\\\\\\\\n                                      '\n",
       "                                        '**xgb_hyperparams)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'modfit_xgb.fit(X_train, '\n",
       "                                        'y_train)\\\\\\\\n\\\\\\\\n    xgb_mse = '\n",
       "                                        'mean_squared_error(y_test.to_numpy(), '\n",
       "                                        'modfit_xgb.predict(X_test))\\\\\\\\n    '\n",
       "                                        'xgb_accuracies = '\n",
       "                                        'cross_val_score(estimator = '\n",
       "                                        'modfit_xgb, X = X_test, y = y_test, '\n",
       "                                        '\\\\\\\\n                                    '\n",
       "                                        'cv = 10)\\\\\\\\n    xgb_r2 = '\n",
       "                                        'xgb_accuracies.mean()\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'return(xgb_mse, xgb_r2, '\n",
       "                                        'xgb_hyperparams)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_float(float_value: float) '\n",
       "                                        '-\\\\u003e str:\\\\\\\\n    if '\n",
       "                                        'isinstance(float_value, '\n",
       "                                        'str):\\\\\\\\n        return '\n",
       "                                        'float_value\\\\\\\\n    if not '\n",
       "                                        'isinstance(float_value, (float, '\n",
       "                                        'int)):\\\\\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" '\n",
       "                                        'has type \\\\\\\\\\\\\"{}\\\\\\\\\\\\\" instead of '\n",
       "                                        \"float.'.format(\\\\\\\\n            \"\n",
       "                                        'str(float_value), '\n",
       "                                        'str(type(float_value))))\\\\\\\\n    '\n",
       "                                        'return str(float_value)\\\\\\\\n\\\\\\\\ndef '\n",
       "                                        '_serialize_json(obj) -\\\\u003e '\n",
       "                                        'str:\\\\\\\\n    if isinstance(obj, '\n",
       "                                        'str):\\\\\\\\n        return obj\\\\\\\\n    '\n",
       "                                        'import json\\\\\\\\n\\\\\\\\n    def '\n",
       "                                        'default_serializer(obj):\\\\\\\\n        '\n",
       "                                        'if hasattr(obj, '\n",
       "                                        \"'to_struct'):\\\\\\\\n            return \"\n",
       "                                        'obj.to_struct()\\\\\\\\n        '\n",
       "                                        'else:\\\\\\\\n            raise '\n",
       "                                        'TypeError(\\\\\\\\n                '\n",
       "                                        '\\\\\\\\\\\\\"Object of type \\'%s\\' is not '\n",
       "                                        'JSON serializable and does not have '\n",
       "                                        '.to_struct() '\n",
       "                                        'method.\\\\\\\\\\\\\"\\\\\\\\n                % '\n",
       "                                        'obj.__class__.__name__)\\\\\\\\n\\\\\\\\n    '\n",
       "                                        'return json.dumps(obj, '\n",
       "                                        'default=default_serializer, '\n",
       "                                        'sort_keys=True)\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'argparse\\\\\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train \"\n",
       "                                        \"xgb', \"\n",
       "                                        'description=\\'\\')\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-x-train-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_x_train_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-y-train-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_y_train_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-x-test-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_x_test_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--input-y-test-csv\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"input_y_test_csv\\\\\\\\\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"--hyperopt-iterations\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"hyperopt_iterations\\\\\\\\\\\\\", '\n",
       "                                        'type=int, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\\\\\n_parser.add_argument(\\\\\\\\\\\\\"----output-paths\\\\\\\\\\\\\", '\n",
       "                                        'dest=\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        'type=str, nargs=3)\\\\\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\\\\\\\\\"_output_paths\\\\\\\\\\\\\", '\n",
       "                                        '[])\\\\\\\\n\\\\\\\\n_outputs = '\n",
       "                                        'train_xgb(**_parsed_args)\\\\\\\\n\\\\\\\\n_output_serializers '\n",
       "                                        '= [\\\\\\\\n    _serialize_float,\\\\\\\\n    '\n",
       "                                        '_serialize_float,\\\\\\\\n    '\n",
       "                                        '_serialize_json,\\\\\\\\n\\\\\\\\n]\\\\\\\\n\\\\\\\\nimport '\n",
       "                                        'os\\\\\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\\\\\n    '\n",
       "                                        'try:\\\\\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\\\\\n    '\n",
       "                                        'except OSError:\\\\\\\\n        '\n",
       "                                        'pass\\\\\\\\n    with open(output_file, '\n",
       "                                        \"'w') as f:\\\\\\\\n        \"\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\\\\\n\\\\\"], '\n",
       "                                        '\\\\\"image\\\\\": '\n",
       "                                        '\\\\\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\\\\\"}}, '\n",
       "                                        '\\\\\"inputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_x_train_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_y_train_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_x_test_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"input_y_test_csv\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"CSV\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"hyperopt_iterations\\\\\", '\n",
       "                                        '\\\\\"type\\\\\": \\\\\"Integer\\\\\"}], '\n",
       "                                        '\\\\\"metadata\\\\\": {\\\\\"annotations\\\\\": '\n",
       "                                        '{\\\\\"author\\\\\": \\\\\"Antoine '\n",
       "                                        'Villatte\\\\\"}}, \\\\\"name\\\\\": \\\\\"Train '\n",
       "                                        'xgb\\\\\", \\\\\"outputs\\\\\": [{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"MSE\\\\\", \\\\\"type\\\\\": \\\\\"Float\\\\\"}, '\n",
       "                                        '{\\\\\"name\\\\\": \\\\\"R2\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"Float\\\\\"}, {\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"hyperparams\\\\\", \\\\\"type\\\\\": '\n",
       "                                        '\\\\\"JsonObject\\\\\"}]}\"},\"labels\":{\"pipelines.kubeflow.org/enable_caching\":\"true\",\"pipelines.kubeflow.org/kfp_sdk_version\":\"1.8.10\",\"pipelines.kubeflow.org/pipeline-sdk-type\":\"kfp\"}},\"container\":{\"name\":\"\",\"image\":\"public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'train_xgb(input_x_train_csv, '\n",
       "                                        '\\\\n              input_y_train_csv, '\n",
       "                                        '\\\\n              input_x_test_csv, '\n",
       "                                        '\\\\n              '\n",
       "                                        'input_y_test_csv,\\\\n              '\n",
       "                                        'hyperopt_iterations\\\\n  ):\\\\n\\\\n    '\n",
       "                                        'global best\\\\n\\\\n    import pandas as '\n",
       "                                        'pd\\\\n    import xgboost as xgb\\\\n    '\n",
       "                                        'from sklearn.metrics import '\n",
       "                                        'mean_squared_error, '\n",
       "                                        'explained_variance_score, '\n",
       "                                        'r2_score\\\\n    from '\n",
       "                                        'sklearn.model_selection import '\n",
       "                                        'cross_val_score, KFold\\\\n    from '\n",
       "                                        'sklearn.svm import SVR\\\\n    import '\n",
       "                                        'hyperopt\\\\n    from hyperopt import '\n",
       "                                        'fmin, tpe, hp, STATUS_OK, Trials, '\n",
       "                                        'space_eval\\\\n    from random import '\n",
       "                                        'seed\\\\n\\\\n    X_train = '\n",
       "                                        'pd.read_csv(input_x_train_csv)\\\\n    '\n",
       "                                        'y_train = '\n",
       "                                        'pd.read_csv(input_y_train_csv)\\\\n    '\n",
       "                                        'X_test = '\n",
       "                                        'pd.read_csv(input_x_test_csv)\\\\n    '\n",
       "                                        'y_test = '\n",
       "                                        'pd.read_csv(input_y_test_csv)\\\\n\\\\n    '\n",
       "                                        'seed(42)\\\\n    def '\n",
       "                                        'model_accuracy(params):\\\\n        '\n",
       "                                        'xgb_reg = xgb.XGBRegressor(objective '\n",
       "                                        '= '\n",
       "                                        '\\\\\"reg:squarederror\\\\\",\\\\n                                   '\n",
       "                                        'tree_method = '\n",
       "                                        \"'hist',\\\\n                                   \"\n",
       "                                        'eval_metric = '\n",
       "                                        '[\\\\\"rmse\\\\\"],\\\\n                                   '\n",
       "                                        '**params)\\\\n        return '\n",
       "                                        'cross_val_score(xgb_reg, X_train, '\n",
       "                                        'y_train).mean()\\\\n\\\\n    space = '\n",
       "                                        \"{\\\\n        'max_depth' : \"\n",
       "                                        \"hp.choice('max_depth', range(1, 30, \"\n",
       "                                        \"1)),\\\\n        'learning_rate' : \"\n",
       "                                        \"hp.quniform('learning_rate', 0.01, \"\n",
       "                                        \"0.5, 0.01),\\\\n        'n_estimators' \"\n",
       "                                        \": hp.choice('n_estimators', range(20, \"\n",
       "                                        \"205, 5)),\\\\n        'gamma' : \"\n",
       "                                        \"hp.quniform('gamma', 0, 0.50, \"\n",
       "                                        \"0.01),\\\\n        'min_child_weight' : \"\n",
       "                                        \"hp.quniform('min_child_weight', 1, \"\n",
       "                                        \"10, 1),\\\\n        'subsample' : \"\n",
       "                                        \"hp.quniform('subsample', 0.1, 1, \"\n",
       "                                        \"0.01),\\\\n        'colsample_bytree' : \"\n",
       "                                        \"hp.quniform('colsample_bytree', 0.1, \"\n",
       "                                        '1.0, 0.01),\\\\n        '\n",
       "                                        \"'colsample_bylevel' : \"\n",
       "                                        \"hp.quniform('colsample_bylevel', 0.1, \"\n",
       "                                        '1.0, 0.01),\\\\n        '\n",
       "                                        \"'colsample_bynode' : \"\n",
       "                                        \"hp.quniform('colsample_bynode', 0.1, \"\n",
       "                                        '1.0, 0.01),\\\\n        '\n",
       "                                        \"'max_delta_step' : \"\n",
       "                                        \"hp.choice('max_delta_step', range(0, \"\n",
       "                                        '11, 1))\\\\n    }\\\\n\\\\n    best=0\\\\n    '\n",
       "                                        'def '\n",
       "                                        'hyperparameter_tuning(space):\\\\n        '\n",
       "                                        'global best\\\\n        acc = '\n",
       "                                        'model_accuracy(space)\\\\n\\\\n        if '\n",
       "                                        'acc \\\\u003e best:\\\\n            best '\n",
       "                                        \"= acc\\\\n            print ('new \"\n",
       "                                        \"best:', best, space)\\\\n\\\\n        \"\n",
       "                                        \"return {'loss': 1-acc, 'status': \"\n",
       "                                        'STATUS_OK}\\\\n\\\\n    trials = '\n",
       "                                        'Trials()\\\\n    best = '\n",
       "                                        'fmin(hyperparameter_tuning, space, '\n",
       "                                        'algo=tpe.suggest, '\n",
       "                                        'max_evals=hyperopt_iterations, '\n",
       "                                        'trials=trials)\\\\n\\\\n    '\n",
       "                                        'xgb_hyperparams = space_eval(space, '\n",
       "                                        'best)\\\\n\\\\n    modfit_xgb = '\n",
       "                                        'xgb.XGBRegressor(objective = '\n",
       "                                        '\\\\\"reg:squarederror\\\\\",\\\\n                                      '\n",
       "                                        'tree_method = '\n",
       "                                        \"'hist',\\\\n                                      \"\n",
       "                                        'eval_metric = '\n",
       "                                        '[\\\\\"rmse\\\\\"],\\\\n                                      '\n",
       "                                        '**xgb_hyperparams)\\\\n\\\\n    '\n",
       "                                        'modfit_xgb.fit(X_train, '\n",
       "                                        'y_train)\\\\n\\\\n    xgb_mse = '\n",
       "                                        'mean_squared_error(y_test.to_numpy(), '\n",
       "                                        'modfit_xgb.predict(X_test))\\\\n    '\n",
       "                                        'xgb_accuracies = '\n",
       "                                        'cross_val_score(estimator = '\n",
       "                                        'modfit_xgb, X = X_test, y = y_test, '\n",
       "                                        '\\\\n                                    '\n",
       "                                        'cv = 10)\\\\n    xgb_r2 = '\n",
       "                                        'xgb_accuracies.mean()\\\\n\\\\n    '\n",
       "                                        'return(xgb_mse, xgb_r2, '\n",
       "                                        'xgb_hyperparams)\\\\n\\\\ndef '\n",
       "                                        '_serialize_float(float_value: float) '\n",
       "                                        '-\\\\u003e str:\\\\n    if '\n",
       "                                        'isinstance(float_value, '\n",
       "                                        'str):\\\\n        return '\n",
       "                                        'float_value\\\\n    if not '\n",
       "                                        'isinstance(float_value, (float, '\n",
       "                                        'int)):\\\\n        raise '\n",
       "                                        'TypeError(\\'Value \\\\\"{}\\\\\" has type '\n",
       "                                        '\\\\\"{}\\\\\" instead of '\n",
       "                                        \"float.'.format(\\\\n            \"\n",
       "                                        'str(float_value), '\n",
       "                                        'str(type(float_value))))\\\\n    return '\n",
       "                                        'str(float_value)\\\\n\\\\ndef '\n",
       "                                        '_serialize_json(obj) -\\\\u003e '\n",
       "                                        'str:\\\\n    if isinstance(obj, '\n",
       "                                        'str):\\\\n        return obj\\\\n    '\n",
       "                                        'import json\\\\n\\\\n    def '\n",
       "                                        'default_serializer(obj):\\\\n        if '\n",
       "                                        'hasattr(obj, '\n",
       "                                        \"'to_struct'):\\\\n            return \"\n",
       "                                        'obj.to_struct()\\\\n        '\n",
       "                                        'else:\\\\n            raise '\n",
       "                                        'TypeError(\\\\n                '\n",
       "                                        '\\\\\"Object of type \\'%s\\' is not JSON '\n",
       "                                        'serializable and does not have '\n",
       "                                        '.to_struct() '\n",
       "                                        'method.\\\\\"\\\\n                % '\n",
       "                                        'obj.__class__.__name__)\\\\n\\\\n    '\n",
       "                                        'return json.dumps(obj, '\n",
       "                                        'default=default_serializer, '\n",
       "                                        'sort_keys=True)\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Train \"\n",
       "                                        \"xgb', \"\n",
       "                                        'description=\\'\\')\\\\n_parser.add_argument(\\\\\"--input-x-train-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_x_train_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-y-train-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_y_train_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-x-test-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_x_test_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--input-y-test-csv\\\\\", '\n",
       "                                        'dest=\\\\\"input_y_test_csv\\\\\", '\n",
       "                                        'type=str, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"--hyperopt-iterations\\\\\", '\n",
       "                                        'dest=\\\\\"hyperopt_iterations\\\\\", '\n",
       "                                        'type=int, required=True, '\n",
       "                                        'default=argparse.SUPPRESS)\\\\n_parser.add_argument(\\\\\"----output-paths\\\\\", '\n",
       "                                        'dest=\\\\\"_output_paths\\\\\", type=str, '\n",
       "                                        'nargs=3)\\\\n_parsed_args = '\n",
       "                                        'vars(_parser.parse_args())\\\\n_output_files '\n",
       "                                        '= '\n",
       "                                        '_parsed_args.pop(\\\\\"_output_paths\\\\\", '\n",
       "                                        '[])\\\\n\\\\n_outputs = '\n",
       "                                        'train_xgb(**_parsed_args)\\\\n\\\\n_output_serializers '\n",
       "                                        '= [\\\\n    _serialize_float,\\\\n    '\n",
       "                                        '_serialize_float,\\\\n    '\n",
       "                                        '_serialize_json,\\\\n\\\\n]\\\\n\\\\nimport '\n",
       "                                        'os\\\\nfor idx, output_file in '\n",
       "                                        'enumerate(_output_files):\\\\n    '\n",
       "                                        'try:\\\\n        '\n",
       "                                        'os.makedirs(os.path.dirname(output_file))\\\\n    '\n",
       "                                        'except OSError:\\\\n        pass\\\\n    '\n",
       "                                        \"with open(output_file, 'w') as \"\n",
       "                                        'f:\\\\n        '\n",
       "                                        'f.write(_output_serializers[idx](_outputs[idx]))\\\\n\"],\"args\":[\"--input-x-train-csv\",\"/tmp/inputs/input_x_train_csv/data\",\"--input-y-train-csv\",\"/tmp/inputs/input_y_train_csv/data\",\"--input-x-test-csv\",\"/tmp/inputs/input_x_test_csv/data\",\"--input-y-test-csv\",\"/tmp/inputs/input_y_test_csv/data\",\"--hyperopt-iterations\",\"{{inputs.parameters.hyperopt_iterations}}\",\"----output-paths\",\"/tmp/outputs/MSE/data\",\"/tmp/outputs/R2/data\",\"/tmp/outputs/hyperparams/data\"],\"resources\":{}}}],\"entrypoint\":\"emission-prediction-pipeline\",\"arguments\":{\"parameters\":[{\"name\":\"bucket\"},{\"name\":\"data_2015\"},{\"name\":\"data_2016\"},{\"name\":\"hyperopt_iterations\"},{\"name\":\"subfolder\"}]},\"serviceAccountName\":\"pipeline-runner\"},\"status\":{\"startedAt\":null,\"finishedAt\":null}}'},\n",
       " 'resource_references': [{'key': {'id': 'fe0390c9-a311-4248-89e2-72522f17c26c',\n",
       "                                  'type': 'EXPERIMENT'},\n",
       "                          'name': 'Emission_experiments',\n",
       "                          'relationship': 'OWNER'},\n",
       "                         {'key': {'id': '3ac54c42-f463-49cb-9cf3-8b1eb14b7eae',\n",
       "                                  'type': 'PIPELINE_VERSION'},\n",
       "                          'name': 'test_from_jupyter',\n",
       "                          'relationship': 'CREATOR'}],\n",
       " 'scheduled_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzutc()),\n",
       " 'service_account': 'default-editor',\n",
       " 'status': None,\n",
       " 'storage_state': None}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.run_pipeline(experiment_id=experiment_id,\n",
    "                   job_name=job_name,\n",
    "                   params=params,\n",
    "                   pipeline_id=pipeline_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=http://f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/pipeline/#/pipelines/details/c7b8b900-dc86-4368-92c0-93829fb2179a>Pipeline details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "today = str(datetime.now())\n",
    "version_name = \"update-pipeline-\" + today\n",
    "desc = 'updated on {} from jupyter'.format(str(date.today()))\n",
    "\n",
    "updade_pipe = client.upload_pipeline_version(pipeline_package_path=\"./pipeline.yaml\",\n",
    "                              pipeline_version_name=version_name,\n",
    "                               pipeline_name = \"test_from_jupyter_NEW\")\n",
    "                              #pipeline_id='bc6f946d-30ce-453c-b08e-84030f87163d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bc6f946d-30ce-453c-b08e-84030f87163d'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_id(str(updade_pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Signature:\n",
    "kfp.Client.upload_pipeline_version(\n",
    "    self,\n",
    "    pipeline_package_path,\n",
    "    pipeline_version_name: str,\n",
    "    pipeline_id: Union[str, NoneType] = None,\n",
    "    pipeline_name: Union[str, NoneType] = None,\n",
    "    description: Union[str, NoneType] = None,\n",
    ") -> kfp_server_api.models.api_pipeline_version.ApiPipelineVersion\n",
    "Docstring:\n",
    "Uploads a new version of the pipeline to the Kubeflow Pipelines cluster.\n",
    "\n",
    "Args:\n",
    "  pipeline_package_path: Local path to the pipeline package.\n",
    "  pipeline_version_name:  Name of the pipeline version to be shown in the UI.\n",
    "  pipeline_id: Optional. Id of the pipeline.\n",
    "  pipeline_name: Optional. Name of the pipeline.\n",
    "  description: Optional. Description of the pipeline version to be shown in the UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "today = str(today.year) + \"-\" + str(today.month) + \"-\" + str(today.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-01-28'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-01-28 16:57:52.701631'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cookiejar' has no attribute 'CookieJar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e6dbc3bb7b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpassword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'12341234'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcookiejar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCookieJar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPCookieProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlogin_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'username'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'j_password'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cookiejar' has no attribute 'CookieJar'"
     ]
    }
   ],
   "source": [
    "import urllib, cookiejar\n",
    "\n",
    "username = 'admin@kubeflow.org'\n",
    "password = '12341234'\n",
    "\n",
    "cj = cookiejar.CookieJar()\n",
    "opener = urllib.build_opener(urllib2.HTTPCookieProcessor(cj))\n",
    "login_data = urllib.urlencode({'username' : username, 'j_password' : password})\n",
    "opener.open('http://f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/dex/auth/local?req=dvcqbyl6ybhhxb3ldce7evhub', login_data)\n",
    "resp = opener.open('http://f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/?ns=admin')\n",
    "print(resp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "from requests import session\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "EMAIL = 'admin@kubeflow.org'\n",
    "PASSWORD = '12341234'\n",
    "\n",
    "URL = 'http://f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/'\n",
    "\n",
    "def main():\n",
    "    # Start a session so we can have persistant cookies\n",
    "    session = requests.session()\n",
    "\n",
    "    # This is the form data that the page sends when logging in\n",
    "    login_data = {\n",
    "        'login': EMAIL,\n",
    "        'password': PASSWORD,\n",
    "        'submit': 'login',\n",
    "    }\n",
    "\n",
    "    # Authenticate\n",
    "    r = session.post(URL, data=login_data)\n",
    "\n",
    "    # Try accessing a page that requires you to be logged in\n",
    "    r = session.get('http://f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/_/jupyter/?ns=admin')\n",
    "\n",
    "    print(r)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cookie(text):\n",
    "    \"\"\"\n",
    "    Function that retrieves login cookie\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        string version of the logs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str : cookie value.\n",
    "\n",
    "    \"\"\"\n",
    "    match = re.search('authservice_session=(.+?) ', text)        \n",
    "    if match:\n",
    "        found = match.group(1)\n",
    "        return(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MTY0MzYzOTU3OHxOd3dBTkROV1JWTlBXbFpRVGxoVFVsUlBSa2hNU3pORFNUYzBVRFZXTTB0WFVWWTBXa1ZEVkZvM04wTkpSVkkwU2s1QlZGVkVVa0U9fEa0lCWonkFmWsW11VLQG3F4N56mhdtJTSO5UTEDQK_3'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mechanize\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import http.cookiejar as cookielib ## http.cookiejar in python3\n",
    "import re\n",
    "\n",
    "cj = cookielib.CookieJar()\n",
    "br = mechanize.Browser()\n",
    "br.set_cookiejar(cj)\n",
    "br.open(URL)\n",
    "\n",
    "br.select_form(nr=0)\n",
    "br.form['login'] = EMAIL\n",
    "br.form['password'] = PASSWORD\n",
    "br.submit()\n",
    "\n",
    "get_cookie(str(cj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<CookieJar[<Cookie authservice_session=MTY0MzYzOTU3OHxOd3dBTkROV1JWTlBXbFpRVGxoVFVsUlBSa2hNU3pORFNUYzBVRFZXTTB0WFVWWTBXa1ZEVkZvM04wTkpSVkkwU2s1QlZGVkVVa0U9fEa0lCWonkFmWsW11VLQG3F4N56mhdtJTSO5UTEDQK_3 for f3f6f1e6-istiosystem-istio-2af2-1570305981.eu-west-1.elb.amazonaws.com/>]>'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(cj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiments': [{'created_at': datetime.datetime(2022, 1, 17, 10, 59, 39, tzinfo=tzutc()),\n",
       "                  'description': None,\n",
       "                  'id': '4786bc8c-05be-4594-a6c2-036690d963e7',\n",
       "                  'name': 'test',\n",
       "                  'resource_references': [{'key': {'id': 'admin',\n",
       "                                                   'type': 'NAMESPACE'},\n",
       "                                           'name': None,\n",
       "                                           'relationship': 'OWNER'}],\n",
       "                  'storage_state': 'STORAGESTATE_AVAILABLE'},\n",
       "                 {'created_at': datetime.datetime(2022, 1, 21, 19, 4, 1, tzinfo=tzutc()),\n",
       "                  'description': None,\n",
       "                  'id': '743a78d1-3f92-4571-810f-1be5f2339188',\n",
       "                  'name': 'exp1',\n",
       "                  'resource_references': [{'key': {'id': 'admin',\n",
       "                                                   'type': 'NAMESPACE'},\n",
       "                                           'name': None,\n",
       "                                           'relationship': 'OWNER'}],\n",
       "                  'storage_state': 'STORAGESTATE_AVAILABLE'},\n",
       "                 {'created_at': datetime.datetime(2022, 1, 27, 17, 25, 25, tzinfo=tzutc()),\n",
       "                  'description': None,\n",
       "                  'id': 'fe0390c9-a311-4248-89e2-72522f17c26c',\n",
       "                  'name': 'Emission_experiments',\n",
       "                  'resource_references': [{'key': {'id': 'admin',\n",
       "                                                   'type': 'NAMESPACE'},\n",
       "                                           'name': None,\n",
       "                                           'relationship': 'OWNER'}],\n",
       "                  'storage_state': 'STORAGESTATE_AVAILABLE'},\n",
       "                 {'created_at': datetime.datetime(2022, 1, 27, 19, 42, 5, tzinfo=tzutc()),\n",
       "                  'description': None,\n",
       "                  'id': 'b9926e1f-b23a-43d0-ab9b-cf843ff45080',\n",
       "                  'name': 'Recurring_runs',\n",
       "                  'resource_references': [{'key': {'id': 'admin',\n",
       "                                                   'type': 'NAMESPACE'},\n",
       "                                           'name': None,\n",
       "                                           'relationship': 'OWNER'}],\n",
       "                  'storage_state': 'STORAGESTATE_AVAILABLE'}],\n",
       " 'next_page_token': None,\n",
       " 'total_size': 4}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authservice_session='authservice_session=MTY0MzYzOTU3OHxOd3dBTkROV1JWTlBXbFpRVGxoVFVsUlBSa2hNU3pORFNUYzBVRFZXTTB0WFVWWTBXa1ZEVkZvM04wTkpSVkkwU2s1QlZGVkVVa0U9fEa0lCWonkFmWsW11VLQG3F4N56mhdtJTSO5UTEDQK_3'\n",
    "client = kfp.Client(host=ENDPOINT, cookies=authservice_session)\n",
    "client.list_experiments(namespace=\"admin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

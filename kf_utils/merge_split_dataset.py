import kfp.components as comp



def merge_and_split(bucket : str, 
                    data_2015 : str, 
                    data_2016 : str, 
                    output_edfcsv : comp.OutputPath('CSV')):
    
    import pandas as pd
    import re
    import boto3
    from io import StringIO
    from sklearn.model_selection import GroupShuffleSplit
    
    def get_location(text, method):
        """Retrieves data from the 2015 dataset to harmonize it with the 2016 dataset"""
        if method == "latitude":
            match = re.search('{\'latitude\': \'(.+?)\', \'longitude', text)
        elif method == "longitude":
            match = re.search('[0-9]\', \'longitude\': \'(.+?)\', \'human_address\'', text)
        elif method == "address":
            match = re.search('\'{"address": "(.+?)", "city":', text)      
        elif method == "city":
            match = re.search('", "city": "(.+?)", "state":', text)
        elif method == "state":
            match = re.search('"state": "(.+?)", "zip":', text)
        elif method == "zip":
            match = re.search('"zip": "(.+?)"}\'}', text)
        else:
            raise ValueError("Veuillez choisir une m√©thode (latitude, longitude, adress, city, state, zip)")
            
        if match:
            found = match.group(1)
            return(found)
        return("N/A")

    # Load datasets
    csv_strings = {}
    encoding = 'utf-8'
    for source_data, year in zip([data_2015, data_2016], ["2015", "2016"]):
        csv_obj = boto3.client('s3').get_object(Bucket=bucket, Key=source_data)
        body = csv_obj['Body']
        csv_string = body.read().decode(encoding)
        csv_strings[year] = csv_string
        
    data15 = pd.read_csv(StringIO(csv_strings["2015"]))
    data16 = pd.read_csv(StringIO(csv_strings["2016"]))

    # Rename mismatched columns
    rename_cols = {
        "GHGEmissions(MetricTonsCO2e)" : "TotalGHGEmissions",
        "GHGEmissionsIntensity(kgCO2e/ft2)" : "GHGEmissionsIntensity",
        "Comment" : "Comments"
    }
    data15.rename(columns = rename_cols, inplace = True)

    # Extract location info from 2015 dataset to harmonize it
    data15["Latitude"] = data15["Location"].apply(get_location, method = "latitude")
    data15["Longitude"] = data15["Location"].apply(get_location, method = "longitude")
    data15["Address"] = data15["Location"].apply(get_location, method = "address")
    data15["City"] = data15["Location"].apply(get_location, method = "city")
    data15["State"] = data15["Location"].apply(get_location, method = "state")
    data15["ZipCode"] = data15["Location"].apply(get_location, method = "zip")
    data15["ZipCode"] = data15["ZipCode"].astype(int) # convert to numeric
    data15.drop(columns = "Location", inplace = True)

    # Delete columns from data15 that arent in data16
    data15.drop(columns = set(data15.columns.tolist()).difference(data16.columns.tolist()), inplace = True)

    # Harmonize column order
    cols_order = data16.columns.tolist()
    data15 = data15.loc[:, cols_order]

    # Concatenate
    emission_df = pd.concat([data15, data16], axis = 0, ignore_index = True)

    # Train/test split
    inTrain , inTest = next(GroupShuffleSplit(train_size = 0.7, random_state = 42).\
                        split(emission_df, groups = emission_df["OSEBuildingID"]))

    emission_df["in_train"] = 0
    emission_df.iloc[inTrain, 46] = 1

    emission_df.to_csv(output_edfcsv, index=False)

if __name__ == '__main__':
    from kfp.components import create_component_from_func
    base_img = "public.ecr.aws/f6t4n1w1/poc_kf_pipeline:latest"
    merge_and_split_op = create_component_from_func(
        merge_and_split,
        output_component_file='merge_and_split_op.yaml',
        base_image=base_img,
        annotations={
            "author": "Antoine Villatte"}
    )